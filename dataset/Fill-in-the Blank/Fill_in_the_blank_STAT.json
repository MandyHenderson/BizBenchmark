[
  {
    "qid": "fill-in-the-blank-ds-3430",
    "question": "In the analysis of screening processes, the variance of $G$ between independent runs for the finite model can be expressed as $\\operatorname{var}\\left(G\\right)=\\frac{N_{0}\\sigma^{2}}{N_{0}+N_{1}V}\\{h(N_{1},N_{2})+V\\}$, where $h(u_{1},u_{2})$ is the variance of the mean of the largest $u_{2}$ values in a random sample of $u_{1}$ members from $N(0,1)$. For $N_{1}=N_{0}$, this simplifies to $\\operatorname{var}\\left(G\\right)=\\frac{\\sigma^{2}\\{h(N_{1},N_{2})+V\\}}{1+V}$. The function $h(u_{1},u_{2})$ can be computed from tables provided by Teichroew (1956), who tabulated expected squares and products of the first, second, ... largest values in random samples of 20 or less from $N(0,1)$. The variance of $G$ is crucial for assessing the reliability of the screening process, especially in ensuring that the risk of having only a small gain is minimized. For $N_{1}=N_{0}=16$, $N_{2}=4$, and $V=1.0$, the estimated $\\operatorname{var}(G)/\\sigma^{2}$ is approximately [BLANK].",
    "gold_answer": "0.533. This value is derived from empirical studies and highlights the variability in the expected gain $G$ for specific parameters of the finite model, emphasizing the importance of understanding the variance in screening processes."
  },
  {
    "qid": "fill-in-the-blank-ds-3162",
    "question": "In the estimation of the conditional density function f of the interarrival times for a PDMP, the function H(x, y, t) is defined for any x, y ∈ E and 0 ≤ t ≤ t*(x) as H(x, y, t) = ∫ₜᵗ*(x) fQ̃(x, s, y) ds + GQ̃(x, t*(x), y). Here, GQ̃(x, t*(x), y) represents the [BLANK].",
    "gold_answer": "survival function multiplied by the transition kernel at the exit time. This term accounts for the scenario where the jump occurs upon hitting the boundary of the state space."
  },
  {
    "qid": "fill-in-the-blank-ds-271",
    "question": "In the context of analyzing three binary variables, $X$, $U_{1}$, and $U_{2}$, the measure $D_{P} = P_{X|U_{1}}(1|1) - P_{X|U_{1}}(1|0)$ is considered a measure of discrimination between the events $X=1$ and $X=0$ based on the information from $U_{1}$. The larger the value of $D_{P}$, the better the discriminator $U_{1}$. This discriminating ability may change according to the association level of the two $U$ variables, specifically as the [BLANK] between $U_{1}$ and $U_{2}$ increases.",
    "gold_answer": "cross-product ratio (CPR). The cross-product ratio between $U_{1}$ and $U_{2}$ is a key measure of their association level, and as it increases, the discriminating ability $D_{P}$ of $U_{1}$ for $X$ also increases, under the assumption that $X$ is positively associated with both $U_{1}$ and $U_{2}$."
  },
  {
    "qid": "fill-in-the-blank-ds-2250",
    "question": "In the context of tests for cointegration with structural breaks, the approach involves computing one of the usual test statistics from subsamples of the data. The breaks hypothesis asserts that there are periods in which fixed cointegrating relationships hold. The possibility of a consistent test requires that these periods must grow in length with the overall sample, and hence, the detection of a relationship should be possible by choosing an appropriate subsample for the test. In its most general form, this approach suggests some sort of [BLANK] sequence of subsamples.",
    "gold_answer": "incremental or rolling. This is because the approach aims to detect cointegrating relationships that may exist over varying subsamples of the data, by either incrementally adding observations or rolling through the dataset to evaluate different segments."
  },
  {
    "qid": "fill-in-the-blank-ds-3317",
    "question": "In the context of stochastic differential equation mixed-effects models (SDEMEMs), the likelihood function is typically intractable, motivating the use of sampling-based approaches such as [BLANK].",
    "gold_answer": "Markov chain Monte Carlo (MCMC). This is because MCMC methods allow for the approximation of the posterior distribution of parameters when the likelihood is not analytically tractable."
  },
  {
    "qid": "fill-in-the-blank-ds-2831",
    "question": "Substationarity means that the distribution of a spatial point process (SPP) can only be invariant under location shifts within a [BLANK] of the domain.",
    "gold_answer": "linear subspace. This term is omitted to emphasize that substationarity is a concept that lies between stationarity and nonstationarity, focusing on invariance within specific subspaces."
  },
  {
    "qid": "fill-in-the-blank-ds-3422",
    "question": "In the context of testing whether the proportion of failures of Type I varies in time, a simple test involves grouping the times of failure and testing by χ² the hypothesis that the probability π₁(t) that a failure is of Type I is [BLANK].",
    "gold_answer": "constant. This test checks for temporal variation in the probability of Type I failures, a key assumption in distinguishing between different models of failure mechanisms."
  },
  {
    "qid": "fill-in-the-blank-ds-3278",
    "question": "In the context of estimating linear functionals of a bivariate distribution with equal marginals, the empirical estimator is efficient if the distribution Q is completely unknown. However, if X and Y are independent, a better estimator is given by [BLANK].",
    "gold_answer": "the U-statistic based on the pooled sample. This estimator is efficient under the minimal assumptions for which it was derived, providing significant improvements over the empirical estimator when additional information about Q is available."
  },
  {
    "qid": "fill-in-the-blank-ds-2712",
    "question": "In the hierarchical modeling approach for clustering probability density functions, the method is introduced in the univariate context and then extended to multivariate densities by means of a [BLANK] model performing dimension reduction.",
    "gold_answer": "factorial. This is omitted to highlight the specific type of model used for extending the method to multivariate settings, emphasizing the approach's adaptability and efficiency in handling higher-dimensional data."
  },
  {
    "qid": "fill-in-the-blank-ds-44",
    "question": "In the simplified model for a panel of time series observations, the equation is given by X_{(i)t} = ∑_{j=1}^{p}a_{j}X_{(i)t-j} + η_{t} + ε_{(i)t}, where η_{t} represents [BLANK].",
    "gold_answer": "effects over time influencing all of the series. This term captures the common temporal effects across the panel, highlighting the intercorrelation among the series."
  },
  {
    "qid": "fill-in-the-blank-ds-1472",
    "question": "In the heteroscedastic hierarchical model, the SURE estimates are shown to be superior to EBMLE and EBMOM in terms of the averaged squared loss under both parametric and semiparametric settings. This superiority is particularly evident when the data exhibit [BLANK], a scenario not uncommon in practical applications such as gene expression data from microarray studies.",
    "gold_answer": "heteroscedasticity and correlation between components. The SURE estimator's ability to account for unequal variances and dependencies among data components makes it particularly effective in complex data structures, outperforming other estimators that may not fully capture these aspects."
  },
  {
    "qid": "fill-in-the-blank-ds-878",
    "question": "For subjects who will never experience a recurrence of the event, referred to as zero-recurrence subjects, the first gap time is considered to be [BLANK].",
    "gold_answer": "infinite. This conceptualization allows the model to differentiate between subjects who are at risk of experiencing the event and those who are not, by assigning an infinite gap time to the latter."
  },
  {
    "qid": "fill-in-the-blank-ds-1146",
    "question": "In the context of testing the randomness of a sequence using the longest run criterion, the hypothesis to be tested, denoted as H₀, is that the elements of the sequence are in a [BLANK] order.",
    "gold_answer": "random. This is the null hypothesis in statistical tests for randomness, assuming no specific pattern or dependency in the sequence."
  },
  {
    "qid": "fill-in-the-blank-ds-385",
    "question": "Edwards' test for seasonality and a suggested alternative likelihood ratio test are compared. The tests are almost identical for samples of [BLANK] observations or more, but for small samples the likelihood ratio test is considerably superior.",
    "gold_answer": "200. This highlights the threshold sample size beyond which both tests perform similarly, emphasizing the likelihood ratio test's advantage with smaller datasets."
  },
  {
    "qid": "fill-in-the-blank-ds-2657",
    "question": "The uniform distribution on the Stiefel manifold is a unit invariant measure on $O(n,\\phi)$ which we denote by [BLANK].",
    "gold_answer": "$[d{\\bf X}]$. This notation represents the uniform distribution on the Stiefel manifold, highlighting its invariance property under orthogonal transformations."
  },
  {
    "qid": "fill-in-the-blank-ds-1920",
    "question": "In the Bayesian approach to estimating COVID-19 incidence and infection fatality rates, the probability that individual i has been infected with COVID-19 is given by logit(p_i) = [BLANK], where x_i is a vector of covariates and β is a vector of regression coefficients.",
    "gold_answer": "β^T x_i. This formula represents the logistic regression model used to relate an individual’s covariates to their probability of infection."
  },
  {
    "qid": "fill-in-the-blank-ds-1274",
    "question": "In the Bayesian method for estimating a mean in the face of mean-shift contamination, the posterior distribution is approximated to simplify computation. This approximation is given by $\\widetilde{\\theta}|y,k\\sim S t[n-k-1,\\hat{\\theta}_{k},\\widetilde{\\lambda}_{k}^{2}]$, where $\\widetilde{\\lambda}_{k}$ is defined as $(n-k-3)^{(1/2)}(n-k-1)^{-(\\bar{1/2})}\\tilde{\\lambda}_{k}$. What is the missing term in the definition of $\\widetilde{\\lambda}_{k}$?",
    "gold_answer": "$\\tilde{\\lambda}_{k}$ is defined as $(n-k-3)^{(1/2)}(n-k-1)^{-(\\bar{1/2})}\\hat{\\lambda}_{k}$. The missing term, $\\hat{\\lambda}_{k}$, is the posterior standard deviation of $\\theta$ given $y$ and $k$, highlighting the adjustment made for degrees of freedom in the approximation."
  },
  {
    "qid": "fill-in-the-blank-ds-2054",
    "question": "The MC-SIS procedure selects important variables based on the magnitudes of $\\widehat{\\lambda_{j1}^*$, which is the estimate of the largest eigenvalue $\\lambda_{j1}^*$ from the generalized eigenvalue problem involving the matrices $\\mathbf{A}_{j00}$, $\\mathbf{A}_{j0X}$, and $\\mathbf{A}_{jXX}$. The selected set of variables is defined as $\\widehat{\\mathcal{D}_{\\nu_n}} = \\{1 \\leq j \\leq p : \\widehat{\\lambda_{j1}^*} \\geq \\nu_n\\}$, where $\\nu_n$ is a pre-specified threshold. The threshold $\\nu_n$ is often chosen such that the size of $\\widehat{\\mathcal{D}_{\\nu_n}}$ is $n$ or $[n / \\ln n]$. The term [BLANK] is used to denote the cardinality of the selected set $\\widehat{\\mathcal{D}_{\\nu_n}}$.",
    "gold_answer": "$|\\widehat{\\mathcal{D}_{\\nu_n}}|$. This notation represents the number of variables selected by the MC-SIS procedure, indicating the size of the reduced dimensionality set that retains the active predictors."
  },
  {
    "qid": "fill-in-the-blank-ds-1117",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies the analysis by allowing valid inferences without modeling the dropout process explicitly."
  },
  {
    "qid": "fill-in-the-blank-ds-3330",
    "question": "The recursive kernel density estimator for directional data proposed in the paper is based on the stochastic approximation method for successive experiments proposed in [BLANK].",
    "gold_answer": "Robbins & Monro (1951). This reference is crucial as it lays the foundation for the recursive estimation technique used in the paper, highlighting the methodological basis of the proposed estimator."
  },
  {
    "qid": "fill-in-the-blank-ds-2246",
    "question": "In the context of analyzing cross-classified survey data, the adjusted Pearson X² statistic is divided by [BLANK] to reduce the error in the level of tests, where v is the appropriate degrees of freedom. What is the term used to describe this adjustment?",
    "gold_answer": "E(X²)/v. This term is crucial for the one moment adjustment of the X² statistic, ensuring the test's level is more accurately aligned with the nominal level by accounting for the survey design's effect."
  },
  {
    "qid": "fill-in-the-blank-ds-3295",
    "question": "The SCAD penalty function is defined for a given tuning parameter ζ > 0 and a threshold a. For |θ| ≤ ζ, the penalty is pe_ζ(θ) = [BLANK].",
    "gold_answer": "ζ|θ|. This part of the SCAD penalty applies a linear penalty to coefficients that are within the threshold ζ, encouraging sparsity."
  },
  {
    "qid": "fill-in-the-blank-ds-1760",
    "question": "In the context of penalized singular value decomposition (SVD) for a data matrix where the left singular vector is sparse and the right singular vector is a discretized function, the method uses two penalties to impose sparsity and smoothness. However, it is shown that the value of only [BLANK] has to be chosen, which is in contrast to previous penalized SVD models.",
    "gold_answer": "one parameter. This highlights the efficiency of the proposed method by reducing the complexity of parameter selection compared to earlier approaches."
  },
  {
    "qid": "fill-in-the-blank-ds-1822",
    "question": "The kernel method of estimating the cell probabilities of a multivariate categorical distribution, due to Aitchison & Aitken (1976), depends crucially on an unknown smoothing parameter [BLANK]. A method of estimating this parameter is introduced which is explicitly connected to multivariate discrimination.",
    "gold_answer": "λ (lambda). This is the smoothing parameter that plays a critical role in the kernel method for estimating cell probabilities in multivariate categorical distributions, as highlighted by Aitchison & Aitken (1976)."
  },
  {
    "qid": "fill-in-the-blank-ds-3047",
    "question": "The reliability ratio (RR), defined as Var(X)/Var(W), is frequently used to quantify the amount of measurement error. In simulations studies with sample sizes of at least n=1000 and reliability ratios as low as [BLANK], the researchers rarely encountered an invalid set of estimated moments.",
    "gold_answer": "0.5. This value demonstrates the robustness of the MAI method under conditions of substantial measurement error, indicating its applicability even when the reliability of the measurements is relatively low."
  },
  {
    "qid": "fill-in-the-blank-ds-1707",
    "question": "In the context of estimating the precision matrix of a singular Wishart distribution, the Stein–Haff identity is established for a singular Wishart distribution with a positive definite mean matrix but with the dimension larger than the degrees of freedom. This identity is then used to obtain estimators of the precision matrix improving on the estimator based on the [BLANK] inverse of the Wishart matrix under the Efron–Morris loss function and its variants.",
    "gold_answer": "Moore–Penrose. The Moore–Penrose inverse is used as a generalized inverse for matrices that are not invertible, making it suitable for the singular Wishart distribution scenario discussed."
  },
  {
    "qid": "fill-in-the-blank-ds-1945",
    "question": "In the context of identifying differentially expressed genes, the ODP approach transforms the data by centering each gene around zero to achieve nuisance parameter invariance. This transformation involves subtracting the estimated mean expression level of each gene from its observations. What is the purpose of this transformation?",
    "gold_answer": "The purpose is to approximately achieve the condition where the average null distribution across all genes equals the average null distribution of only the true null genes, thus ensuring that the nuisance parameters do not bias the ODP's performance."
  },
  {
    "qid": "fill-in-the-blank-ds-979",
    "question": "In the context of Hertzian fracture data, the hypothesis about the distribution of critical loads can be expressed as P(X>x) = exp{-d²α(x)}, where X=w/d² and α(x) is an unknown function that increases continuously from 0 to ∞ with x. What is the term that represents the critical load on an indenter of diameter d required to produce a fracture?",
    "gold_answer": "w. This term is crucial as it directly relates to the physical measurement of the load at which fracture occurs, forming the basis for the hypothesis about the distribution of critical loads."
  },
  {
    "qid": "fill-in-the-blank-ds-2708",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by stating that the missingness mechanism depends only on observed data, not on unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-3257",
    "question": "The stationary complex boundary for AR(2) processes is located at [BLANK], where unit root cycles at any frequency ω can be generated for values of ϕ₁ in the range [−2,2].",
    "gold_answer": "ϕ₂ = −1. This condition defines the stationary complex boundary for AR(2) processes, allowing for unit root cycles at any frequency ω."
  },
  {
    "qid": "fill-in-the-blank-ds-3243",
    "question": "In the context of extreme conditional expectile estimation, the expectile at level α is defined as the solution to a minimization problem involving the expectile check function ηα(y). The expectile check function is given by ηα(y) = [BLANK]. What is the correct form of the expectile check function?",
    "gold_answer": "|α − 𝟙{y≤0}|y². The expectile check function is used in the minimization problem to define expectiles, which are analogous to quantiles but are based on squared loss rather than absolute loss, making them sensitive to the magnitude of deviations."
  },
  {
    "qid": "fill-in-the-blank-ds-429",
    "question": "Low tidal volume ventilation (LTVV) is recommended as an effective ventilation strategy for patients with acute lung injury (ALI), based on the results of a randomized clinical trial comparing low versus high tidal volume strategies. The recommendation was made despite high non-adherence rates in the LTVV arm, where non-adherence occurred because treating physicians felt that deviating from the prescribed regime would improve patients’ outcomes. To address this controversy, researchers sought to estimate the survival distribution in the counterfactual setting where all patients assigned to LTVV followed the regime, using a fully Bayesian implementation of Robins’s [BLANK] formula.",
    "gold_answer": "G-computation. This formula is used to estimate the potential survival distribution under a specific treatment regime by integrating over the distribution of observed data, accounting for time-dependent confounders and missing data mechanisms."
  },
  {
    "qid": "fill-in-the-blank-ds-2875",
    "question": "The second approach developed to help understand EPICs is called the [BLANK] method, which aims at identifying easy-to-describe regions in the sample space that are dominated by one EPIC.",
    "gold_answer": "Prominent Region (PR). This method seeks to find regions in the feature space where one EPIC predominates, described by simple conditions on individual variables, aiding in the interpretation of EPICs."
  },
  {
    "qid": "fill-in-the-blank-ds-2481",
    "question": "In the context of testing for serial correlation in least squares regression, the statistic used is denoted by [BLANK]. This statistic is calculated as the ratio of the sum of squared first differences of the residuals to the sum of squared residuals.",
    "gold_answer": "d. The statistic d is central to the Durbin-Watson test for serial correlation, measuring the degree of autocorrelation in the residuals from a regression analysis."
  },
  {
    "qid": "fill-in-the-blank-ds-1930",
    "question": "The EM algorithm is used in the two-stage model to handle missing data on tumor characteristics under the assumption that the data are [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the EM algorithm to provide valid inferences without explicitly modeling the missingness process, by allowing the missingness to depend only on observed data."
  },
  {
    "qid": "fill-in-the-blank-ds-26",
    "question": "In the pseudolikelihood approach for nested case-control studies, the likelihood is factorized into a product of the outcome model and the missingness mechanism, expressed as f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK], where Rᵢ denotes the missingness indicators. What missingness-related term completes this equation?",
    "gold_answer": "f(Rᵢ | Yᵢ). This term is crucial as it represents the conditional probability of the missingness indicators given the outcomes, highlighting the dependency between missingness and the observed data."
  },
  {
    "qid": "fill-in-the-blank-ds-899",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). We remove it from the question because it represents the core assumption that simplifies inference: once we condition on the observed responses, the missingness no longer depends on the unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-434",
    "question": "In network meta-analysis, it is often desirable to synthesize different types of studies, featuring aggregated data and individual patient level data. However, existing methods do not sufficiently consider the quality of studies across different types of data and assume that the treatment effects are exchangeable across all studies regardless of these types. We propose Bayesian hierarchical network meta-analysis models that allow us to borrow information adaptively across aggregated data and individual patient level data studies by using [BLANK] and commensurate priors. The power parameter in the power priors and spike-and-slab hyperprior in the commensurate priors govern the level of borrowing information among study types.",
    "gold_answer": "power priors. This is excluded to highlight the method's ability to adaptively borrow information across different types of studies by adjusting the influence of each study type based on its quality."
  },
  {
    "qid": "fill-in-the-blank-ds-1489",
    "question": "In adaptive rejection sampling, the upper hull hᵤ(x) of h(x) consists of the tangents at {xᵢ}. It is defined by the slope of the tangents h'(xᵢ), the abscissae {z₍ᵢ₎} of the intersection between the tangents at x₍ᵢ₎ and at x₍ᵢ₊₁₎, and the values [BLANK]. Which term completes the definition of the upper hull?",
    "gold_answer": "hᵤ(z₍ᵢ₎). This term is essential as it represents the value of the upper hull at the intersection points, which are used to define the piecewise linear approximation of the log-density function."
  },
  {
    "qid": "fill-in-the-blank-ds-1136",
    "question": "The Akaike Information Criterion, AIC, and a bias-corrected version, [BLANK], are two methods for selection of regression and autoregressive models.",
    "gold_answer": "AICc. The bias-corrected version of AIC is denoted as AICc and is used to adjust for small sample sizes."
  },
  {
    "qid": "fill-in-the-blank-ds-1778",
    "question": "In the linear instrumental variables regression framework, the model averaging estimator is a weighted average of individual estimates obtained using different lists of valid instruments. The weights for averaging across individual estimates are obtained by direct smoothing of [BLANK] arising from the estimation stage.",
    "gold_answer": "selection criteria"
  },
  {
    "qid": "fill-in-the-blank-ds-2522",
    "question": "In the approach to fitting sparse Seasonal Vector Autoregressive (SVAR) models based on Partial Spectral Coherences (PSCs), the seasonal filter Φ_s(B^s) accounts for the between-cycle dependence structure. The sparse filter Φ_s(B^s) can be estimated by following the approach of Davis et al. (2015) applied to the series Y_t^(m) = X_((t-1)s + m), where m is a fixed season. A new issue arising here is how to combine the information across different seasons m. Once the sparse seasonal filter is estimated, its seasonal effect on X_n can be removed, and then the between-season filter Φ(B) can be estimated sparsely by following again the approach of Davis et al. (2015). The key step involves calculating the PSCs for each season m and then defining the rank of the seasonal PSC for the pair (j, k) as r(j, k) = sum from m=1 to s of R^(m)(j, k), where R^(m)(j, k) is the rank of the PSC for the pair (j, k) in season m. The term [BLANK] is used to rank the partial correlations in the between-cycle time series Y_t^(m).",
    "gold_answer": "r(j, k)"
  },
  {
    "qid": "fill-in-the-blank-ds-1000",
    "question": "In the application to polymer chemistry, the stress relaxation modulus G(ω) can be represented as an integral involving the relaxation spectral measure μ, specifically G(ω) = ∫_0^∞ (1/x) e^(-ω/x) dμ(x). The measure μ is assumed to be [BLANK].",
    "gold_answer": "finite. The assumption that μ is a finite measure on (ℝ_+, ℛ_+) is fundamental to the model, as it allows for the representation of the stress relaxation modulus in terms of an integral with respect to μ."
  },
  {
    "qid": "fill-in-the-blank-ds-1175",
    "question": "The skew-normal random process is defined by the transformation of a stationary Gaussian process. If we let $X(s)$ be a stationary Gaussian random process with zero-mean, unit variance, and correlation function $\\rho(h)$, then the skew-normal random process $Z(s)$ can be defined as $Z(s) = \\sqrt{1-\\delta(s)^2}X(s) + \\delta(s)X''(s)$, where $X''(s) = X' | X' + \\varepsilon > 0$ and $X'$ is independent of $X(s)$. The slant function $\\delta(s)$ must satisfy [BLANK] for all $s \\in \\mathbb{S}$ to ensure the process is well-defined.",
    "gold_answer": "-1 < \\delta(s) < 1. This condition ensures that the transformation remains valid and the process retains the properties of a skew-normal distribution across its domain."
  },
  {
    "qid": "fill-in-the-blank-ds-2933",
    "question": "In the proposed Bayesian framework for VAR models, the shrinkage parameter λ is selected at the minimum point of a newly proposed score function which is asymptotically equivalent to the [BLANK] of the model coefficients.",
    "gold_answer": "mean squared error. The score function is designed to approximate the mean squared error, providing a computationally feasible method for selecting the shrinkage parameter without relying on traditional MCMC sampling methods."
  },
  {
    "qid": "fill-in-the-blank-ds-1504",
    "question": "The Maximum Likelihood Histogram (ML histogram) is defined as the maximizer of the log-likelihood in $\\mathcal{F}_{\\mathbb{Z}}$ and is given by $\\widehat{f}_{\\mathcal{Z}} := \\mathrm{argmax}_{f\\in\\mathcal{F}_{\\mathcal{Z}}}L(f,x_{1},\\ldots,x_{n}) = \\frac{1}{n}\\sum_{j=1}^{D}\\frac{N_{j}}{|I_{j}|}\\mathbb{1}_{I_{j}}$, where $N_{j} = \\sum_{i=1}^{n}\\mathbf{1}_{I_{j}}(x_{i})$. The log-likelihood is $L(\\hat{f}_{\\mathcal{T}},x_{1},\\dots,x_{n}) = \\sum_{j=1}^{D}N_{j}\\log\\frac{N_{j}}{n|I_{j}|}$. What is the term that represents the count of observations in the interval $I_{j}$?",
    "gold_answer": "$N_{j}$. This term counts the number of observations that fall into the interval $I_{j}$, which is crucial for calculating the height of the histogram bars in the ML histogram."
  },
  {
    "qid": "fill-in-the-blank-ds-816",
    "question": "The RAMSVM classifier uses a convex combination of two MSVM losses to form a new group of Fisher consistent hinge loss functions for multicategory problems. The convex combination parameter is denoted by [BLANK].",
    "gold_answer": "γ (gamma). This parameter balances the contribution of the two MSVM losses in the convex combination, allowing for a flexible and potentially more robust classification approach."
  },
  {
    "qid": "fill-in-the-blank-ds-2574",
    "question": "In the analysis of the Lachish skulls, the percentage of cases with no teeth lost before death is high, but it must be remembered that the age constitution, judging from the state of the sutures, indicates a younger group, on the average, than that expected in a cemetery population. The frequencies of adult upper jaws with one or both third molars absent are not unusual, but it is customary to find the female percentage greater than the male. The samples are too small, however, to give a reliable sexual comparison in this respect. The condition where one or both third molars are absent is referred to as [BLANK].",
    "gold_answer": "congenitally absent. This term is used to describe the absence of third molars from birth, which is a common dental anomaly observed in the study."
  },
  {
    "qid": "fill-in-the-blank-ds-813",
    "question": "The estimator of the error density f_U proposed in the paper involves a deconvolution technique that requires the Fourier transform of the error density, f_U^Ft, to be real-valued and not vanish at any point on the real line. This condition is referred to as [BLANK].",
    "gold_answer": "Assumption 3. This assumption ensures that the deconvolution problem is well-posed and that the estimator of f_U can be accurately computed."
  },
  {
    "qid": "fill-in-the-blank-ds-2339",
    "question": "In the AR(1) model with heteroscedasticity, the error term u_t is defined as u_t = ρu_{t-1} + e_t, where e_t are normally and independently distributed with mean 0 and variance [BLANK]. What is the correct term to fill in the blank?",
    "gold_answer": "w_tσ^2. This term represents the variance of the error term e_t, which is a function of a known vector z_t and parameters λ, highlighting the heteroscedastic nature of the model."
  },
  {
    "qid": "fill-in-the-blank-ds-2091",
    "question": "The likelihood ratio test for the hypothesis that the smaller of two canonical correlations is zero is nonsimilar; the distribution of the test statistic depends on the value of the largest canonical correlation. In applications the nuisance parameter usually has to be estimated, and this paper describes the distributional properties of the test, conditional on the estimator. Although these properties depend on the nuisance parameter, the dependency seems to be negligible for practical purposes. The hypothesis of interest is that the rank of the covariance matrix is at most one, or equivalently that [BLANK]. The likelihood ratio test statistic, suggested by Bartlett (1938), is given by LR = -n log(1 - r₂²).",
    "gold_answer": "λ² = 0. This is the hypothesis being tested, indicating that the smaller canonical correlation is zero, which implies the rank of the covariance matrix is at most one."
  },
  {
    "qid": "fill-in-the-blank-ds-2882",
    "question": "In the context of multivalued functions, the integral of a function F is defined as the set of integrals of all measurable selections of F. This is known as the [BLANK] integral.",
    "gold_answer": "Aumann. The Aumann integral generalizes the concept of integration to multivalued functions by considering the integral of all measurable selections."
  },
  {
    "qid": "fill-in-the-blank-ds-1555",
    "question": "In the intraclass correlation model, the covariance matrix Σ is expressed as σ²[(1-ρ)I + ρ11'], where [BLANK] is the intraclass correlation coefficient.",
    "gold_answer": "ρ. This coefficient measures the degree of correlation among the observations within the same class or group."
  },
  {
    "qid": "fill-in-the-blank-ds-1037",
    "question": "In the variance-based sensitivity model, the residual variation in the true weights not explained by the estimated weights is parameterized by an [BLANK] value.",
    "gold_answer": "R². This parameter represents the proportion of variance in the true weights that is not explained by the estimated weights, providing a measure of imbalance due to omitted confounders."
  },
  {
    "qid": "fill-in-the-blank-ds-778",
    "question": "In the power studies section, the paper compares the performance of the proposed tests with that of Delgado's test. For the AR(1) model $U_{t}=b*U_{t-1}+\\delta_{t}$, Delgado's statistic performs slightly better, but for the nonlinear alternative $U_{t}=b\\delta_{t-1}^{2}+\\delta_{t}$, the proposed tests $V,~\\bar{V},~V^{*}$ or $\\bar{V}^{*}$ are more powerful. This illustrates the tests' ability to detect [BLANK].",
    "gold_answer": "nonlinear dependencies. The proposed tests show superior performance in detecting nonlinear relationships in the data, highlighting their versatility and robustness beyond linear alternatives."
  },
  {
    "qid": "fill-in-the-blank-ds-613",
    "question": "The distribution of a stationary log Gaussian Cox process is completely characterized by its intensity and the [BLANK] function.",
    "gold_answer": "pair correlation"
  },
  {
    "qid": "fill-in-the-blank-ds-2485",
    "question": "In the context of testing one hypothesis multiple times (TOHM), the global p-value is approximated using the expected Euler characteristic (EC) of the excursion set of the underlying random field. This approximation relies on the so-called [BLANK] heuristic.",
    "gold_answer": "EC heuristic. This heuristic is used to approximate the probability of observing a supremum of a random field above a certain threshold by considering the expected Euler characteristic of the excursion set, which simplifies the computation of global p-values in multidimensional settings."
  },
  {
    "qid": "fill-in-the-blank-ds-2240",
    "question": "For the extreme members in samples from normal populations, the second moment about the mean, μ₂, for a sample size n=2 is [BLANK].",
    "gold_answer": "0.68169011. This value is derived from the specific calculations for the second moment of the extreme order statistic in samples of size 2 from a normal distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-2707",
    "question": "The Birnbaum–Saunders distribution is receiving considerable attention due to its good properties. One of its extensions is the class of scale-mixture Birnbaum–Saunders (SBS) distributions, which shares its good properties, but it also has further properties. The autoregressive conditional duration models are the primary family used for analyzing high-frequency financial data. We propose a methodology based on SBS autoregressive conditional duration models, which includes in-sample inference, goodness-of-fit and out-of-sample forecast techniques. We carry out a Monte Carlo study to evaluate its performance and assess its practical usefulness with real-world data of financial transactions from the New York stock exchange. The main objective of this work is to propose a methodology based on ACD models generated from SBS distributions (SBS–ACD models). This methodology includes in-sample techniques considering estimation of the model parameters via the [BLANK] algorithm, inference about these parameters and model checking based on residual analysis, and out-of-sample forecast techniques.",
    "gold_answer": "EM (Expectation–Maximization). The EM algorithm is highlighted as a method for efficiently computing the maximum likelihood (ML) estimates of the model parameters, which is crucial for the in-sample techniques mentioned."
  },
  {
    "qid": "fill-in-the-blank-ds-1942",
    "question": "The most widely used approach for analyzing data from a multi-reader multi-test study is the [BLANK] method, which utilizes a standard analysis of variance (ANOVA) model for the jackknife pseudovalues of the area under the ROC curves (AUCs).",
    "gold_answer": "Dorfman–Berbaum–Metz (DBM). This method is highlighted for its common use in analyzing multi-reader multi-test ROC data, despite lacking a clear theoretical basis."
  },
  {
    "qid": "fill-in-the-blank-ds-595",
    "question": "In the proposed multi-dimensional functional principal component analysis, the first FPC ψ₁(u,ν,t) is obtained by minimizing a specific objective function subject to ||ψ₁||² = 1. What is the critical element omitted in the objective function?",
    "gold_answer": "The critical element omitted is the estimated mean function μ̂(uᵢⱼ,νᵢⱼ,tᵢⱼ). This highlights the importance of centering the data by subtracting the mean function before estimating the functional principal components, ensuring that the analysis focuses on the variation around the mean."
  },
  {
    "qid": "fill-in-the-blank-ds-825",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yᵢⱼ can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where αᵣ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "bᵢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-3534",
    "question": "In the linear functional relationship model where ηᵢ = β + αξᵢ, and given that ξᵢ and ηᵢ are normally distributed with the same variances and zero correlations, the maximum likelihood estimate of α when λ = δy²/δx² is known is given by a formula involving Θ. What is the formula for Θ?",
    "gold_answer": "Θ = (Σ(y - ȳ)² - λΣ(x - x̄)²) / (2Σ(x - x̄)(y - ȳ)). This formula is crucial for estimating the slope α in the presence of known variance ratio λ, highlighting the relationship between the variances of y and x and their covariance."
  },
  {
    "qid": "fill-in-the-blank-ds-3535",
    "question": "In the analysis of a dam with infinite depth and unit release per unit time, the inputs form a compound Poisson process with parameter [BLANK]. What is the parameter of the Poisson process that models the inputs?",
    "gold_answer": "λ. This parameter represents the rate of the Poisson process, which is crucial for modeling the timing of inputs into the dam."
  },
  {
    "qid": "fill-in-the-blank-ds-749",
    "question": "In the context of multiple imputation for missing data, Rubin & Schenker (1986) proposed the approximate Bayesian bootstrap method, which involves a two-stage resampling procedure. The first stage involves resampling [BLANK] values with replacement from the observed data.",
    "gold_answer": "n. This refers to the number of observed values resampled in the first stage of the approximate Bayesian bootstrap method, a critical step in creating multiple imputations for missing data."
  },
  {
    "qid": "fill-in-the-blank-ds-2601",
    "question": "The self-controlled case series model is derived from an underlying [BLANK] model.",
    "gold_answer": "Poisson cohort. This is the foundational model from which the self-controlled case series method is developed, assuming events arise as a non-homogeneous Poisson process."
  },
  {
    "qid": "fill-in-the-blank-ds-1204",
    "question": "In penalized spline regression, the smoothness of the fitted curve is controlled by the parameter [BLANK], which is often estimated using restricted maximum likelihood (REML).",
    "gold_answer": "λ (lambda). This parameter determines the influence of the penalty matrix on the smoothness of the spline, with higher values leading to smoother curves."
  },
  {
    "qid": "fill-in-the-blank-ds-618",
    "question": "In the context of log Gaussian Cox processes, the 'scale' parameter β is with respect to [BLANK].",
    "gold_answer": "locations"
  },
  {
    "qid": "fill-in-the-blank-ds-2124",
    "question": "The EM algorithm for the TCFA model involves an E-step that calculates the conditional expectations of the complete log-likelihood function. Specifically, it requires the computation of $\\widehat{\\mathbf{y}_{i}}^{(k)} = E\\left[\\mathbf{y}_{i}|\\mathbf{V}_{i},\\mathbf{C}_{i},\\pmb{\\theta}^{(k)}\\right]$ and $\\widehat{\\mathbf{y}_{i}\\mathbf{y}_{i}^{\\top}}^{(k)} = E\\left[\\mathbf{y}_{i}\\mathbf{y}_{i}^{\\top}|\\mathbf{V}_{i},\\mathbf{C}_{i},\\pmb{\\theta}^{(k)}\\right]$. These expectations are the first and second moments of a [BLANK] distribution, which are essential for the E-step computations.",
    "gold_answer": "multivariate truncated normal. These moments are crucial for updating the parameters in the M-step of the EM algorithm, as they account for the censoring in the data."
  },
  {
    "qid": "fill-in-the-blank-ds-2713",
    "question": "In structural equation models for benchmark analysis, the observed exposures and outcomes are assumed to depend on underlying latent variables and a random measurement error. The latent exposure is denoted as [BLANK], and the latent response is denoted as η₂.",
    "gold_answer": "η₁. This is excluded to highlight the distinction between the latent exposure (η₁) and the latent response (η₂) in the model, emphasizing the structural relationships between these unobserved variables."
  },
  {
    "qid": "fill-in-the-blank-ds-730",
    "question": "In the context of the MESV model, the term [BLANK] refers to the correlation between the ith asset return at time t and the function of jth asset volatility at time t+1.",
    "gold_answer": "cross leverage"
  },
  {
    "qid": "fill-in-the-blank-ds-384",
    "question": "The Dickey–Fuller test evaluates the null hypothesis of unit root non-stationarity, under no missing data. Beyond recommendations under data missing completely at random for complete case analysis or last observation carry forward imputation, researchers have not extended unit root nonstationarity testing to more complex missing data mechanisms. Multiple imputation with chained equations, Kalman smoothing imputation, and linear interpolation have also been used for time-series data, however such methods impose constraints on the autocorrelation structure and impact unit root testing. We propose maximum likelihood estimation and multiple imputation using state space model approaches to adapt the augmented Dickey–Fuller test to a context with missing data. We further develop sensitivity analyses to examine the impact of [BLANK] data.",
    "gold_answer": "MNAR (Missing Not at Random). This term is omitted to highlight the focus on examining the impact of data that is missing not at random, which is a more complex missingness mechanism than MCAR or MAR."
  },
  {
    "qid": "fill-in-the-blank-ds-183",
    "question": "In the context of modified profile likelihoods for stratified data, the condition for the profile likelihood to have the usual asymptotic distribution is $1/m=o(q^{-1})$, while for the modified profile likelihood, it is $1/m=o([BLANK])$. What is the missing term that completes the condition for the modified profile likelihood?",
    "gold_answer": "q^{-1/3}. This term is crucial as it indicates that the modified profile likelihood can achieve the usual asymptotic distribution under a weaker condition compared to the profile likelihood, allowing for more flexibility in the relationship between the number of strata (q) and the sample size per stratum (m)."
  },
  {
    "qid": "fill-in-the-blank-ds-902",
    "question": "In the context of particle counting, the concentration of particles on the plate is measured by the quantity ψ = πNδ²/4A, where ψ represents the ratio of the sum of the areas of the particles to the area of the plate. For the model to be justifiable, we assume that for a given concentration ψ, N is sufficiently large, and [BLANK] is sufficiently small to neglect certain 'edge effects' and deal merely with the expected numbers of clumps of various sizes. What is the term that is deliberately omitted here?",
    "gold_answer": "δ²/A. This term is omitted to highlight the condition that the square of the particle diameter divided by the area of the plate must be sufficiently small to justify neglecting edge effects and focusing on expected clump numbers without considering sampling variation."
  },
  {
    "qid": "fill-in-the-blank-ds-3341",
    "question": "In the functional data analysis model, the observations can be modeled as Yₜ(xₜⱼ) = ηₜ(xₜⱼ) + σₜ(xₜⱼ)εₜⱼ, where εₜⱼ are measurement errors with Eεₜⱼ = 0 and Eεₜⱼ² = 1. The noise variance function is denoted by [BLANK].",
    "gold_answer": "σₜ²(x). This represents the variance function of the measurement error at point x for the t-th observation."
  },
  {
    "qid": "fill-in-the-blank-ds-3194",
    "question": "In the mixed model, the F-statistic F_2(ˆT_B) is based on the joint null hypothesis that there is a unit root and that the coefficients of the time-trend and the lagged trend-break dummy are both equal to zero. The data generating process under the unit root null hypothesis includes a term γ DU_{t-1}^0, where DU_{t-1}^0 is a dummy variable defined using the true break-date T_B^0, and e_t ~ i.i.d. (0,σ^2). The initial condition is set as y_0 = [BLANK].",
    "gold_answer": "0. This initial condition is commonly assumed in the derivation of the limiting distributions of unit root test statistics."
  },
  {
    "qid": "fill-in-the-blank-ds-1315",
    "question": "A sufficient condition for the identifiability of the contaminated Gaussian HMM is that if k ≠ k₁ implies ||μₖ - μₖ₁||₂² + ||Σₖ - aΣₖ₁||₂² ≠ 0 for all a > 0, where ||·||₂ is the Frobenius norm. This ensures that the finite mixture of contaminated Gaussian distributions is identifiable if two of the K Gaussian distributions representing the good observations have distinct component means and/or [BLANK]. What is the missing condition?",
    "gold_answer": "nonproportional component covariance matrices. This condition is crucial for distinguishing between different states based on their covariance structures, ensuring the model's identifiability."
  },
  {
    "qid": "fill-in-the-blank-ds-3601",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). We remove it from the question because it represents the core assumption that simplifies inference: once we condition on the observed responses, the missingness no longer depends on the unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-1731",
    "question": "In the Levinson-Durbin algorithm for the pure autoregressive case, the coefficient αₚ,₀(p) can be interpreted as minus the partial correlation of y(0) and y(-p) holding y(-1),...,y(-p+1) fixed. For the general autoregressive-moving average case, a similar representation of αₚ,ᵩ(p) and γₚ,ᵩ(p) is given, along with a simple relation between them which can replace the computationally expensive relation (2.7). This relation is given by γₚ,ᵩ(p) = [BLANK].",
    "gold_answer": "αₚ,ᵩ₋₁(p) (vₚ₋₁,ᵩ / σₚ₋₁,ᵩ) σₚ₋₁,ᵩ₋₁ vₚ₋₁,ᵩ₋₁ (σₚ₋₁,ᵩ₋₁² - σ²)⁻¹. This relation simplifies the computation by relating γₚ,ᵩ(p) to previously computed values, avoiding the need for more complex calculations."
  },
  {
    "qid": "fill-in-the-blank-ds-1890",
    "question": "In the dependent BINAR(1) model, the conditional pgf is exponentially affine in ±bX_{t-1}. Such a process is called [BLANK].",
    "gold_answer": "compound autoregressive (CaR). This term is used to describe processes where the conditional probability generating function (pgf) is exponentially affine in the past values of the process, highlighting the model's structure and properties."
  },
  {
    "qid": "fill-in-the-blank-ds-2593",
    "question": "The structural dimension, denoted as d, is defined as the dimension of the [BLANK] or the central mean subspace.",
    "gold_answer": "central subspace. The structural dimension is a key concept in sufficient dimension reduction, representing the dimension of the central subspace or the central mean subspace."
  },
  {
    "qid": "fill-in-the-blank-ds-3432",
    "question": "The basic idea behind testing goodness of fit for continuous distributions is that the distance should be '[BLANK]' when the null hypothesis is true, and '[BLANK]' when the hypothesis is false.",
    "gold_answer": "The basic idea behind testing goodness of fit for continuous distributions is that the distance should be 'small' when the null hypothesis is true, and 'large' when the hypothesis is false. This highlights the fundamental principle that the test statistic's value indicates the degree of agreement between the observed data and the null hypothesis."
  },
  {
    "qid": "fill-in-the-blank-ds-2274",
    "question": "The sample frequency spectrum (SFS) is a summary statistic which describes the distribution of mutant alleles at a polymorphic site in a sample of DNA sequences and provides a highly efficient dimensional reduction of large-scale population genomic variation data. The joint SFS data from multiple populations can be used to infer parameters of complex demographic histories, including variable population sizes, population split times, migration rates, admixture proportions, and so on. SFS-based inference methods require accurate computation of the expected SFS under a given demographic model. The expected joint SFS for thousands of individuals sampled from hundreds of populations related by a complex demographic model with arbitrary population size histories can be computed using new analytic formulas and algorithms implemented in a software package called [BLANK].",
    "gold_answer": "momi (MOran Models for Inference). The blank is filled with the name of the software package that implements the new analytic formulas and algorithms for computing the expected joint SFS, highlighting its role in demographic inference."
  },
  {
    "qid": "fill-in-the-blank-ds-1219",
    "question": "In the context of Data-Generating Experiments (DGEs), the Empirical Discrimination Index (EDI) is introduced to confirm almost surely discrimination of θ from θ*, that is, Fθ ≠ Fθ*, and to confirm identifiability of θ ∈ Θ by repeating this for θ* in a fine sieve of Θ. The EDI is based on properties of the Expected p-value for the [BLANK] test.",
    "gold_answer": "Kolmogorov-Smirnov. The EDI utilizes the Expected p-value from the Kolmogorov-Smirnov test to assess the discrimination between θ and θ* by evaluating the distance between their respective cumulative distribution functions, Fθ and Fθ*."
  },
  {
    "qid": "fill-in-the-blank-ds-3423",
    "question": "For the Weibull distribution, the distribution function is given by 1-exp{-(γt)^(1+[BLANK])}.",
    "gold_answer": "β. This parameter adjusts the shape of the Weibull distribution, allowing it to model various types of failure rate behaviors over time."
  },
  {
    "qid": "fill-in-the-blank-ds-842",
    "question": "The concept of a μ-pure field is analogous to the compactness of a class but is weaker because the μ-pure field depends on [BLANK] in an essential manner.",
    "gold_answer": "μ"
  },
  {
    "qid": "fill-in-the-blank-ds-2892",
    "question": "In the model, the mean expression level μ_{g i k} is modeled using a log-linear regression that includes the library size, baseline expression, and the effect size, which is the log-fold change of expression between the two conditions, denoted by [BLANK].",
    "gold_answer": "β_{g k}. This parameter captures the effect size or log-fold change in expression for gene g in study k between conditions."
  },
  {
    "qid": "fill-in-the-blank-ds-289",
    "question": "In the context of additive and causal interactions under exposure misclassification, the condition for positive interaction on the linear additive scale is given by p11 - p10 - p01 + p00 > 0. If this condition is satisfied, it implies that the effects of X1 and X2 together exceed the sum of the effects of X1 and X2 considered individually, that is, (p11 - p00) > (p10 - p00) + (p01 - p00). The standard condition for positive interaction on the linear additive scale is expressed as [BLANK] > 0.",
    "gold_answer": "p11 - p10 - p01 + p00. This condition is fundamental for identifying when the combined effect of two exposures exceeds the sum of their individual effects, indicating a synergistic interaction."
  },
  {
    "qid": "fill-in-the-blank-ds-435",
    "question": "In the penalized hazard model, the log-hazard function is expressed as a sum of functions, each representing a marginal basis or a tensor product of marginal bases. The general form is given by log{h(t;x)} = Σgⱼ(t;x), where h is the hazard function, t is the follow-up time, and x is a vector of continuous covariates. The function gⱼ can be a marginal basis of time, a marginal basis of a covariate, or the tensor product of the marginal bases of any elements of (t, x). For a marginal basis, gⱼ(x) = Σβⱼᵢbⱼᵢ(x), where bⱼᵢ are known functions and βⱼᵢ are coefficients to estimate. For a tensor product involving time t and covariates x₁ and x₂, gⱼ(t, x₁, x₂) = ΣΣΣβᵢₜ,ᵢ₁,ᵢ₂bₜᵢₜ(t)bₓ₁ᵢ₁(x₁)bₓ₂ᵢ₂(x₂). The key element omitted here is the [BLANK], which controls the trade-off between model fit and model smoothness.",
    "gold_answer": "smoothing parameters (λₘ). These parameters are crucial as they determine the extent to which the model penalizes roughness in the fitted functions, thus balancing the fit to the data against the smoothness of the model."
  },
  {
    "qid": "fill-in-the-blank-ds-827",
    "question": "In the context of censored samples from truncated normal distributions, the probability density function of a normal distribution with mean, m, and standard deviation, σ, truncated on the left at a fixed terminus, x₀, can be written as f(x) = (I₁σ√(2π))⁻¹exp{-[(x - m)²/(2σ²)]} for x₀ ≤ x ≤ ∞, and f(x) = 0 for x < x₀. Here, I₁ = I(ξ₁) represents the proportion of the complete distribution retained after truncation, where ξ₁ is the left terminus in standard units of the complete distribution, defined as ξ₁ = [BLANK].",
    "gold_answer": "(x₀ - m)/σ. This formula calculates the truncation point in standard units, which is essential for determining the proportion of the distribution that remains after truncation."
  },
  {
    "qid": "fill-in-the-blank-ds-419",
    "question": "In the context of extreme value analysis, the generalized extreme value (GEV) distribution is used to model the behavior of extreme events. The GEV distribution is characterized by three parameters: location (μ), scale (σ), and shape (ξ). The shape parameter ξ determines the heaviness of the tail, where ξ < 0 corresponds to distributions with a finite upper end point, and ξ ≥ 0 corresponds to distributions with an infinite upper end point. The formula for the GEV distribution is given by: exp[-{1 + ξ((x - μ)/σ)}+^(-1/ξ)]. What is the term inside the curly braces {} that is raised to the power of -1/ξ?",
    "gold_answer": "1 + ξ((x - μ)/σ). This term is crucial as it defines the behavior of the tail of the distribution, influencing how extreme values are modeled."
  },
  {
    "qid": "fill-in-the-blank-ds-489",
    "question": "In the context of elliptical distributions, the sample covariance is not an efficient estimator unless the condition [BLANK] is met.",
    "gold_answer": "E(R^2) = 8. This condition is crucial for the sample covariance to be efficient in the general case of elliptical distributions, as it relates to the variance of the underlying random variable R."
  },
  {
    "qid": "fill-in-the-blank-ds-1050",
    "question": "A key assumption for the convergence of empirical Gittins indices to the true Gittins indices is that the transition probability pᵏ(x, x') is [BLANK] for all k ∈ K and x, x' ∈ χᵏ.",
    "gold_answer": "greater than zero. This ensures that every state is accessible from any other state, facilitating the estimation process and ensuring the Markov chains are ergodic."
  },
  {
    "qid": "fill-in-the-blank-ds-1226",
    "question": "In certain longitudinal clinical studies, two ordinal variables (e.g., a therapeutic effect rating and a side-effect rating) are repeatedly measured at scheduled visits but may be missing for some patients who do not return. If we let Yᵢ = (Yᵢ₁, ..., Yᵢⱼ) represent the patient’s responses over time, one method to jointly analyze both ordinal outcomes and their missingness is to factorize the likelihood into a product of the outcome model and the missingness mechanism. In selection modeling, this can be expressed as f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK], where Rᵢ denotes the missingness indicators. Which missingness-related term is deliberately omitted in this equation?",
    "gold_answer": "f(Rᵢ | Yᵢ). We remove it to highlight that, in a selection framework, the distribution of the missingness (Rᵢ) may depend on the observed and unobserved outcomes (Yᵢ), which is precisely what distinguishes selection models from pattern–mixture approaches."
  },
  {
    "qid": "fill-in-the-blank-ds-615",
    "question": "The pair correlation function of a log Gaussian Cox process is given by g(s) = exp(σ²r(s)), where r(s) is the [BLANK] function of the underlying Gaussian process.",
    "gold_answer": "correlation"
  },
  {
    "qid": "fill-in-the-blank-ds-3321",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK]. This assumption is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by stating that once we condition on the observed responses, the missingness no longer depends on the unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-2964",
    "question": "In the context of nonparametric quantile regression for VaR prediction, the Double Kernel Local Linear (DKLL) estimator is chosen because it localizes the data in both the x- and y-direction, which leads to smoother estimates. The estimator is defined as the inverse of a conditional distribution function, and for notational convenience, observations are assumed to be drawn from an underlying bivariate distribution F(x,y) with density f(x,y). The extension to the multivariate case is straightforward but requires a more tedious notation. The estimator is defined as the inverse of a conditional distribution function as in (2.1). Throughout this section, quantiles of return distributions are discussed, so that VaR corresponds to the negative quantile. A generic nonparametric method of estimating a conditional distribution F(y|x) is given by [BLANK], where I(·) is an indicator function and the weights w_t(x) are positive and sum up to one.",
    "gold_answer": "tilde{F}(y|x) = sum_{t=1}^n w_t(x) I(Y_t ≤ y). This formula represents a generic nonparametric method for estimating a conditional distribution function, highlighting the flexibility of nonparametric approaches in statistical estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-450",
    "question": "In the additive non-parametric logistic regression model described, the form is given as logit $[P(\\mathbf{x})]=\\alpha+$ $\\Sigma f_{j}(x_{j})$, where $P(\\mathbf{x})=P(y=1\\mid\\mathbf{x})$ for a 0-1 variable $y$, and $\\textbf{x}$ is a vector of $p$ covariates. The functions $f_{j}$ can be chosen to be linear, general non-linear, or step functions for discrete covariates. The functions are estimated simultaneously using the [BLANK] algorithm.",
    "gold_answer": "local scoring. This algorithm is a generalization of the iteratively reweighted least squares algorithm (IRLS) for estimating the parameters in generalized linear models, adapted for non-parametric function estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-2954",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yᵢⱼ can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where αᵣ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "bᵢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-3244",
    "question": "In the context of hypothesis testing for a bivariate normal distribution with missing observations, the test statistic that discards additional X observations and uses only the pairs (Xᵢ, Yᵢ) for i=1,2,...,n is known as [BLANK]. This test is proven to be admissible for testing H₀: μ=0 vs. H₁: μ≠0.",
    "gold_answer": "Hotelling's T² test. The missing element is highlighted to emphasize the specific test discussed in the paper, which is admissible under the given conditions."
  },
  {
    "qid": "fill-in-the-blank-ds-2008",
    "question": "In the estimation of population parameters from capture-recapture data, the ratio method of maximizing the likelihood function involves equating L(θ) to [BLANK].",
    "gold_answer": "L(θ-1). This approach, used by Darroch (1958), involves setting the difference in log likelihoods to zero to find maximum likelihood estimates."
  },
  {
    "qid": "fill-in-the-blank-ds-635",
    "question": "The penalized least squares approach with smoothly clipped absolute deviation penalty has been consistently demonstrated to be an attractive regression shrinkage and selection method. It not only automatically and consistently selects the important variables, but also produces estimators which are as efficient as the [BLANK] estimator.",
    "gold_answer": "oracle. The oracle estimator is a theoretical benchmark that assumes knowledge of the true model, and the smoothly clipped absolute deviation method's estimators achieve similar efficiency under certain conditions."
  },
  {
    "qid": "fill-in-the-blank-ds-2113",
    "question": "In the context of biclustering analysis of functionals via penalized fusion, the objective function for estimation without clustering includes a lack-of-fit term and a penalty term. The penalty term is given by [BLANK], where γ₁ is a non-negative tuning parameter and D is a matrix representing the second order differential operator.",
    "gold_answer": "½γ₁βᵢⱼᵀDβᵢⱼ. This penalty term controls the smoothness of the estimation by penalizing the second derivative of the functional estimates, encouraging smoother functions."
  },
  {
    "qid": "fill-in-the-blank-ds-3323",
    "question": "In the context of constructing a joint confidence region for an overall ranking of populations, the main result states that for each population k, the rank r_k is contained in the set {|Λ_Lk| + 1, |Λ_Lk| + 2, ..., |Λ_Lk| + |Λ_Ok| + 1}, where Λ_Lk and Λ_Ok are defined based on the overlap of confidence intervals. What critical element is missing from this description that defines Λ_Lk and Λ_Ok?",
    "gold_answer": "The definition of Λ_Lk as the set of populations j where U_j ≤ L_k, and Λ_Ok as the set of populations j where U_j > L_k and U_k > L_j. This is crucial for understanding how the overlap or lack thereof between confidence intervals influences the possible ranks of each population."
  },
  {
    "qid": "fill-in-the-blank-ds-3493",
    "question": "In the context of constructing a confidence region with prescribed maximum width and coverage probability for linear regression parameters, the sequential procedure's sample size N depends on d, and as d approaches 0, N(d) approaches infinity almost surely. The goal is to find a region R in p-dimensional Euclidean space such that P{β ∈ R} = α and the maximum diameter of R ≤ 2d. The missing element in the equation representing this goal is [BLANK].",
    "gold_answer": "P{β ∈ R} = α. This equation is fundamental as it sets the coverage probability requirement for the confidence region R, ensuring that the true parameter vector β lies within R with probability α."
  },
  {
    "qid": "fill-in-the-blank-ds-566",
    "question": "In the context of interval-censored failure time data analysis, the joint distribution of the failure time T and the censoring interval length W given covariates Z can be expressed using a copula function as K(t, w) = Cα(FT(t), FW(w)), where FT and FW are the marginal distributions of T and W given Z, respectively. The term [BLANK] in this equation represents the association parameter that captures the dependence between T and W.",
    "gold_answer": "α. This term is crucial as it quantifies the degree of dependence between the failure time and the censoring interval length, which is essential for accurately modeling and analyzing interval-censored data when the censoring mechanism is dependent on the failure time."
  },
  {
    "qid": "fill-in-the-blank-ds-1476",
    "question": "The convergence of the test statistic towards its asymptotic distribution is relatively slow. Thus, [BLANK] methods based on random samples are suggested to determine the corresponding critical values.",
    "gold_answer": "Monte Carlo"
  },
  {
    "qid": "fill-in-the-blank-ds-3576",
    "question": "An unbiased estimate of the total of a variate $y$ may then be obtained from formula (1) by putting $n$ equal to 2, and replacing $x_{i}$ by $\\nabla_{\\vec{p}}\\prime_{i}$ and $\\Sigma(x)$ by [BLANK].",
    "gold_answer": "1. This omission emphasizes the normalization step in obtaining unbiased estimates by adjusting the size measures."
  },
  {
    "qid": "fill-in-the-blank-ds-3098",
    "question": "In selection modeling, the joint analysis of both ordinal outcomes and their missingness can be expressed as f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK], where Rᵢ denotes the missingness indicators.",
    "gold_answer": "f(Rᵢ | Yᵢ). This term highlights the dependency of the missingness distribution on the observed and unobserved outcomes, distinguishing selection models from pattern–mixture approaches."
  },
  {
    "qid": "fill-in-the-blank-ds-1148",
    "question": "The controlled direct effect (CDE), the natural direct effect (NDE), and the natural indirect effect (NIE) are defined in the context of causal mediation analysis. For a treatment level x* and a control level x of treatment X, the natural direct effect is defined as E(Yx*Mx - YxMx). The key condition required to identify the natural direct and indirect effects, besides randomization of treatment X, is [BLANK].",
    "gold_answer": "Yx'm ⊥⊥ Mx | (X=x, U) for all x, x', and m. This condition, known as the sequential ignorability assumption, ensures that the mediator's effect on the outcome is not confounded by unobserved variables conditional on the treatment and observed covariates."
  },
  {
    "qid": "fill-in-the-blank-ds-467",
    "question": "In the context of analyzing experimental data with potential wild points, the $L_{1}$ approximation is theoretically justified over $L_{2}$ approximation because it minimizes the sum of the absolute deviations, which is represented by the formula: $\\sum_{i=1}^{N}\\mid y_{i}-L(A,x_{i})\\mid$. This approach is particularly effective when the data contains [BLANK], as it tends to ignore or lightly weight these points.",
    "gold_answer": "wild points. The $L_{1}$ approximation's superiority in handling wild points is due to its robustness against outliers, minimizing the impact of these extreme values on the overall approximation."
  },
  {
    "qid": "fill-in-the-blank-ds-3403",
    "question": "In the construction of non-orthogonal unsaturated main effect plans for any $k^{n}$ factorial, when $k$ is even, the method consists of forming $k^{n}/2$ pairs of treatment combinations. What property must these pairs satisfy?",
    "gold_answer": "Differences within pairs are clear of 'even' effects and sums are clear of 'odd' effects. This property is crucial for the construction method to ensure that the main effect plans can estimate the desired effects without interference from the other type of effects."
  },
  {
    "qid": "fill-in-the-blank-ds-1304",
    "question": "In the context of bias correction for estimators defined by an unbiased linear estimating equation, the new formula for the exact bias is expressed as a [BLANK]. What term describes the nature of this sequence?",
    "gold_answer": "convergent sequence. This term is used to describe the sequence because it approaches a specific limit as the number of terms increases, ensuring the formula's accuracy and computational feasibility."
  },
  {
    "qid": "fill-in-the-blank-ds-3074",
    "question": "The MADD dissimilarity index uses a scaling factor of [BLANK] to account for the increase in interpoint distances with dimensionality.",
    "gold_answer": "1/√p. This scaling adjusts for the fact that distances in high-dimensional spaces grow at a rate proportional to the square root of the dimensionality."
  },
  {
    "qid": "fill-in-the-blank-ds-2857",
    "question": "A collection of random variables $(Y_{1},...,Y_{b})$ is said to have a Dirichlet distribution with parameters $(\\mathfrak{v}_{1},...,\\mathfrak{v}_{b};\\mathfrak{v}_{b+1})$ written as $D(\\mathfrak{v}_{1},...,\\mathfrak{v}_{b};\\mathfrak{v}_{b+1})$ if they have the joint density ${\\frac{I(v_{1}+\\cdots+\\nu_{b+1})}{I(v_{1})\\cdots I(v_{b+1})}}\\left(\\prod_{1}^{b}y_{i}^{v_{i}-1}\\right)(1-y_{1}\\cdots-y_{\\mathsf{b}})^{v_{b+1}-1}$ over the $\\pmb{b}$ dimensional simplex $S_{b}=\\{(y_{1},...,y_{b}){:}y_{i}\\geqslant0,\\quad i=1,...,b,$ $\\begin{array}{r}{\\sum_{1}^{b}y_{i}\\leqslant1\\}}\\end{array}$ and zero outside $\\pmb{S_{b}}$ . This is a $b$ variate generalization of the familiar beta density. For an elementary exposition on Dirichlet distributions and some properties, see Wilks [11] and for a more detailed discussion as well as tables, see Sobel et al. [9]. Incomplete Dirichlet integrals are strongly connected with the multinomial and negative multinomial probabilities and these relations are explored in Olkin and Sobel [7] and Khatri and Mitra [5]. The integral $J_{p}^{(b)}(1,n)$ is defined for $0<p<1/b$ as the probability of the event $\\{Y_{i}>p,i=1,...,b\\}$ and is given by $J_{p}^{(b)}(1,n)={\\frac{n!}{(n-b)!}}\\int_{p}^{1}\\cdot\\stackrel{\\cdot\\cdot\\cdot}{\\scriptscriptstyle\\downarrow^{b}y_{1}\\leqslant1\\atop1}\\int_{p}^{1}\\left(1-\\sum_{1}^{b}y_{i}\\right)^{n-b}\\prod_{1}^{b}d y_{i}$. For $b=0$, $J_{p}^{(0)}(1,n)$ is defined to be equal to 1 if $\\pmb{p}$ is positive and zero otherwise. A recurrence formula for $\\pmb{\\cal J}_{p}^{(b)}(1,n)$ is obtained by integrating $y_{b}$ from $p$ to $1-\\textstyle\\sum_{i}^{b-1}y_{i}$ and transforming $y_{i}$ to $\\big(y_{i}/(1-p)\\big)$. Thus, $J_{p}^{(b)}(1,n)=(1-p)^{n}J_{p/(1-p)}^{(b-1)}(1,n)$. Using this relation repeatedly gives $J_{p}^{(b)}(1,n)=\\langle1-b p\\rangle^{n}$. Which mathematical operation is used to derive the final expression for $J_{p}^{(b)}(1,n)$ from the recurrence relation?",
    "gold_answer": "Iteration. The final expression for $J_{p}^{(b)}(1,n)$ is derived by repeatedly applying the recurrence relation until the base case is reached, demonstrating how the integral simplifies through iterative substitution."
  },
  {
    "qid": "fill-in-the-blank-ds-207",
    "question": "The adaptive ABC-MCMC algorithm adjusts the tolerance parameter δ to achieve a target acceptance rate α∗. The update rule for the log tolerance is given by logδk←logδk−1+γk(α∗−Ak), where Ak is the acceptance indicator at iteration k, and [BLANK] is a sequence of decreasing step sizes.",
    "gold_answer": "γk. The sequence γk controls the rate at which the tolerance parameter δ is adjusted, ensuring convergence to the target acceptance rate α∗."
  },
  {
    "qid": "fill-in-the-blank-ds-1995",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a pattern–mixture perspective, where we distinguish subpopulations according to their missingness patterns. Suppose we rely on the ‘neighboring case missing value’ approach (NCMV) so that missing values in a partially observed sequence borrow information only from the next identified pattern. If we consider the subpopulation distribution f(Y | pattern), we multiply this by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern (f(pattern)). We omit it to underscore that each pattern has a distinct distribution of Y, and combining them in a pattern–mixture approach requires weighting by the relative frequency of each pattern."
  },
  {
    "qid": "fill-in-the-blank-ds-2364",
    "question": "The PC-algorithm starts from a complete, undirected graph and deletes recursively edges based on [BLANK] decisions. This yields an undirected graph which can then be partially directed and further extended to represent the underlying DAG.",
    "gold_answer": "conditional independence. This is omitted to highlight the fundamental operation of the PC-algorithm, which relies on testing conditional independence to iteratively remove edges from the complete graph."
  },
  {
    "qid": "fill-in-the-blank-ds-1676",
    "question": "In the context of nonlinear mixed effects models for repeated measures data, the test statistic for Neyman's partial score test under the null hypothesis has asymptotically a [BLANK] distribution.",
    "gold_answer": "χ². This is because, under the null hypothesis, the test statistic follows a chi-square distribution with degrees of freedom equal to the number of independent restrictions over the parameters."
  },
  {
    "qid": "fill-in-the-blank-ds-1906",
    "question": "In the Bayesian methodology for multiple testing that asymptotically guarantees type I error control, the proposed approach is more powerful than the method of [BLANK], which is commonly utilized in practice as a more powerful alternative to the ubiquitous Bonferroni correction.",
    "gold_answer": "Holm (1979). This is highlighted to emphasize the comparative advantage of the Bayesian approach in controlling type I error while maintaining higher power across various correlations between outcomes."
  },
  {
    "qid": "fill-in-the-blank-ds-1333",
    "question": "In the construction of the extensively corrected score, the first step involves [BLANK], which is crucial for generating independent replicates of the surrogate measurements.",
    "gold_answer": "duplicating. This step allows for the creation of multiple independent replicates of the surrogate measurements, enabling the subsequent steps of weighing, correcting, and averaging to construct an unbiased estimating function."
  },
  {
    "qid": "fill-in-the-blank-ds-293",
    "question": "In the context of nonparametric estimation of a periodic function, the convergence rate of the estimator of periods is given as [BLANK], where n denotes the number of observations made.",
    "gold_answer": "$O(n^{-3/2})$. This rate indicates that the estimator of periods converges at a parametric rate, which is faster than typical nonparametric rates, highlighting the efficiency of the method in estimating the period of a periodic function from noisy observations."
  },
  {
    "qid": "fill-in-the-blank-ds-1443",
    "question": "A key assumption in the IRT approach for factor analysis with ordinal data is that, conditional on the latent variables, the observed variables are [BLANK]. This assumption simplifies the model by allowing the joint probability of the observed variables to be expressed as the product of their individual conditional probabilities.",
    "gold_answer": "independent. This conditional independence assumption is fundamental to the IRT approach, enabling the factorization of the joint probability distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-2318",
    "question": "A key assumption in the smooth function model is that the parameter of interest $\\theta$ and its estimator $\\hat{\\theta}$ can be expressed as $\\theta = g(\\mu)$ and $\\hat{\\theta} = g(\\overline{X})$, where $\\mu$ is the mean of the distribution $F$ and $\\overline{X}$ is the sample mean. The function $g$ is assumed to be [BLANK] in an open neighbourhood of $\\mu$.",
    "gold_answer": "continuously differentiable up to a sufficiently high order. This ensures the applicability of the smooth function model by guaranteeing the necessary smoothness conditions for the function $g$."
  },
  {
    "qid": "fill-in-the-blank-ds-59",
    "question": "In the study of the inheritance of longevity, the correlation in the duration of life is greater between two brothers or two sisters than between brother and sister, highlighting that inheritance is stronger in members of the same sex. The daughter seems to be more closely related in duration of life to her parents than the son, which is somewhat opposed to the result obtained for [BLANK].",
    "gold_answer": "eye-colour. This opposition is explicable by noting how much more liable the male is to accidental death, thus intensifying the nonselective death-rate in his case."
  },
  {
    "qid": "fill-in-the-blank-ds-2681",
    "question": "In the context of split-plot designs, the variance–covariance matrix for the response vector y is given by V = σ²εI_N + σ²γZZ′ = σ²ε(I_N + ηD), where η = σ²γ/σ²ε. The matrix D is block-diagonal, implying that observations in the same whole plot are correlated, while those from different whole plots are not. The matrix D is constructed using vectors of ones and zero matrices, specifically D = [1_n1′_n 0_n ... 0_n; 0_n 1_n1′_n ... 0_n; ...; 0_n 0_n ... 1_n1′_n], where 1_n is an n-dimensional vector of ones and 0_n is an n×n zero matrix. The term [BLANK] represents the ratio of the variance components in the model.",
    "gold_answer": "η = σ²γ/σ²ε. This ratio quantifies the relative importance of the whole-plot variance component compared to the error variance component in the model."
  },
  {
    "qid": "fill-in-the-blank-ds-1866",
    "question": "In the heterogeneous mixing model of infectious diseases, the force of infection for class (x,u) is given by λ(t|x,u) = ∫β(x,u;y,v)I(t|y,v)dF(y,v). For the case where the transmission parameter can be factorized as β(x,u;y,v) = β(x,u)β(y,v), the hazard rate h(t|x,u) reduces to β(x,u)h₀(t), where h₀(t) is known as the [BLANK].",
    "gold_answer": "baseline hazard function. This term is crucial as it represents the hazard rate for a hypothetical subgroup with a mixing factor equal to one, scaling up based on the subgroup's contact with others."
  },
  {
    "qid": "fill-in-the-blank-ds-868",
    "question": "The proof of $L^{2}$ consistency for the kth nearest neighbour distance estimator of the Shannon entropy for an arbitrary fixed $k\\geq1$ is provided. It is constructed the nonparametric test of goodness-of-fit for a class of introduced generalised multivariate Gaussian distributions based on a [BLANK] principle. The theoretical results are followed by numerical studies on simulated samples.",
    "gold_answer": "maximum entropy. This principle is crucial for constructing the test as it underpins the theoretical foundation for analyzing the goodness-of-fit for generalised multivariate Gaussian distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-587",
    "question": "The (mean-zero) EG density for a point $\\pmb{x}\\in\\mathbb{R}^{q}$ is given by $$ p_{\\mathrm{eg}}(\\pmb{x};\\pmb{\\Sigma},a,b):=\\frac{\\Gamma(q/2)}{\\pi^{q/2}\\Gamma(a)b^{a}|\\pmb{\\Sigma}|^{1/2}}\\big(\\pmb{x}^{\\top}\\pmb{\\Sigma}^{-1}\\pmb{x}\\big)^{a-q/2}\\exp\\bigl(-b^{-1}\\pmb{x}^{\\top}\\pmb{\\Sigma}^{-1}\\pmb{x}\\bigr), $$ where $\\Sigma\\succ0$ is the scatter matrix, and $a,b>0$ are scale and shape parameters. The EG density generalizes the Gaussian density, which corresponds to $a=[BLANK]$. What value of $a$ makes the EG density equivalent to the Gaussian density?",
    "gold_answer": "$a=q/2$. This is the value at which the additional elliptical factor $(\\pmb{x}^{\\top}\\pmb{\\Sigma}^{-1}\\pmb{x})^{a-q/2}$ becomes 1, simplifying the EG density to the Gaussian density."
  },
  {
    "qid": "fill-in-the-blank-ds-2920",
    "question": "In the context of polynomial histogram estimators, the first-order polynomial histogram estimator (Fophe) for a multivariate density f is given by g₁(x) = a₀ + aᵀx. The estimator satisfies two integral conditions over each bin Bℓ. The first condition is ∫Bℓ g₁(x)dx = nℓ/n. The second condition is ∫Bℓ x g₁(x)dx = [BLANK]. What is the missing term in the second condition?",
    "gold_answer": "nℓ/n x̄ℓ. This condition ensures that the estimator captures the local mean within each bin, aligning the polynomial's linear term with the data's average behavior in that region."
  },
  {
    "qid": "fill-in-the-blank-ds-2965",
    "question": "For estimating the parameters of the CAViaR models, an algorithm similar to the one proposed in the original paper is applied. A grid search is conducted by generating a large number of random vectors, the dimensions of which correspond to the number of model parameters. The five vectors which lead to the lowest values of the objective function (2.3) are selected and fed into a simplex optimization algorithm. The final parameter vector is chosen to be the one minimizing (2.3). Our new AR-TGARCH specification fits into this procedure. The objective function used in this context is [BLANK], where p denotes the probability level of the quantile being estimated, I(·) is the indicator function, and VaR_p^t(β) is the Value at Risk estimate at time t for probability level p.",
    "gold_answer": "min_β (1/n) sum_{t=1}^n [p - I(Y_t < -VaR_p^t(β))] (Y_t + VaR_p^t(β)). This objective function is crucial for estimating the parameters of CAViaR models, as it directly relates to the quantile regression framework, emphasizing the model's focus on accurately capturing the tail behavior of financial return distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-162",
    "question": "In the context of biplots, the approximation of the data matrix Y by AB^T is given by Y ≃ AB^T, where A and B are matrices of markers for the rows and columns of Y, respectively. The goodness of fit for this approximation is measured by the coefficient GF(Y, AB^T) = [BLANK]. What is the correct formula for GF(Y, AB^T)?",
    "gold_answer": "GF(Y, AB^T) = tr^2(Y^T AB^T) / {tr(Y^T Y) tr(B A^T A B^T)}. This formula measures the proportional goodness of fit of the biplot approximation to the data matrix Y, emphasizing the importance of the trace operations in assessing the fit."
  },
  {
    "qid": "fill-in-the-blank-ds-1795",
    "question": "In the context of EM-type algorithms for computing restricted MLEs in multivariate normal distributions, the key idea is to introduce a sequence of latent variables such that the complete-data model belongs to the [BLANK], resulting in a simple E-step and an explicit M-step.",
    "gold_answer": "exponential family. This is crucial because it simplifies the estimation process by leveraging the properties of the exponential family, which facilitates both the expectation (E-step) and maximization (M-step) steps in the EM algorithm."
  },
  {
    "qid": "fill-in-the-blank-ds-1116",
    "question": "The method is designed to answer questions arising in biophysical research on nanoclusters of Ras proteins. It takes into account the presence of disturbing metacluster structures as well as non-clustering objects, both common among Ras clusters. Its focus lies on estimating the proportion of points lying in clusters, the mean cluster size and the mean cluster radius without depending on prior knowledge of the [BLANK].",
    "gold_answer": "parameters. The method does not require prior knowledge of the parameters, making it versatile for various applications."
  },
  {
    "qid": "fill-in-the-blank-ds-2852",
    "question": "In generalized linear mixed models (GLMMs), the variance of the pseudo-data Y_i* in the linear mixed model approximation is given by Var(Y_i*) ≈ Δ_i Z_i D Z_i' Δ_i' + Σ_i, where Δ_i is [BLANK].",
    "gold_answer": "the diagonal matrix of derivatives ∂μ_i/∂η_i evaluated at b_i = 0. This matrix plays a crucial role in the approximation by linking the mean and the linear predictor through the link function."
  },
  {
    "qid": "fill-in-the-blank-ds-897",
    "question": "In the context of two-dimensional Functional Time Series, the prediction band for a future observation Y_{T+1} is defined as {y ∈ H: y(u, v) ∈ [g_{I_1}(u, v; X_{T+1}) ± k^s s_{I_1}(u, v)] ∀(u, v) ∈ [c, d] × [e, f]}, where g_{I_1} is a point predictor built from the training set I_1, and s_{I_1} is a [BLANK]. What term completes the definition of the prediction band?",
    "gold_answer": "modulation function. The modulation function s_{I_1} allows for prediction bands with non-constant width along the domain, adjusting the band's width based on the variability of the data in different parts of the domain."
  },
  {
    "qid": "fill-in-the-blank-ds-1227",
    "question": "The Hidden Mixture Transition Distribution (HMTD) model integrates refinements of the mixture model and the hidden Markov model, allowing the observed heterogeneity to be induced by one or several [BLANK].",
    "gold_answer": "latent factors. This answer highlights the core aspect of the HMTD model, which is its ability to model observed heterogeneity through underlying, unobserved factors."
  },
  {
    "qid": "fill-in-the-blank-ds-693",
    "question": "In the context of stochastic differential equations driven by fractional Brownian motion, the Skorokhod integral with respect to the fractional Brownian motion is not computable when the Hurst index H is not equal to [BLANK].",
    "gold_answer": "1/2. This is because the Skorokhod integral coincides with Itô’s integral only when H = 1/2, making it computable in that specific case."
  },
  {
    "qid": "fill-in-the-blank-ds-3607",
    "question": "In the evaluation of determinants for a class of patterned matrices, the determinant of a matrix $M = [D_{a_{i}} + \\alpha\\mathbf{b}\\mathbf{b}^{\\prime}]$ can be expressed as $\\Delta = \\left(1 + \\alpha\\sum_{i=1}^{n}\\frac{b_{i}^{2}}{a_{i}}\\right)\\prod_{i=1}^{n}a_{i}$. What critical element is missing from this formula?",
    "gold_answer": "The missing element is the condition that $a_{i} \\neq 0$ for all $i$. This condition is crucial because division by zero is undefined, and the formula assumes that all $a_{i}$ are non-zero to allow for the summation term."
  },
  {
    "qid": "fill-in-the-blank-ds-1821",
    "question": "An indirect estimation approach for elliptical stable distributions is presented. The auxiliary model is another elliptical distribution, the [BLANK] distribution. It has parameters that have a one-to-one relationship with those of the elliptical stable, making the proposed indirect approach particularly suitable.",
    "gold_answer": "multivariate Student-t. This choice is highlighted because the parameters of the multivariate Student-t distribution have a direct, one-to-one relationship with those of the elliptical stable distributions, facilitating the indirect estimation process."
  },
  {
    "qid": "fill-in-the-blank-ds-2833",
    "question": "The concept of substationarity is particularly useful in analyzing spatial point processes where the distribution is invariant under shifts in a subspace but may vary outside it, providing a bridge between [BLANK] and nonstationarity.",
    "gold_answer": "stationarity. This omission underscores substationarity's role in connecting the well-known concepts of stationarity and nonstationarity in spatial statistics."
  },
  {
    "qid": "fill-in-the-blank-ds-1993",
    "question": "In the method based on gamma distribution for constructing confidence intervals, the upper confidence limit is adjusted by a factor denoted as [BLANK], which can vary based on the approach taken.",
    "gold_answer": "w*. This factor is critical in determining the conservativeness of the confidence intervals constructed under the gamma distribution method."
  },
  {
    "qid": "fill-in-the-blank-ds-1926",
    "question": "The marginal distributions in the proposed model are modeled through semiparametric transformation models using [BLANK], with the proportional hazards or odds model being a special case.",
    "gold_answer": "sieves. This emphasizes the use of sieves for approximating the infinite-dimensional nuisance parameters in the marginal models, allowing for flexible modeling beyond the proportional hazards or odds models."
  },
  {
    "qid": "fill-in-the-blank-ds-1843",
    "question": "The total force of decrement in a multiple decrement table, denoted as μₓ⁽ᵗ⁾, is the sum of the forces of decrement for all causes, expressed as μₓ⁽ᵗ⁾ = [BLANK].",
    "gold_answer": "Σ μₓ⁽ʲ⁾(t) over all causes j. This summation aggregates the instantaneous rates of decrement from all causes to represent the total force of decrement acting on the population."
  },
  {
    "qid": "fill-in-the-blank-ds-1181",
    "question": "The null distribution of the maximum likelihood ratio test statistic for two upper outliers in an exponential sample is derived. The test statistic for labelled slippage, introduced by Barnett and Lewis (1978, Ch. 3), identifies the k largest values as the only possible discordant observations. The maximum likelihood ratio test in this case is equivalent to using the test statistic Tₖ = (yₙ₋ₖ₊₁ + yₙ₋ₖ₊₂ + ... + yₙ) / Σᵢ₌₁ⁿ yᵢ, a large value of which supplies evidence against H₀. For k=2, the null distribution of [BLANK] is obtained, critical values are tabulated and a simple inequality for the probability of wrongly rejecting H₀ is presented.",
    "gold_answer": "T₂. This is the test statistic specifically for testing two upper outliers in an exponential sample, as detailed in the paper."
  },
  {
    "qid": "fill-in-the-blank-ds-15",
    "question": "When modeling correlated ordinal responses, a proportional odds mixed model may include random effects to account for individual heterogeneity. The model can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where the omitted term captures individual-specific deviations.",
    "gold_answer": "bᵢ (the random intercept). This term is essential for modeling the correlation within each subject's repeated measurements, accounting for the variability not explained by the fixed effects alone."
  },
  {
    "qid": "fill-in-the-blank-ds-2321",
    "question": "In the Gamma-frailty proportional hazards model for bivariate interval-censored data, the conditional cumulative hazard function for Tj, given the frailty η, is given by Aj(t|x,η) = A0j(t)exp(x′βj)η, for j=1,2. The frailty is assumed to follow a gamma distribution with shape and rate parameters both equal to [BLANK].",
    "gold_answer": "ν. The frailty parameter ν controls the dependence structure between the two failure times, with smaller values indicating stronger dependence."
  },
  {
    "qid": "fill-in-the-blank-ds-656",
    "question": "One of the sample allocation methods mentioned is the [BLANK] allocation, where each stratum sample size is the same.",
    "gold_answer": "equal"
  },
  {
    "qid": "fill-in-the-blank-ds-3261",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the validity of likelihood-based or multiple-imputation methods without explicitly modeling the dropout process."
  },
  {
    "qid": "fill-in-the-blank-ds-3071",
    "question": "The parametric bootstrap is a distribution-free method of assessing sampling variability based on resampling from the empirical distribution; the parametric bootstrap resamples from a fitted [BLANK] model.",
    "gold_answer": "parametric. The blank is filled with 'parametric' to specify that the parametric bootstrap involves resampling from a model that has been fitted to the data, distinguishing it from non-parametric methods that resample directly from the empirical distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-2016",
    "question": "The null hypothesis H that π_{ijkl}^{ABCD} = π_{ik}^{AC}π_{jl}^{BD} can be expressed in terms of two sub-hypotheses, H_a and H_b, where H_a states that π_{ijk}^{ABC} = π_{ik}^{AC}, and H_b states that π_{ijkl}^{ABCD} = [BLANK].",
    "gold_answer": "π_{jl}^{BD}. This decomposition simplifies the testing of the overall hypothesis H by breaking it down into more manageable parts."
  },
  {
    "qid": "fill-in-the-blank-ds-2454",
    "question": "In the context of nonlinear prediction theory, the functional $F(f) = N_{\\phi}(f_0 - f)$ assumes its minimum exactly once on a set $C$ whenever $C$ is sequentially complete in the topology of $\\sigma(L^{\\phi}(\\mathcal{X}), \\mathcal{M}^{\\psi}(\\mathcal{X}^{*}))$. This uniqueness is guaranteed by the property of $L^{\\Phi}(\\Sigma, \\mathcal{X})$ being [BLANK].",
    "gold_answer": "rotund. This property ensures that the functional $F(\\cdot)$ on $C$ has a unique minimum, highlighting the importance of the space's strict convexity in guaranteeing uniqueness in optimization problems."
  },
  {
    "qid": "fill-in-the-blank-ds-1886",
    "question": "The algorithm computes a distribution-free confidence interval for the median in a one-sample problem, the median difference in a paired sample problem, the difference in the location parameters (shift parameter) in a two-sample problem, and the ratio of the [BLANK] in a two-sample problem.",
    "gold_answer": "scale parameters. This is omitted to highlight the algorithm's capability to handle not just location but also scale differences between two samples, broadening its applicability in statistical analysis."
  },
  {
    "qid": "fill-in-the-blank-ds-889",
    "question": "In the context of tensor regression, the Frobenius norm of a tensor B is defined as [BLANK], which is the square root of the sum of the squares of all its elements.",
    "gold_answer": "√(∑_{i1,...,id}b_{i1...id}^2). This definition is fundamental for measuring the magnitude of tensors in regression problems, analogous to the Euclidean norm for vectors."
  },
  {
    "qid": "fill-in-the-blank-ds-2802",
    "question": "In the analysis of factorial experiments where the effects of one factor are assumed to be proportional at different levels of another factor, the expected effect of the combination of level i of factor A with level j of factor B can be expressed in the form [BLANK]. Which formula correctly represents this expected effect?",
    "gold_answer": "a_i c_j + b_j. This formula captures the proportional effect of factor A at different levels of factor B, where a_i represents the effect of level i of factor A, c_j are the weights for factor B levels, and b_j represents the effect of level j of factor B."
  },
  {
    "qid": "fill-in-the-blank-ds-2142",
    "question": "The singular value decomposition (SVD) of the data matrix Y is used in factor analysis to obtain estimates of the factors and loadings by minimizing the [BLANK].",
    "gold_answer": "reconstruction error. The SVD decomposes Y into components that capture the most significant patterns or variations in the data, providing a low-rank approximation that minimizes the difference between the original data and the model's reconstruction."
  },
  {
    "qid": "fill-in-the-blank-ds-2584",
    "question": "In the context of functional data analysis, the problem of feature selection is addressed by identifying a small subset of functions that can 'better explain' the model. The aim is to highlight the most important features by focusing on a statistical method such as classification, regression, or [BLANK].",
    "gold_answer": "principal components. This is omitted to emphasize the variety of statistical methods that can be applied to functional data analysis, with principal components being a key method for dimensionality reduction and feature extraction."
  },
  {
    "qid": "fill-in-the-blank-ds-1297",
    "question": "In the context of testing for equality of mean ranks between two groups, the proposed statistic is defined as [BLANK]. What is the correct term to fill in the blank?",
    "gold_answer": "ℓ=Σ(k₁−l₁)². This statistic is used to compare the mean ranks between two groups, highlighting the differences in their rankings."
  },
  {
    "qid": "fill-in-the-blank-ds-272",
    "question": "The incomplete beta function can be expressed as a contour integral, and its inverse can be represented by a quickly converging series. The equation for solving the incomplete beta function is given by $I_{x}(p,q)=\\frac{\\displaystyle{\\int_{0}^{x}t^{p-1}(1-t)^{q-1}d t}}{\\displaystyle{\\int_{0}^{1}t^{p-1}(1-t)^{q-1}d t}}=P$. To find either $\\pmb{\\mathcal{P}}$ or ${\\pmb x}$, the result is found in terms of percentage points of the [BLANK] distribution.",
    "gold_answer": "$x^{2}$ (chi-squared). This is omitted to highlight the distribution used to find the percentage points for solving the incomplete beta function equation."
  },
  {
    "qid": "fill-in-the-blank-ds-2034",
    "question": "The practice of interring artifacts with the body had died out by the [BLANK] century, making graveyards of that period of little interest to archaeologists.",
    "gold_answer": "10th and 11th"
  },
  {
    "qid": "fill-in-the-blank-ds-1058",
    "question": "In the context of outlier detection in networks with missing links, the proposed algorithm is designed to detect outliers and simultaneously predict missing links under the assumption that the matrix of connection probabilities can be decomposed into a low-rank component and a column-wise sparse component. The low-rank component represents the connectivity pattern of inliers, while the column-wise sparse component corresponds to outliers. The key assumption regarding the outliers is that their number is small compared to the size of the network, which is formalized by stating that the matrix representing the outliers is [BLANK]. What term describes the sparsity condition of the outlier matrix?",
    "gold_answer": "column-wise sparse. This term is used to highlight that the matrix representing the outliers has a small number of non-zero columns, indicating that only a few nodes (the outliers) have anomalous connection patterns compared to the majority of nodes (the inliers)."
  },
  {
    "qid": "fill-in-the-blank-ds-133",
    "question": "In the context of the Johnson system of probability distributions, the variable x has an S_B distribution if z = η + δ sinh⁻¹((x - ξ)/λ), where z is a unit normal variable. The parameters η, δ, ξ, and λ are to be determined from the first four moments of an observed distribution. For distributions not too far from normality, the problem reduces to determining ω and Ω from given values of β₁ and γ₂, where ω = e^(1/δ²) and Ω = η/δ. If the distribution is symmetrical about the origin, then β₁ = 0, implying Ω = 0, and γ₂ can be expressed in terms of ω as γ₂ = (1/8)(ω⁴ - 1)(ω⁴ + 3). Solving for ω gives ω = {√(4 + 2γ₂) - 1}^(1/2) = {√(2β₂ - 2) - 1}^(1/2). What is the value of ω when γ₂ = 0?",
    "gold_answer": "1. When γ₂ = 0, ω = {√(4 + 2*0) - 1}^(1/2) = {√4 - 1}^(1/2) = {2 - 1}^(1/2) = 1^(1/2) = 1. This indicates that the distribution is normal when γ₂ = 0, as ω = 1 corresponds to δ approaching infinity, making the transformation linear and thus the distribution normal."
  },
  {
    "qid": "fill-in-the-blank-ds-2966",
    "question": "In the application of nonparametric quantile regression with refinements from extreme value theory for VaR prediction, the peaks over threshold (POT) method is incorporated and applied to the standardized nonparametric quantile residuals. This results in an estimator that combines nonparametric quantile regression and extreme value theory (EVT). The POT method approximates large observations that exceed a high threshold reasonably well by the Generalized Pareto Distribution (GPD) with distribution function G_ξ,β(x). The shape parameter ξ and scale parameter β > 0 of the GPD can be consistently estimated if the threshold exceedances are independent, regardless of the true underlying distribution. The support of the GPD is x ≥ 0 when ξ ≥ 0 and 0 ≤ x ≤ -β/ξ if ξ < 0. The GPD is used to model the tail behavior of the distribution beyond a certain threshold, u, and the probability of a random variable Y exceeding u at most by x is given by [BLANK], where F is the distribution function of Y.",
    "gold_answer": "F_u(x) = P[Y - u ≤ x | Y > u] = [F(x + u) - F(u)] / [1 - F(u)]. This equation is fundamental in extreme value theory for modeling exceedances over a threshold, allowing for the estimation of tail behavior and the calculation of extreme quantiles, which are essential for accurate VaR prediction."
  },
  {
    "qid": "fill-in-the-blank-ds-373",
    "question": "In the model where the probability differential of a service completion is μσₙ dt when the queue contains n, and arrivals occur in a Poisson stream with parameter λ, the equivalent traffic intensity for the system σₙ = n + 1 is given by [BLANK].",
    "gold_answer": "1 - e^(-ρ). This is derived from the mean length of a steady-state service interval being λ⁻¹(1 - e^(-ρ)), where ρ = λ/μ."
  },
  {
    "qid": "fill-in-the-blank-ds-1696",
    "question": "The proposed Bayesian model stands on a two-level hierarchy where at the instance level, latent indicator variables are assigned to individual instances, each indicating whether the corresponding instance is responsible for the response of the bag it belongs to. These latent indicators are modeled through a [BLANK] regression model.",
    "gold_answer": "logistic. This model is used to explain the relationship between the explanatory variables of instances and their binary latent variables, indicating the probability of an instance being responsible for the bag's response."
  },
  {
    "qid": "fill-in-the-blank-ds-2848",
    "question": "In additive fuzzy clustering, the $n\\times K$ fuzzy memberships matrix $\\mathbf{P}$ is found by least-squares approximation of the off-diagonal elements of $\\mathbf{\\deltaQ}$ by inner products of rows of P. By contrast, kernelized fuzzy c-means is not least-squares and requires an additional [BLANK]. What is the additional requirement for kernelized fuzzy c-means?",
    "gold_answer": "fuzziness parameter. This parameter governs the degree of fuzziness in the clustering, distinguishing it from the least-squares approach of additive fuzzy clustering."
  },
  {
    "qid": "fill-in-the-blank-ds-1691",
    "question": "In the construction of a multivariate integer-valued trawl (MIVT) process, the cross-sectional dependence is entirely characterized through the [BLANK]. Which key element is this?",
    "gold_answer": "multivariate Lévy measure ν. This is because the cross-sectional dependence between the components of the MIVT process is determined by the joint distribution of jumps in the different components, which is specified by the multivariate Lévy measure."
  },
  {
    "qid": "fill-in-the-blank-ds-1497",
    "question": "In the context of the random-scale model, the peak-to-sum ratio P is modeled given M > u and P < 1 using a [BLANK] distribution.",
    "gold_answer": "scaled beta. This distribution is selected for its ability to model variables bounded within a specific range, fitting the constraints of the peak-to-sum ratio."
  },
  {
    "qid": "fill-in-the-blank-ds-208",
    "question": "In the context of off-policy evaluation in reinforcement learning, the efficiency bound for evaluating natural stochastic policies, such as tilting policies, is inflated compared to the case of a prespecified evaluation policy. This inflation is due to the fact that the evaluation policy itself is [BLANK].",
    "gold_answer": "unknown. This is because natural stochastic policies are defined in terms of deviations from the unknown behaviour policy, making the evaluation policy not prespecified and thus introducing additional uncertainty into the estimation process."
  },
  {
    "qid": "fill-in-the-blank-ds-3158",
    "question": "The algorithm described in the text is designed to compute the exact likelihood function of a stationary autoregressive-moving average (ARMA) process of order $(p,q)$. The equation defining the ARMA $(p,q)$ process is given by $w_{t}=\\phi_{1}w_{t-1}+...+\\phi_{p}w_{t-p}+a_{t}-\\theta_{1}a_{t-1}-...-\\theta_{q}a_{t-q}$, where $a_{t}$ are normally and independently distributed with zero mean and constant variance $\\sigma^{2}$. The likelihood is then given by the expression $(2\\pi)^{-n/2}\\left(\\prod_{\\scriptstyle t=1}^{n}\\sigma_{t}\\right)^{-1}\\exp\\left\\{-\\frac{1}{2}\\sum_{\\scriptstyle t=1}^{n}(\\hat{a}_{t}/\\sigma_{t})^{2}\\right\\}$, where $\\sigma_{t}=h_{t}\\sigma$ is the standard deviation of $\\widehat{\\pmb{a}}_{t}$. Maximizing this likelihood with respect to the parameters included in $\\phi$ and $\\pmb\\theta$ is equivalent to minimizing the sum of squares $\\left(\\prod_{t=1}^{n}h_{t}^{2}\\right)^{1/n}\\sum_{t=1}^{n}\\left(\\frac{\\hat{a}_{t}}{h_{t}}\\right)^{2}$. The maximum likelihood estimate of $\\sigma^{2}$ is then given by [BLANK], evaluated at the optimal parameter point.",
    "gold_answer": "$n^{-1}\\Sigma(\\widehat{a}_{t}/h_{t})^{2}$. This is the formula for the maximum likelihood estimate of the variance $\\sigma^{2}$ of the innovations $a_{t}$, evaluated at the parameter values that minimize the sum of squares."
  },
  {
    "qid": "fill-in-the-blank-ds-1748",
    "question": "In the simulation study comparing different methods for testing the effect of $X$ conditional on $Z$, the proposed conditional adaptive resampling test is shown to control the sizes reasonably well, except in cases with large $d$ and small $n$. The test based on direct estimation of the asymptotic critical value of the maximum-type statistic $T_{n}$, assuming independence of the noise and the covariates, gives inflated Type I error for the small sample size of $n=100$. This highlights the importance of the [BLANK] approach in small sample settings.",
    "gold_answer": "bootstrap. The bootstrap approach is crucial for accurately estimating the distribution of the test statistic in small samples, where asymptotic approximations may not hold."
  },
  {
    "qid": "fill-in-the-blank-ds-1267",
    "question": "In probit analysis, the relationship between the level of stimulant and the effect is completely specified by the mean and variance of the [BLANK] distribution of critical levels.",
    "gold_answer": "normal. This is omitted to emphasize the foundational assumption in probit analysis that the critical levels of stimulant among objects follow a normal distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-532",
    "question": "The MMC plot can be used with unbalanced, multifactor designs with [BLANK].",
    "gold_answer": "covariates. This is omitted to highlight the versatility of MMC plots in handling complex designs that include covariates, which is a key feature distinguishing them from simpler graphical methods."
  },
  {
    "qid": "fill-in-the-blank-ds-1535",
    "question": "Theorem 3 suggests that the distance between estimates $\\hat{\\mathcal{C}}^{(t)}$ and the true coefficient tensor $\\mathcal{C}$ is bounded by a term that decays geometrically plus a statistical error term, under the condition that the initialization error $\\mu$ is not too large and the restricted isometry property holds with a small enough constant $\\delta$. The statistical error term is proportional to $\\sqrt{(1/n)\\log n}$, indicating the convergence rate is [BLANK].",
    "gold_answer": "$\\sqrt{(1/n)\\log n}$. This rate demonstrates the statistical efficiency of the deep Kronecker network in estimating the true coefficient tensor from observed data."
  },
  {
    "qid": "fill-in-the-blank-ds-2597",
    "question": "The kernel estimate of a probability density function is defined by fₙ(x) = n⁻¹h⁻¹∑ⱼ₌₁ⁿK{h⁻¹(x - Xⱼ)}, where K is the [BLANK] and h is the smoothing parameter or window width.",
    "gold_answer": "kernel function. This is omitted to highlight the role of K in determining the shape of the estimate, while h controls the smoothness."
  },
  {
    "qid": "fill-in-the-blank-ds-3516",
    "question": "In the context of comparing alternative nested linear models, the global Bayes factor is defined as B₀₁ = p(y | M₀) / p(y | M₁), where p(y | Mᵢ) is the marginal likelihood under model Mᵢ. The global Bayes factor is closely related to the [BLANK] model choice criterion.",
    "gold_answer": "Schwarz. The global Bayes factor is shown to lead, essentially, to the Schwarz-type of criterion, exemplifying its role as a model choice criterion based on posterior probabilities."
  },
  {
    "qid": "fill-in-the-blank-ds-2150",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a pattern–mixture perspective, where we distinguish subpopulations according to their missingness patterns. If we consider the subpopulation distribution f(Y | pattern), we multiply this by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern (f(pattern))"
  },
  {
    "qid": "fill-in-the-blank-ds-2101",
    "question": "In addition to the asymptotic variance and covariance, some asymptotic moments of $r_{a b}$ , $(a\\ne b)$ ) are available with or without normality. Hotelling (1953, p. 212) gave the asymptotic central moments of $r_{a b}$ up to the sixth order under normality. Olkin and Pratt (1958, Eq. (2.7)) derived the asymptotically unbiased estimator of the population correlation coefficient up to order $n^{-1}$ in normal samples. Konishi (1978, Lemma; 1979a, Theorems 2.1 and 2.2; 1979b, Theorem 6.2) provided the Edgeworth expansions of the distribution of the function of the sample correlation matrix up to order $n^{-1}$ under normality. The normality assumption has been relaxed by some authors. Boik (1998, Eq. (19)) derived the matrix expression of the asymptotic biases of order $n^{-1}$ for the vectorized sample correlation matrix under nonnormality while Ogasawara (2004a, Eq. (A11)) gave the corresponding elementwise result which is convenient for actual computation. Kollo and Ruul (2003, Theorem 4) provided the Edgeworth expansion of the vectorized sample correlation matrix up to order $\\bar{n}^{-1/2}$ with the matrix expression of the associated cumulants up to the third order under nonnormality. The purpose of this paper is to have the Edgeworth expansion of $r_{a b}$ under nonnormality up to order $n^{-1}$ and to illustrate their results with comparison to the corresponding simulated distributions. It will be shown that the asymptotic expansion will improve the approximation to the true distribution with moderate sample sizes. The key to this improvement is the calculation of the [BLANK].",
    "gold_answer": "fourth cumulant. This is essential for accurately approximating the distribution of the sample correlation coefficient under nonnormality with the Edgeworth expansion."
  },
  {
    "qid": "fill-in-the-blank-ds-1916",
    "question": "In the Gaussian process accelerated failure time model, the log-survival time is modeled as T = Zβ + G + ε, where G ~ Nn{0, K(X, σ²)} and ε ~ Nn{0, σε²In}. The term [BLANK] represents the covariance function based on genome-wide gene expression data.",
    "gold_answer": "K(X, σ²). This term is crucial as it models the covariance structure of the log-survival times based on the similarity of genome-wide gene expression data among patients."
  },
  {
    "qid": "fill-in-the-blank-ds-692",
    "question": "In the context of model selection strategies for identifying most relevant covariates in homoscedastic linear models, the proposed method is based on an interpretable scaled quantity that measures a maximal relative error one makes by selecting covariates from a given set of all available covariates. This quantity is denoted as [BLANK].",
    "gold_answer": "D or D_alpha,n. The quantity measures the maximal relative error when selecting covariates, providing a basis for the proposed model selection procedures."
  },
  {
    "qid": "fill-in-the-blank-ds-2060",
    "question": "In the context of mixing random variables, the empirical distribution function $T_n(t)$ is defined as $T_n(t) = n^{-1}\\sum_{i=1}^{n}u(t-\\xi_i)$, where $u(t) = 1$ if $t \\geq 0$ and $0$ otherwise. The sequence $\\{\\xi_i\\}$ is said to be strong mixing if for all $A \\in M_1^k$ and $B \\in M_{k+n}^\\infty$, $|P(A \\cap B) - P(A)P(B)| \\leq [BLANK]$. What is the term that fills in the blank?",
    "gold_answer": "\\alpha(n). This term represents the strong mixing coefficient, which quantifies the dependence between events separated by n steps in the sequence."
  },
  {
    "qid": "fill-in-the-blank-ds-3187",
    "question": "In the context of linear state space models with known parameters, the Kalman filter (KF) generates best linear unbiased predictions of the underlying states together with their corresponding [BLANK].",
    "gold_answer": "Prediction Mean Square Errors (PMSE). This term is critical as it measures the uncertainty associated with the estimated states."
  },
  {
    "qid": "fill-in-the-blank-ds-836",
    "question": "In the model for aligning time series fragments, the equation Y_t = β + X_{t+J} + ε_t is used, where ε_t are independent and identically distributed with zero mean and finite variance σ². The term [BLANK] represents the unknown lag between the master series and the fragment to be aligned.",
    "gold_answer": "J. This term is crucial for determining the time shift needed to align the fragment with the master series, capturing the temporal discrepancy between them."
  },
  {
    "qid": "fill-in-the-blank-ds-2797",
    "question": "A univariate spline $S(x)$ of degree $\\mathbf{\\nabla}m$ with knots $\\{x^{i}\\},i=0,...,n$ is a function S $\\because R\\rightarrow R$ which is globally of continuity class $C^{m-1}$ , and on every interval between knots $(-\\infty,x^{0})$, $(x^{0},x^{1}),...,(x^{n-1},x^{n}),(x^{n},\\infty)$ is a polynomial of degree [BLANK].",
    "gold_answer": "m. The degree of the polynomial pieces between the knots is equal to the degree of the spline, which is m."
  },
  {
    "qid": "fill-in-the-blank-ds-3119",
    "question": "The POT stability of a univariate GPD is characterized by the property that for a random variable $U$ following a GPD $W$, the conditional probability $P(U>t x_{0} \\mid U>x_{0})$ is invariant to the choice of $x_{0}$. For a polynomial GPD, this probability equals $t^{\\alpha}$ for $t\\in[0,1]$. For a Pareto GPD, it equals $t^{-\\alpha}$ for $t\\geqslant1$, and for the exponential GPD, it equals $\\exp(-t)$ for $t\\geqslant0$. The key property that makes these distributions POT stable is the [BLANK] of the exceedance distributions to the threshold $x_{0}$.",
    "gold_answer": "invariance. This property is crucial for understanding the behavior of exceedances over thresholds in the context of generalized Pareto distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-784",
    "question": "In the partially linear regression model with responses missing at random, the conditional probability of observing the response given the covariates is denoted by [BLANK]. This assumption is crucial for the validity of the complete case analysis.",
    "gold_answer": "π(U,X). This term represents the probability that the response Y is observed given the covariates (U,X), which is essential for understanding the missingness mechanism in the model."
  },
  {
    "qid": "fill-in-the-blank-ds-2499",
    "question": "When the pdf $f(\\mathbf{x})$ is non-increasing in $\\left|x_{i}\\right|$ for $i=1,2,...,k$, the sphere of diameter $^d$ centred at the origin has the largest probability content compared to any other region of diameter at most $d$. This implies that a sphere of diameter $^d$ has the largest [BLANK] among the regions of diameter at most $d$.",
    "gold_answer": "volume. This is because the probability content is maximized for the sphere under the given conditions, and when considering the uniform distribution (where the pdf is constant), the probability content directly relates to the volume of the region."
  },
  {
    "qid": "fill-in-the-blank-ds-3328",
    "question": "In the context of Approximate Bayesian Computation (ABC), the true posterior is approximated by $p(\\theta|y)\\approx p(\\theta|s)$, where $s=s(y)=(s_{1},\\ldots,s_{d})^{\\top}$ is a low-dimensional vector of summary statistics. The approximate posterior itself is constructed as $\\begin{array}{r}{p(\\theta|s)\\approx\\int p(\\theta,s^{*}|s)d s^{*}}\\end{array}$, following standard kernel density estimation arguments. The form of this allows sampler-based ABC algorithms to sample from $p(\\theta,s^{*}|s)$ without direct evaluation of the likelihood. What term is used to describe the scale parameter in the standard smoothing kernel $K_{\\epsilon}(\\|u\\|)=K(\\|u\\|/\\epsilon)/\\epsilon$?",
    "gold_answer": "epsilon. This term controls the bandwidth of the kernel, influencing the degree of smoothing applied in the approximation of the posterior distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-226",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK].",
    "gold_answer": "Missing at random (MAR)"
  },
  {
    "qid": "fill-in-the-blank-ds-3622",
    "question": "In the context of testing hypotheses about changes in the center of location for truncated data, the test function proposed by David and Johnson for the one-sample case is denoted as [BLANK]. What is the correct symbol for this test function?",
    "gold_answer": "T_a. This symbol is used to represent the test function based on the difference of sample quantiles in the one-sample case, highlighting its distinction from other test functions discussed in the paper."
  },
  {
    "qid": "fill-in-the-blank-ds-98",
    "question": "In the context of dependent competing risks, the joint density of survival time T and censoring time C is denoted by f(t, s). The assumption that the conditional death hazard at instant t differs by a known factor ρ(t) depending on whether an individual is censored before or after t is expressed as lim_(δ→0) [pr(t < T < t + δ | T > t, C ≤ t) / pr(t < T < t + δ | T > t, C > t)] = [BLANK].",
    "gold_answer": "ρ(t). This equation highlights the assumption that the ratio of conditional hazards for individuals censored before time t versus those censored after time t is a known function ρ(t), which is central to modeling dependent censoring."
  },
  {
    "qid": "fill-in-the-blank-ds-2923",
    "question": "In the comparison of polynomial histogram estimators with kernel estimators, one notable advantage of the second-order polynomial histogram estimator (Sophe) is its larger optimal binwidth. This larger binwidth leads to [BLANK], making the Sophe computationally more efficient than kernel estimators in higher dimensions.",
    "gold_answer": "more efficient computations. The larger binwidth reduces the number of bins needed, significantly lowering the computational effort required for density estimation in multivariate settings."
  },
  {
    "qid": "fill-in-the-blank-ds-1427",
    "question": "In the context of seasonal cointegration analysis, the new iterative reduced-rank regression procedures are motivated by the idea that modelling the cointegration restrictions jointly at different frequencies may increase [BLANK] in finite samples.",
    "gold_answer": "efficiency. This highlights the advantage of considering multiple frequencies together to improve the accuracy and reliability of statistical analyses in small samples."
  },
  {
    "qid": "fill-in-the-blank-ds-1395",
    "question": "The BHEP test statistic for multivariate normality is given by $T_{n,\\beta}:=n(4\\mathrm{\\boldmath~1\\{~}}S_{n}\\mathrm{is~singular\\}+W_{n,\\beta}\\mathrm{\\boldmath~1\\{~}}S_{n}\\mathrm{is~nonsingular\\}})$. Here, $W_{n,\\beta}$ is the weighted $L^{2}$ -distance between the empirical characteristic function of the scaled residuals and the characteristic function of the standard $d$ -variate normal distribution, weighted by $\\varphi_{\\beta}(t):=(2\\pi\\beta^{2})^{-d/2}\\exp{\\biggl(-\\frac{\\|t\\|^{2}}{2\\beta^{2}}\\biggr)}$. The weight function $\\varphi_{\\beta}$ is chosen because it allows $W_{n,\\beta}$ to take the simple form involving $\\exp\\left(-\\frac{\\beta^{2}}{2}\\parallel Y_{j}-Y_{k}\\parallel^{2}\\right)$. What is the key property of $\\varphi_{\\beta}$ that enables this simplification?",
    "gold_answer": "The weight function $\\varphi_{\\beta}$ is the Fourier transform of a Gaussian kernel, which simplifies the integral expression for $W_{n,\\beta}$ into a sum of exponentials. This property is crucial for the computational tractability of the BHEP test statistic."
  },
  {
    "qid": "fill-in-the-blank-ds-2137",
    "question": "In the context of testing the conditional mean and conditional variance for nonstationary data, the hypothesis can be interpreted as testing both the mean and the variance, or testing the mean under knowledge of an upper bound on the variance. The paper mainly uses interpretation (A), which is relevant when the tester is interested in whether a time series has switched away from a given regime with specified mean and variance bounds. The key challenge in this setting is that the data points are not [BLANK], and hence we cannot make inference of the distributions themselves.",
    "gold_answer": "independent and identically distributed. This is excluded to highlight the complexity of the problem where traditional inference methods cannot be directly applied due to the lack of i.i.d. assumptions."
  },
  {
    "qid": "fill-in-the-blank-ds-2200",
    "question": "In the context of high-dimensional data analysis for causal effect estimation with multivariate treatments, the proposed Double Screening Prior Adaptive Lasso (DSPAL) method combines the adaptive lasso method with the marginal conditional (in)dependence prior information to select target covariates. The distinctive feature of DSPAL is that it can be applied to [BLANK] dimensional covariates for multivariate treatments, and can deal with both parametric and nonparametric outcome models.",
    "gold_answer": "high-dimensional or even ultra-high. This highlights DSPAL's capability to handle datasets where the number of covariates is very large, possibly exceeding the sample size, making it versatile for various types of data analysis scenarios."
  },
  {
    "qid": "fill-in-the-blank-ds-1342",
    "question": "The Coordinate-Exchange Algorithm is used to construct the additional runs X₂ to optimize the Bayesian D-optimality criterion |X₁′X₁ + X₂′X₂ + R|. This algorithm iterates through each entry in the design matrix, replacing the current value with the entry from {-1, +1} that results in the largest value of the objective function. Because the resulting design is likely only locally optimal, the algorithm is repeated many times with different random starting values for the entries. After many random starts, e.g., 100, the design with the largest determinant is approximately the Bayesian D-optimal design. The number of random starts suggested by Jones et al. (2008) to ensure the design is approximately optimal is [BLANK].",
    "gold_answer": "100. This number of random starts is suggested to ensure that the algorithm explores a wide range of possible designs and converges to one that is approximately optimal."
  },
  {
    "qid": "fill-in-the-blank-ds-2130",
    "question": "In the probabilistic principal component analysis (PPCA) model, the random vector \\(\\mathbf{y}_{i}\\) is expressed as \\(\\mathbf{y}_{i} = \\pmb{\\mu} + W\\mathbf{u}_{i} + \\epsilon_{i}\\), where \\(\\mathbf{u}_{i}\\) is a vector of latent principal components and \\(\\epsilon_{i}\\) is the error term. The distribution assumed for \\(\\mathbf{u}_{i}\\) is [BLANK].",
    "gold_answer": "\\(\\mathbf{u}_{i} \\sim \\mathcal{N}(\\mathbf{0}, I_{q})\\). This distribution is chosen because it simplifies the model by assuming that the latent principal components are independently and identically distributed with zero mean and unit variance, facilitating the estimation of the model parameters."
  },
  {
    "qid": "fill-in-the-blank-ds-36",
    "question": "In the analysis of correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yᵢⱼ can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where αᵣ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "bᵢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-1072",
    "question": "The proposed method for subgroup identification is robust against heavy-tailed errors or outliers due to the use of [BLANK] regression.",
    "gold_answer": "median"
  },
  {
    "qid": "fill-in-the-blank-ds-2705",
    "question": "In the context of geological studies, the term 'target population' refers to the entire group of interest about which inferences are to be made, whereas the 'sampled population' consists of the parts of the target population that are actually accessible for sampling. A key concept that bridges these two is the [BLANK], which represents the part of the original rock body still extant and available for sampling.",
    "gold_answer": "existent population. This term is crucial for understanding the limitations and possibilities in geological sampling, highlighting the difference between what was originally present and what remains accessible for study."
  },
  {
    "qid": "fill-in-the-blank-ds-580",
    "question": "In the context of row-column designs, the average efficiency factor is given by the harmonic mean of the [BLANK], which are (1/r) times the nonzero eigenvalues of its information matrix.",
    "gold_answer": "canonical efficiency factors. This highlights the mathematical foundation used to evaluate the performance of row-column designs by focusing on the eigenvalues of the information matrix."
  },
  {
    "qid": "fill-in-the-blank-ds-1572",
    "question": "In the setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR)"
  },
  {
    "qid": "fill-in-the-blank-ds-2061",
    "question": "For a stationary sequence of uniform [0, 1] random variables $\\{\\xi_i\\}$, the empirical distribution function $T_n(t)$ is used to study asymptotic properties. Under $\\varphi$-mixing conditions, given $\\epsilon > 0$, there exists a subset $S_{n,\\epsilon}$ of $\\Omega$ with $P(S_{n,\\epsilon}) > 1 - \\epsilon$ on which $1 - (1 - t)/\\beta \\leq T_n(t) \\leq t/\\beta$ for $0 \\leq t \\leq 1$. Here, $\\beta$ depends on [BLANK]. What fills in the blank?",
    "gold_answer": "\\epsilon. The parameter $\\beta$ is chosen based on the given $\\epsilon$ to ensure the probability condition is satisfied."
  },
  {
    "qid": "fill-in-the-blank-ds-428",
    "question": "In the algorithm for generating population correlation matrices with specified eigenvalues, the initial step involves generating a random orthogonal matrix A from the invariant Haar measure on the group of orthogonal matrices. The resulting matrix C₀ = A D A′ is a random covariance matrix with eigenvalues given by D. What is the next step in the algorithm after obtaining C₀?",
    "gold_answer": "The algorithm successively obtains n-1 orthogonal matrices Pᵢ so that C = Pₙ₋₁Pₙ₋₂...P₂P₁C₀P₁′P₂′...Pₙ₋₂′Pₙ₋₁′ is a correlation matrix having the same eigenvalues as C₀. This step is crucial for transforming the covariance matrix into a correlation matrix while preserving the specified eigenvalues."
  },
  {
    "qid": "fill-in-the-blank-ds-802",
    "question": "A necessary, though not sufficient, condition for a multivariate distribution to be normal is that all the marginal distributions should be [BLANK].",
    "gold_answer": "univariate normal. This is removed to emphasize the foundational requirement for testing multivariate normality through the examination of its marginal distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-2845",
    "question": "The horizontal distance between the two lines turns out to be the ratio of the number of degrees of freedom attributable to regression to the total number of degrees of freedom. This indicates rather neatly the way in which the degree of indeterminacy in the bounds procedure depends on both the number of regressors and the [BLANK].",
    "gold_answer": "sample size. The ratio reflects how the test's sensitivity to serial correlation is influenced by the model's complexity and the amount of data available."
  },
  {
    "qid": "fill-in-the-blank-ds-3608",
    "question": "For a matrix $M = [D_{a_{i}} + \\alpha\\mathbf{b}\\mathbf{b}^{\\prime}]$ where all $a_{i} = a$ and $\\mathbf{b}$ is a unit vector, the characteristic equation reduces to $\\{(a - \\lambda) + \\alpha n\\}(a - \\lambda)^{n-1} = 0$. What are the $n$ characteristic roots in this case?",
    "gold_answer": "The $n$ characteristic roots are $n-1$ roots equal to $a$ and one root equal to $a + \\alpha n$. This result highlights the impact of the vector $\\mathbf{b}$ and scalar $\\alpha$ on the matrix's eigenvalues."
  },
  {
    "qid": "fill-in-the-blank-ds-1526",
    "question": "The usual measures of dispersion such as the sample variance, the sample mean deviation, the sample range, etc. cannot be used when the mean of the population is undergoing a trend, since they are likely to be seriously affected by the trend. Under these circumstances and especially if the trend is a slow-moving one, the following four measures of dispersion based on successive differences have been proposed: [BLANK], d, δ₁³, and d₃.",
    "gold_answer": "δ². This is the first of the four measures of dispersion based on successive differences proposed for use when the population mean is undergoing a trend, highlighting its importance in such scenarios."
  },
  {
    "qid": "fill-in-the-blank-ds-2378",
    "question": "The measurement equation for continuous variables in the GLVM is specified using an identity link function, where the expected value of the response variable is related to the latent variables through the equation: gⱼ(ϑᵢⱼ,ₖ) = ϑᵢⱼ,ₖ = μⱼ,ₖ + [BLANK]'ωᵢ. What term completes this equation to represent the linear predictor?",
    "gold_answer": "Λⱼ,ₖ. This term represents the vector of factor loadings for the jth observed variable in the kth component, linking the latent variables to the observed variables."
  },
  {
    "qid": "fill-in-the-blank-ds-1244",
    "question": "For the risk ratio (RR) in a three-arm NI trial, under Margin 1, the NI hypothesis can be written as H₀: πE/πR ≤ 1 + f(1 − πP/πR) vs. H₁: πE/πR > 1 + f(1 − πP/πR), where [BLANK] is the pre-specified negative fraction.",
    "gold_answer": "f. This element is crucial as it defines the fraction of the effect size of the reference treatment over placebo used to determine the NI margin."
  },
  {
    "qid": "fill-in-the-blank-ds-2799",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK]. This assumption is essential for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by ensuring that missingness does not depend on unobserved data once conditioned on observed responses."
  },
  {
    "qid": "fill-in-the-blank-ds-2793",
    "question": "The method was originally proposed for cases where the probability models have [BLANK] support.",
    "gold_answer": "overlapping. The original proposal of bridge sampling was for probability models that have overlapping support, facilitating the computation of ratios of normalizing constants."
  },
  {
    "qid": "fill-in-the-blank-ds-1779",
    "question": "The asymptotic properties of the model averaging estimator are derived under [BLANK] and heteroskedastic errors.",
    "gold_answer": "homoskedastic"
  },
  {
    "qid": "fill-in-the-blank-ds-2806",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yᵢⱼ can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where αᵣ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "bᵢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-3458",
    "question": "In the context of rounding error adjustments in regression, Sheppard's corrections involve subtracting a term of the form [BLANK] from the diagonal elements of the sample covariance matrix calculated using rounded data, where δ denotes the width of the rounding interval.",
    "gold_answer": "δ²/12. This term is subtracted to adjust for the bias introduced by rounding errors in the data."
  },
  {
    "qid": "fill-in-the-blank-ds-3552",
    "question": "In the context of robust estimation of power spectra, the term [BLANK] refers to the process of filtering the data to transform the original time series into a series whose spectrum is nearly flat.",
    "gold_answer": "prewhitening"
  },
  {
    "qid": "fill-in-the-blank-ds-318",
    "question": "In the study of Shirley poppies, the mean number of stigmatic bands per capsule was found to be [BLANK] for the original Hampden crop.",
    "gold_answer": "12.51. This value represents the average number of stigmatic bands observed in the capsules of the original Hampden crop, serving as a baseline for comparison with other crops."
  },
  {
    "qid": "fill-in-the-blank-ds-1827",
    "question": "The optimal rate of convergence for estimators of the stable tail dependence function l is determined by the behavior of a function g, which is ρ-varying at 0. For a sequence tₙ satisfying lim_{n→∞} g(tₙ)(n tₙ)¹/² = 1, the optimal rate aₙ must satisfy lim_{n→∞} aₙ/(g(tₙ)) = [BLANK] if ρ > 0.",
    "gold_answer": "∞. This indicates that the rate of convergence aₙ must be slower than g(tₙ) to ensure that the estimator achieves the optimal balance between bias and variance."
  },
  {
    "qid": "fill-in-the-blank-ds-1228",
    "question": "In the HMTD model, the time series is treated as a mixture where the relation between the components is governed by a [BLANK] latent transition process.",
    "gold_answer": "Markovian. This emphasizes the model's use of Markov processes to govern transitions between different states or components of the mixture."
  },
  {
    "qid": "fill-in-the-blank-ds-3019",
    "question": "In the context of analyzing the divergence of sub-groups from a general population, the coefficient of mean square contingency is used to measure heterogeneity. The formula for the coefficient of divergence for a sub-group b is given by c_b = sqrt(phi_b^2 / (1 - n_b/N + phi_b^2)), where phi_b^2 is the contribution of the sub-group to the total mean square contingency, n_b is the size of the sub-group, and N is the total population size. If phi_b^2 = 0, this implies that the sub-group is a [BLANK] sample of the general population.",
    "gold_answer": "random. This is because a phi_b^2 value of 0 indicates no contribution to the mean square contingency, suggesting the sub-group does not diverge from the general population and thus is a random sample."
  },
  {
    "qid": "fill-in-the-blank-ds-1746",
    "question": "In the context of conditional marginal regression, the proposed maximum-type test statistic is designed to detect the effects of $X$ in the presence of $Z$ by considering conditional marginal regression, where the response variable is separately regressed on each component of $X$ conditional on $Z$. The test statistic is based on a scale-invariant $t$-statistic, which maximizes $(\\hat{\\theta}_{j}^{Z})^{2}\\hat{V}_{j|Z}$, where $\\hat{\\theta}_{j}^{Z}$ is the estimated coefficient of $X_{j}$ when regressing $Y$ on $Z$ and $X_{j}$ together, and $\\hat{V}_{j|Z}$ is the estimated [BLANK] of $X_{j}$ given $Z$.",
    "gold_answer": "conditional variance. This term is crucial for understanding the variability of $X_{j}$ after accounting for the effects of $Z$, which is essential for the scale-invariance property of the test statistic."
  },
  {
    "qid": "fill-in-the-blank-ds-1648",
    "question": "In the nonparametric calibration method for age estimation, the posterior distribution of age given the indicator variables is derived using [BLANK], which combines the likelihood of the indicators given age and the prior distribution of age.",
    "gold_answer": "Bayes’s theorem. This is the fundamental principle that allows the posterior distribution to be calculated from the likelihood and the prior, enabling the incorporation of prior knowledge into the estimation process."
  },
  {
    "qid": "fill-in-the-blank-ds-2824",
    "question": "The selection of the tuning parameter q in the TC-MLqE method is based on the empirical stability of the estimates, aiming to choose q closest to 1 such that the estimates are sufficiently [BLANK].",
    "gold_answer": "stable. This approach ensures that the method remains efficient in the absence of contamination while robust against outliers."
  },
  {
    "qid": "fill-in-the-blank-ds-1177",
    "question": "In the context of multivariate scale mixtures, the transformation from $S$ to $Y = S^{\\delta/\\rho}$ is considered, where $\\delta = \\pm1$ and $\\rho$ is a positive number. The choice of $\\rho$ is typically $\\frac{1}{2}$ or $1$ depending on whether $Z_1$ is distributed as the standard normal distribution or a gamma distribution. The constant $\\delta$ is chosen so that the first few moments of $S_i^{\\delta/\\rho}, i=1,\\dots,p$ are computable or evaluated. The transformation in case (1.2) is expressed as $Y_i = S_i^{\\delta/\\rho}, i=1,\\dots,p$. What critical value is omitted in the transformation expression?",
    "gold_answer": "The critical value omitted in the transformation expression is the specific choice of $\\delta$ (which can be $1$ or $-1$) that ensures the first few moments of $S_i^{\\delta/\\rho}$ are computable or evaluated. This choice is crucial for the practical application of the transformation, as it influences the computability of the moments and the overall behavior of the scale mixture model."
  },
  {
    "qid": "fill-in-the-blank-ds-1619",
    "question": "In the Gaussian channel model with feedback, the mutual information $I_{t}(\\xi,Y)$ between the message $\\xi(\\cdot)$ and the output $Y(\\cdot)$ is given by a causal functional of $Y(\\cdot)$ when the spectral measure of the Gaussian noise $X(\\cdot)$ is [BLANK].",
    "gold_answer": "continuous. This condition ensures that the mutual information can be expressed in terms of a causal functional of the output process, facilitating the analysis of information transmission in such channels."
  },
  {
    "qid": "fill-in-the-blank-ds-2026",
    "question": "The Gaussian state space form is given by y_t = Z_tα_t + ε_t, α_t = T_tα_{t-1} + η_t (t=1,…,n), where α_0 ~ N(a_0, P_0), ε_t ~ N(0, H_t), η_t ~ N(0, Q_t), and the initial conditions a_0 and P_0 are known. The [BLANK] can be used to deliver the log likelihood which in turn means the score can be evaluated by numerical differentiation.",
    "gold_answer": "Kalman filter. This is omitted to highlight the tool's central role in evaluating the log likelihood and subsequently the score through numerical differentiation in Gaussian state space models."
  },
  {
    "qid": "fill-in-the-blank-ds-2",
    "question": "In the analysis of ordinal data, the proportional odds mixed model for a single ordinal response Yᵢⱼ can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where αᵣ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "bᵢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-1100",
    "question": "In the context of product return data with two-layer censoring, the first layer of censoring is called [BLANK], which applies to the product lifetime due to a fixed warranty limit.",
    "gold_answer": "warranty censoring. This term is used to describe the censoring that occurs because the product's lifetime is only observed up to the warranty limit."
  },
  {
    "qid": "fill-in-the-blank-ds-3219",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yᵢⱼ can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where αᵣ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "bᵢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-565",
    "question": "The bootstrap-based procedure proposed as a diagnostic tool involves generating new samples by resampling the pairs $(x_t, y_t)$ from the data, taking into account the stochastic properties of the variables if necessary, a method attributed to [BLANK].",
    "gold_answer": "Künsch (1989), Politis and Romano (1994), and Hansen (2002). These authors contributed to the development of bootstrap methods that account for the time series properties of financial data, ensuring the robustness of the resampling procedure."
  },
  {
    "qid": "fill-in-the-blank-ds-1088",
    "question": "The asymptotic null distribution of the proposed test statistic is shown to converge weakly to a function of the [BLANK], under the null hypothesis of no parameter change.",
    "gold_answer": "Brownian bridge. This convergence is crucial for determining the critical values of the test statistic under the null hypothesis, facilitating hypothesis testing."
  },
  {
    "qid": "fill-in-the-blank-ds-3202",
    "question": "In the context of goodness-of-fit tests for a multivariate distribution using the empirical characteristic function approach, the null hypothesis can be expressed as $H_{0}\\colon C(t)=C_{0}(t)$ for $t\\in R^{d}$, where $C(t)$ is the characteristic function of the distribution function $F(\\cdot)$ and $C_{0}(t)$ is the characteristic function of the specified distribution function $F_{0}(\\cdot)$. The test statistic proposed to measure the discrepancy between the empirical characteristic function $C_{n}(\\cdot)$ and $C_{0}(\\cdot)$ is given by $T_{n}=[Z_{n}(\\bar{t}_{m})-Z_{0}(\\bar{t}_{m})]^{\\prime}\\varOmega_{0}^{-1/2}(\\bar{t}_{m})W(\\bar{t}_{m},\\lambda)\\varOmega_{0}^{-1/2}(\\bar{t}_{m})[Z_{n}(\\bar{t}_{m})-Z_{0}(\\bar{t}_{m})]$, where $Z_{n}(\\bar{t}_{m})$ and $Z_{0}(\\bar{t}_{m})$ are vectors containing the real and imaginary parts of $C_{n}(t)$ and $C_{0}(t)$ evaluated at points $t_{1},...,t_{m}\\in R^{d}$, and $\\varOmega_{0}(\\bar{t}_{m})$ is the covariance matrix of $Y_{j}(\\bar{t}_{m})$ under $H_{0}$. The weight matrix $W(\\bar{t}_{m},\\lambda)$ is used to direct the power of the test towards different frequencies. The term deliberately omitted in the description of $T_{n}$ that highlights the role of $\\varOmega_{0}^{-1/2}(\\bar{t}_{m})$ is [BLANK].",
    "gold_answer": "ensuring that the transformed vector $\\varOmega_{0}^{-1/2}(\\bar{t}_{m})[Z_{n}(\\bar{t}_{m})-Z_{0}(\\bar{t}_{m})]$ has an identity covariance matrix under $H_{0}$. This transformation standardizes the discrepancy measure, making the test statistic invariant to the scale of the original data and facilitating the comparison across different frequencies."
  },
  {
    "qid": "fill-in-the-blank-ds-724",
    "question": "Under appropriate conditions, the paper proves consistency and asymptotic normality of WC estimators. From a computational point of view, computing WC estimators involves solving a minimax continuous problem, which is quite a challenging task, and the use of efficient numerical methods is required. In particular, the paper uses the global optimization algorithm considered by [BLANK].",
    "gold_answer": "Zakovic and Rustem (2003). This specifies the algorithm used for solving the minimax problem, highlighting the practical approach to computation."
  },
  {
    "qid": "fill-in-the-blank-ds-3026",
    "question": "In the eigen-adjusted FPCA model, the covariance function Γ(s,t,z) is assumed to vary with the covariates via its [BLANK] while the corresponding eigenfunctions remain independent of the covariates.",
    "gold_answer": "eigenvalues. This highlights the model's flexibility by allowing the eigenvalues to adjust based on covariate information, facilitating a more nuanced analysis of functional data."
  },
  {
    "qid": "fill-in-the-blank-ds-995",
    "question": "In the proportional hazards regression model for the subdistribution of a competing risk, the subdistribution hazard function is defined as [BLANK], where F₁(t;Z) is the cumulative incidence function of cause 1 given covariates Z.",
    "gold_answer": "λ₁*(t;Z) = -d log{1 - F₁(t;Z)} / dt. This formula is crucial as it directly relates the subdistribution hazard to the cumulative incidence function, allowing for the modeling of covariate effects on the subdistribution hazard."
  },
  {
    "qid": "fill-in-the-blank-ds-2024",
    "question": "In the WaveSpect0 software package, the step-interval unification is achieved by applying [BLANK] interpolation in resampling.",
    "gold_answer": "cubic spline. Cubic spline interpolation is used to unify the step intervals of discrete data, ensuring that the data can be correctly and efficiently processed by MATLAB wavelet functions."
  },
  {
    "qid": "fill-in-the-blank-ds-1737",
    "question": "In the LSRE model, the data are modeled as $X_{i j}=\\mu_{i}+\\sigma_{i}\\epsilon_{i j}$, where $\\epsilon_{i j}$ are i.i.d. with mean 0 and variance 1. The key assumption that allows for the identification of the error distribution $F$ when $n\\geq4$ is that the characteristic functions of $\\log\\sigma_{i}$, $\\epsilon_{i1}$, and $\\log|\\epsilon_{i1}-\\epsilon_{i2}|$ have [BLANK]. What property must these characteristic functions satisfy?",
    "gold_answer": "countably many zeroes. This assumption is crucial for the identifiability of the error distribution $F$ in the LSRE model, ensuring that the distributions of the components can be distinguished based on the observed data."
  },
  {
    "qid": "fill-in-the-blank-ds-1812",
    "question": "In the context of quality control for skew distributed data, the logarithmic transformation is used to calculate control limits by reversing the transformation to fix the limits so that sample values can be plotted in their original scale of measurement. This approach is based on the properties of the [BLANK] distribution.",
    "gold_answer": "lognormal. The question removes 'lognormal' to emphasize the specific distribution that underpins the method for handling skew data in quality control, highlighting its importance in the transformation process."
  },
  {
    "qid": "fill-in-the-blank-ds-1144",
    "question": "In the semiparametric model proposed for the marginal mark distribution, the association between the mark and survival time is parameterised by [BLANK], while the marginals are left unspecified.",
    "gold_answer": "ρ (the correlation coefficient). This highlights the model's flexibility in specifying the dependence structure without imposing strict assumptions on the marginal distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-2127",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK]. This assumption is crucial for likelihood-based or multiple-imputation methods to yield valid inferences.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by stating that once we condition on the observed responses, the missingness no longer depends on the unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-1872",
    "question": "The dichotomy pointed out by Feller in the context of diffusion processes distinguishes between systems with microscopic fluctuations and those with macroscopic fluctuations. In the case of microscopic fluctuations, the limit process is of the Ornstein-Uhlenbeck (Gaussian) type, obtained by amplifying the fluctuations by an appropriate factor. For systems with macroscopic fluctuations, the diffusion process satisfies a stochastic differential equation with nonconstant coefficients and is a mass process in the sense that the state space is [BLANK]. What is the state space for systems with macroscopic fluctuations?",
    "gold_answer": "R+. This denotes the space of nonnegative real numbers, indicating that the process models quantities that are inherently nonnegative, such as mass."
  },
  {
    "qid": "fill-in-the-blank-ds-3109",
    "question": "Kernel density estimators for discrete multivariate data are investigated, using the notation framework of contingency tables. We derive large sample properties of kernel estimators and the least-squares cross-validation method for choosing the bandwidth, including the asymptotic bias, the mean summed squared error, the actual summed squared error, and the asymptotic distribution of the resulting nonparametric estimator. We show that the least-squares cross-validation procedure is superior to Kullback-Leibler cross-validation in terms of [BLANK], but that the least-squares cross-validation is still sub-optimal concerning actual summed squared error.",
    "gold_answer": "mean summed squared error. This highlights the comparative advantage of the least-squares cross-validation method over Kullback-Leibler cross-validation when evaluating the performance of kernel estimators based on mean summed squared error, despite its sub-optimality regarding actual summed squared error."
  },
  {
    "qid": "fill-in-the-blank-ds-624",
    "question": "In the context of Gaussian Process (GP) regression surrogates for Bayesian estimation, the universal approximation property ensures that the GP can approximate any continuous function arbitrarily well on a compact subset of the input space. This property is guaranteed if the kernel used is [BLANK]. Which type of kernel guarantees this property?",
    "gold_answer": "universal. A kernel is universal if it can approximate any continuous function to arbitrary precision on a compact subset of the input space, which is a critical property for Gaussian Process regression surrogates in Bayesian estimation frameworks."
  },
  {
    "qid": "fill-in-the-blank-ds-1233",
    "question": "In the hierarchical-likelihood approach to autoregressive stochastic volatility models, the h-likelihood is defined as h(b, α) = ∑ from t=1 to n of log f(y_t | b_t) + log f_α(b_1, ..., b_n). The term [BLANK] is crucial for estimating the unobserved log of volatilities (random effects). What is the missing term in the h-likelihood definition?",
    "gold_answer": "log f_α(b_1, ..., b_n). This term represents the log-density of the random effects b under the parameters α, which is essential for capturing the autoregressive structure of the volatilities in the model."
  },
  {
    "qid": "fill-in-the-blank-ds-1308",
    "question": "The probability generating functional (PGF) of the point process Nₙ(·|(a,i)) is given by Gₙ(φ|(a,i)), where φ is a function from D×{1,...,q} to ℝ, with 1−φ(·,i) ∈ C_c(D), and 0 ≤ φ(·,·) ≤ 1. The semigroup property of Gₙ states that Gₙ(Gₘ(φ|·,·)|(x,i)) = [BLANK].",
    "gold_answer": "Gₙ₊ₘ(φ|(x,i)). This property reflects the Markovian nature of the branching random walk, allowing the composition of generating functionals over successive generations."
  },
  {
    "qid": "fill-in-the-blank-ds-191",
    "question": "In the study of human skull variation and correlation, the system of measurement used for most skulls was in accordance with the [BLANK], so far as the condition of the material allowed.",
    "gold_answer": "Frankfurter Verstandigung"
  },
  {
    "qid": "fill-in-the-blank-ds-524",
    "question": "The iterative convex minorant (ICM) algorithm proposed by Groeneboom and Wellner is fast in computing the NPMLE of the distribution function for interval censored data without covariates. We reformulate the ICM as a [BLANK], which leads to a natural extension to the Cox model.",
    "gold_answer": "generalized gradient projection method (GGP). This reformulation allows the ICM to be extended to the Cox model by treating it as a special case of the GGP, facilitating its application to more complex models."
  },
  {
    "qid": "fill-in-the-blank-ds-2565",
    "question": "In the context of forensic science, the likelihood ratio (LR) is used to evaluate the strength of evidence under two mutually exclusive hypotheses: contact (C) and no contact (¬C). The general expression for LR, considering all possible partitions of evidence E into transferred (ETi) and background (EBi) material, is given by LR = [BLANK]. This formula accounts for the probabilities of transferred material under both hypotheses and the background material's distribution.",
    "gold_answer": "∑(i=1 to N) [p(ETi|C)p(yTi|ETiCx)pρ(EBiyBi)] / ∑(i=1 to N) [p(ETi|¬C)p(yTi|ETi¬C)pρ(EBiyBi)]. This expression is derived to comprehensively evaluate the evidence by considering all possible ways the evidence could be partitioned into transferred and background material, under both hypotheses of contact and no contact."
  },
  {
    "qid": "fill-in-the-blank-ds-1021",
    "question": "In statistical inference, one may choose between a population model or a permutation model. The population model, introduced by Neyman and Pearson in 1928, involves sampling from one or more defined populations and applying a test statistic to this randomized sampling. On the other hand, the permutation model was introduced by Fisher in [BLANK].",
    "gold_answer": "1925"
  },
  {
    "qid": "fill-in-the-blank-ds-5",
    "question": "In the context of hereditary entropion and changes in the skin of the eyelids, the condition where the skin of the upper lids is very thin, has lost elasticity, and resembles crinkled cigarette paper is referred to as [BLANK].",
    "gold_answer": "blepharochalasis. This term is used to describe the specific condition of the eyelids where the skin becomes thin, loses elasticity, and forms fine wrinkles, resembling crinkled cigarette paper, as described by Fuchs in 1896."
  },
  {
    "qid": "fill-in-the-blank-ds-1925",
    "question": "In the proposed copula-based semiparametric transformation model for bivariate data under general interval censoring, the joint likelihood is modeled through a two-parameter [BLANK], which can flexibly characterize the dependence between the two margins in both tails.",
    "gold_answer": "Archimedean copula. This is specified to highlight the flexibility of the two-parameter Archimedean copula in modeling dependence structures in both upper and lower tails of the distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-365",
    "question": "The target INR range for patients prescribed anticoagulants is typically between [BLANK] and 3, aiming to balance the risk of thrombosis and bleeding.",
    "gold_answer": "2. The blank is filled with '2' to specify the lower bound of the target INR range for patients on anticoagulants, ensuring a reduced risk of thrombosis without excessively increasing bleeding risk."
  },
  {
    "qid": "fill-in-the-blank-ds-1139",
    "question": "In the context of analyzing the range of samples from a normal population, the mean range for a sample size n is given by the integral from negative infinity to positive infinity of {1 - (1 - α)^n - α^n} dα. For a sample size of n=10, the mean range is approximately [BLANK] in terms of the standard deviation of the original population.",
    "gold_answer": "3.07751. This value is derived from the integral expression provided, representing the expected range for samples of size 10 from a normal population with unit standard deviation."
  },
  {
    "qid": "fill-in-the-blank-ds-3369",
    "question": "In the context of sequential t tests, the ordinate zₙ is calculated as [BLANK] divided by the sum of the squares of the observations up to n. What is the numerator in this calculation?",
    "gold_answer": "the square of the sum of the observations up to n. This is excluded to emphasize the formula's structure, highlighting how zₙ aggregates the observations' linear and quadratic forms."
  },
  {
    "qid": "fill-in-the-blank-ds-1937",
    "question": "The variance–covariance matrix for the random vectors u and ν is given by Σ = Γ ⊗ I_M, where Γ is a matrix with elements θ_u^2, ρθ_uθ_ν, ρθ_uθ_ν, and [BLANK].",
    "gold_answer": "θ_ν^2. The blank is filled with 'θ_ν^2' to complete the specification of the variance–covariance matrix Γ, quantifying the heterogeneity in the unobserved random effects for the hazard rate of death."
  },
  {
    "qid": "fill-in-the-blank-ds-2842",
    "question": "A well-known procedure for testing for serial correlation is to plot out the sample path of the cumulated periodogram and to compare the resulting graph with the [BLANK] limits.",
    "gold_answer": "Kolmogorov-Smirnov. This is a standard method for assessing the goodness of fit between the empirical distribution of the sample and the expected distribution under the null hypothesis of serial independence."
  },
  {
    "qid": "fill-in-the-blank-ds-907",
    "question": "In the context of Bayesian hierarchical models, the joint posterior for (x, θ) can have a complex dependence structure, especially when the scale of x|θ, y varies substantially as a function of θ in high-density regions of p(θ|y), leading to a [BLANK]-shaped joint posterior.",
    "gold_answer": "funnel. This shape complicates the exploration of the full target distribution and necessitates careful tuning of the HMC algorithm."
  },
  {
    "qid": "fill-in-the-blank-ds-2650",
    "question": "The paper proposes a new approach to evaluate the effect of the guidance strategy on the predictability of monetary policy, based on jump probabilities of Norwegian interest rates on announcement days of the Norges Bank before and after the introduction of [BLANK].",
    "gold_answer": "quantitative guidance. This is the key change in the Norges Bank's strategy that the paper investigates to assess its impact on monetary policy predictability."
  },
  {
    "qid": "fill-in-the-blank-ds-996",
    "question": "In selection modeling, the likelihood can be factorized into a product of the outcome model and the missingness mechanism, expressed as f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK], where Rᵢ denotes the missingness indicators. Which missingness-related term is deliberately omitted in this equation?",
    "gold_answer": "f(Rᵢ | Yᵢ). This term is omitted to highlight that, in a selection framework, the distribution of the missingness (Rᵢ) may depend on the observed and unobserved outcomes (Yᵢ), distinguishing selection models from pattern–mixture approaches."
  },
  {
    "qid": "fill-in-the-blank-ds-358",
    "question": "In the context of categorical judgment data, the Successive Intervals model postulates that subjects' opinions of each stimulus are normally distributed over some opinion scale T', which can be expressed as F_i(T') = Φ{b'_i(T' - a'_i)} for i = 1, 2, ..., s, where Φ is the standard normal distribution function. The categories for this scale are given by arbitrary intervals. What is the standard deviation of the opinion distributions on the T' scale?",
    "gold_answer": "1/b'_i. This is excluded to highlight that the standard deviation of the opinion distributions is inversely related to the scale parameter b'_i, which is a key aspect of the model's structure."
  },
  {
    "qid": "fill-in-the-blank-ds-2948",
    "question": "The proposed nonparametric estimator of the psf h assumes that h is a member of [BLANK], meaning ∫∫_D h²(x,y) dxdy < ∞.",
    "gold_answer": "L²(D). This assumption ensures that the psf h has finite energy over the domain D, which is a common requirement in image processing."
  },
  {
    "qid": "fill-in-the-blank-ds-2837",
    "question": "In the context of kernel density estimation for circular data, the von Mises distribution is often used as a kernel function. The estimator can be written as \\(\\hat{f}(\\theta;\\nu)=\\frac{1}{n(2\\pi)I_{0}(\\nu)}\\sum_{i=1}^{n}\\exp\\{\\nu\\cos(\\theta-\\theta_{i})\\},\\) where \\(I_{r}(\\nu)\\) is the modified Bessel function of order \\(r\\), and \\(\\nu\\) is the concentration parameter. The optimal choice of \\(\\nu\\) can be derived by minimizing the asymptotic mean integrated squared error (AMISE), leading to a plug-in rule that depends on the concentration parameter of the data \\((\\kappa)\\) and the sample size \\((n)\\). This plug-in rule is given by \\(\\nu=\\left[3n\\hat{\\kappa}^{2}I_{2}(2\\hat{\\kappa})\\{4\\pi^{1/2}I_{0}(\\hat{\\kappa})^{2}\\}^{-1}\\right]^{[BLANK]}.\\). What exponent completes the plug-in rule for the smoothing parameter \\(\\nu\\)?",
    "gold_answer": "2/5. This exponent is derived from the optimization of the asymptotic mean integrated squared error (AMISE), balancing the bias and variance of the kernel density estimator for circular data."
  },
  {
    "qid": "fill-in-the-blank-ds-2075",
    "question": "The Generalized Tukey Lambda (GTL) distribution is defined by its link function G given by ε = G(u; α, δ) = (u^(α−δ) − 1)/(α−δ) − ((1−u)^(α+δ) − 1)/(α+δ), where u ∈ [0,1]. When α−δ = 0, the first term is replaced with [BLANK] according to l’Hôpital’s Rule.",
    "gold_answer": "ln u"
  },
  {
    "qid": "fill-in-the-blank-ds-2109",
    "question": "The robust differential abundance test is designed to be simple, computationally efficient, robust to prevalent zero counts, account for the compositional nature of the data, and have a theoretical guarantee of controlling false discoveries in a general setting. One critical element omitted in this description is [BLANK].",
    "gold_answer": "the ability to work with covariate-balancing techniques to remove potential confounding effects. This element is crucial for drawing reliable conclusions in the presence of observed covariates."
  },
  {
    "qid": "fill-in-the-blank-ds-1268",
    "question": "The varying-coefficient single-index models (VCSIMs) form a class of very flexible and general dimension reduction models, which contain many important regression models such as partially linear models, pure single-index models, partially linear single-index models, varying-coefficient models and so on as special examples. However, the testing problems of the index parameter of the VCSIM have not been very well developed, due partially to the complexity of the models. To this end, based on the estimators obtained by the local linear method and the backfitting technique, we propose the generalized [BLANK] test method to deal with the testing problems of the index parameters of the VCSIM.",
    "gold_answer": "F-type. The generalized F-type test method is proposed to handle the testing problems of the index parameters in VCSIMs, leveraging estimators from the local linear method and backfitting technique."
  },
  {
    "qid": "fill-in-the-blank-ds-2594",
    "question": "A method to jointly analyze both ordinal outcomes and their missingness is to factorize the likelihood into a product of the outcome model and the [BLANK].",
    "gold_answer": "missingness mechanism. This factorization is a fundamental approach in selection modeling to handle missing data in statistical analyses."
  },
  {
    "qid": "fill-in-the-blank-ds-927",
    "question": "In the context of testing the equality of two survival distributions using the modified Savage statistic, the null hypothesis $H_{0}$ states that $F_{1}=F_{2}=F$, where $F$ is an unknown continuous cumulative distribution function. The test is against either the one-sided alternative $H_{1}: F_{1}>F_{2}$ or the two-sided alternative $H_{1}: F_{1}\\neq F_{2}$. The Savage statistic, $\\mathcal{S}_{N}$, for testing $H_{0}$ is defined as $\\mathcal{S}_{N}=\\sum_{i=1}^{m}b_{N}(\\mathcal{R}_{Ni})-m=\\sum_{i=1}^{N}d_{i}\\{b_{N}(i)-1\\}$, where $b_{N}(i)$ is the expected value of the ith order statistic in a random sample of size $N$ from the exponential distribution. Under $H_{0}$, the expected value of $\\mathcal{S}_{N}$ is [BLANK].",
    "gold_answer": "0. This is because, under the null hypothesis, the Savage statistic is centered around zero, reflecting no difference between the two survival distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-904",
    "question": "In the context of Brownian motion, Hincin's law of the iterated logarithm states that for a real-valued Brownian motion with continuous sample paths, the probability that the limit superior of B(t)/(2t log log t)^(1/2) as t approaches infinity equals 1 is [BLANK].",
    "gold_answer": "1. This is the core result of Hincin's law, indicating that the maximum fluctuation of Brownian motion paths is almost surely bounded by the function (2t log log t)^(1/2)."
  },
  {
    "qid": "fill-in-the-blank-ds-2784",
    "question": "Ferebee’s method for constructing an unbiased estimator of the drift $\\theta$ in a group sequential test results in an estimator that agrees with the truncation-adaptable unbiased estimator $\\hat{\\theta}^{*}$. Ferebee’s estimator is given by $\\widehat{\\theta}_{F}(k,x)=[BLANK]$.",
    "gold_answer": "$\\frac{\\partial}{\\partial u}\\log p_{0}(k,x|u)|_{u=0}$. This expression defines Ferebee’s estimator, highlighting its dependence on the derivative of the log density of the sufficient statistic under the null hypothesis."
  },
  {
    "qid": "fill-in-the-blank-ds-762",
    "question": "Patterson and Thompson (1971) propose the [BLANK] estimation to estimate variance components in the context of an unbalanced incomplete-block design.",
    "gold_answer": "residual maximum likelihood (REML). REML is preferred for estimating covariance parameters in linear models due to its consideration of the loss of degrees of freedom in estimating the mean."
  },
  {
    "qid": "fill-in-the-blank-ds-1063",
    "question": "In the simulation study, the true MSPE of the PEB estimator is calculated as TMSPE(γ̂iwPEB)=1R∑r=1R{γ̂iwPEB(r)−γi(r)}2. What does [BLANK] represent in this formula?",
    "gold_answer": "R. This is the number of independent simulation runs used to estimate the true mean squared prediction error, ensuring the reliability of the simulation results."
  },
  {
    "qid": "fill-in-the-blank-ds-883",
    "question": "The N-parameter Wiener process on R_{+}^{N} is defined by several properties, including that for any points s and t in R_{+}^{N}, the expected value E[X(s)X(t)] is equal to [BLANK].",
    "gold_answer": "the product of the minima of their corresponding components (min(s₁, t₁) * ... * min(s_N, t_N). This is excluded to highlight the specific covariance structure that defines the multiparameter Wiener process, distinguishing it from other types of stochastic processes."
  },
  {
    "qid": "fill-in-the-blank-ds-597",
    "question": "In the context of robust regression using iteratively reweighted least squares (IRLS), the weight function wt.bisquare is defined for a given residual u and tuning constant c as [BLANK]. What is the correct expression for the wt.bisquare function?",
    "gold_answer": "w(u) = (1 - (u/c)^2)^2 for 0 < |u/c| ≤ 1, and 0 otherwise. This expression is crucial for understanding how the bisquare weight function downweights outliers in robust regression."
  },
  {
    "qid": "fill-in-the-blank-ds-1706",
    "question": "In the variational Bayes algorithm for Ising model parameter estimation, the pseudo-likelihood is used instead of the true likelihood due to the intractable nature of the [BLANK] in the likelihood.",
    "gold_answer": "normalizing constant. The normalizing constant is intractable in the Ising model likelihood, making direct computation infeasible, hence the use of pseudo-likelihood for estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-2683",
    "question": "In the trichotomous framework for analyzing high-dimensional data, the signal subset includes only strong signals that stand outside the range of noise, the noise subset includes only noise, and the third subset, where relatively weak signals mix indistinguishably with noise, is called the [BLANK] subset.",
    "gold_answer": "mixed/indistinguishable. This term is used to describe the subset where weak signals are not easily distinguishable from noise, highlighting the challenge in identifying these signals amidst high-dimensional data."
  },
  {
    "qid": "fill-in-the-blank-ds-2228",
    "question": "The mean residual life (MRL) of a nonnegative random variable $X$ at age t is defined as $M(t)=E(X-t|X>t)=\\frac{\\int_{t}^{\\infty}S(x)d x}{S(t)}$, where $S(t)$ is the [BLANK] function.",
    "gold_answer": "survival. The survival function $S(t)=P(X>t)$ gives the probability that the variable exceeds a certain value t, which is crucial for calculating the mean residual life."
  },
  {
    "qid": "fill-in-the-blank-ds-563",
    "question": "A key assumption in likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process is known as [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption simplifies the analysis by allowing the missingness to depend only on observed data, not on unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-1688",
    "question": "In the context of optimal discrimination designs for semiparametric models, the Kullback–Leibler divergence measures the discrepancy between two densities and is given by [BLANK]. What is the correct formula for the Kullback–Leibler divergence?",
    "gold_answer": "I_{1,2}(x,f_{1},f_{2},\\theta_{1},\\theta_{2})=\\int f_{1}(y;x,\\theta_{1})\\log\\frac{f_{1}(y;x,\\theta_{1})}{f_{2}(y;x,\\theta_{2})}\\mathrm{d}y. The formula is crucial for measuring the discrepancy between two competing models in the context of optimal discrimination designs."
  },
  {
    "qid": "fill-in-the-blank-ds-140",
    "question": "Bivariate extreme value distributions arise as the limiting distributions of renormalized componentwise maxima. No natural parametric family exists for the dependence between the marginal distributions, but there are considerable restrictions on the dependence structure. We consider modelling the dependence function with parametric models, for which two new models are presented. Tests for independence, and discriminating between models, are also given. The estimation procedure, and the fexibility of the new models, are illustrated with an application to [BLANK] data.",
    "gold_answer": "sea level. This blank is filled to specify the type of data used to illustrate the estimation procedure and the flexibility of the new models in the context of bivariate extreme value theory."
  },
  {
    "qid": "fill-in-the-blank-ds-831",
    "question": "One method to analyze both ordinal outcomes and their missingness in longitudinal clinical studies is to factorize the likelihood into a product of the outcome model and the missingness mechanism, expressed as f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK].",
    "gold_answer": "f(Rᵢ | Yᵢ). This term is crucial in selection modeling as it accounts for the dependency of missingness on observed and unobserved outcomes."
  },
  {
    "qid": "fill-in-the-blank-ds-2556",
    "question": "The functional tangential angle pseudo-depth (FUNTA) is defined for a sample of real centred differentiable functions. The FUNTA pseudo-depth of a function $\tilde{x}(t)$ with respect to the sample is given by $\\mathrm{FUNTA}_{n}(\\tilde{x}) = 1 - (m\\pi)^{-1}\\sum_{i=1}^{n}\\sum_{k=1}^{m_{i}}\\gamma_{k}(\\tilde{x}(s_{i,k}),x_{i}(s_{i,k}))$. What does $\\gamma_{k}$ represent in this equation?",
    "gold_answer": "The geometric angle (in radiant measure) of the tangent to $\\tilde{x}(s_{i,k})$ with the tangent to $x_{i}(s_{i,k})$. It is the intersection angle between the function $\\tilde{x}$ and the sample function $x_{i}$ at their $k$-th intersection point $s_{i,k}$."
  },
  {
    "qid": "fill-in-the-blank-ds-1547",
    "question": "In the context of bivariate binomial autoregressive models, the bivariate binomial distribution of Type II is abbreviated as [BLANK].",
    "gold_answer": "BVBII. This abbreviation is used to succinctly refer to the bivariate binomial distribution of Type II, which is central to the development of the models discussed."
  },
  {
    "qid": "fill-in-the-blank-ds-2470",
    "question": "In the context of functional data analysis, the covariance function γ(s,t) can be expressed as a sum of eigenvalues λj and eigenfunctions φj(s)φj(t), where the eigenvalues are ordered as [BLANK].",
    "gold_answer": "λ1 ≥ λ2 ≥ ... ≥ 0. This ordering is crucial for identifying the principal modes of variation in the data, with λ1 representing the largest variance explained by the first principal component."
  },
  {
    "qid": "fill-in-the-blank-ds-3277",
    "question": "The unscented Kalman smoother algorithm first implements a forward unscented Kalman filter and then evokes a separate backward smoothing pass by only making Gaussian approximations in the state but not in the [BLANK] space.",
    "gold_answer": "observation. This highlights the algorithm's focus on maintaining accuracy in the state space while simplifying the observation space processing."
  },
  {
    "qid": "fill-in-the-blank-ds-1387",
    "question": "The de la Vallée Poussin kernel ψ_κ^VP is a nonnegative kernel function on SO(3) defined for any κ ∈ ℕ∖{0} by its finite Chebyshev expansion, and it yields the optimal convergence rate of [BLANK] for the class F_2,S^2.",
    "gold_answer": "N^(-4/7). The de la Vallée Poussin kernel achieves this optimal rate, demonstrating its efficiency in kernel density estimation for functions with bounded Sobolev norm of order 2."
  },
  {
    "qid": "fill-in-the-blank-ds-3253",
    "question": "In the hierarchical Bayes approach to meta-analysis of microarray studies, the model uses an informative prior for the parameter of interest to aid the detection of differentially expressed genes. The parameter of interest is denoted by [BLANK].",
    "gold_answer": "γ_g. This parameter represents the differential expression of gene g across all studies, with values close to zero indicating no differential expression and values far from zero indicating significant differential expression."
  },
  {
    "qid": "fill-in-the-blank-ds-364",
    "question": "In the context of anticoagulant control, the international normalized ratio (INR) is a standardized measure of blood clotting speed, where a healthy population averages an INR of [BLANK], but patients on anticoagulants aim for a higher INR to reduce thrombosis risk.",
    "gold_answer": "1. The blank is filled with '1' to indicate the average INR in a healthy population, which is the baseline against which anticoagulant effects are measured."
  },
  {
    "qid": "fill-in-the-blank-ds-1259",
    "question": "In a logistic random intercept model where no distributional assumption is made on the random intercept, the estimator developed using semiparametric methods is guaranteed to be [BLANK].",
    "gold_answer": "consistent. This highlights the robustness of the estimator against misspecification of the random intercept distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-2864",
    "question": "The ROC surface is a generalization of the ROC curve which is intended to accommodate the problems of [BLANK] classification.",
    "gold_answer": "three-class. This is highlighted to emphasize the ROC surface's application in scenarios where diagnostic tests categorize subjects into three distinct groups."
  },
  {
    "qid": "fill-in-the-blank-ds-721",
    "question": "A worst-case estimator for econometric models containing unobservable components, based on minimax principles for optimal selection of parameters, is proposed. This estimator is robust against the averse effects of unobservables and involves solving a [BLANK] problem.",
    "gold_answer": "minimax continuous. The blank is filled to highlight the nature of the problem that needs to be solved to compute the worst-case estimators, emphasizing the challenge in their computation."
  },
  {
    "qid": "fill-in-the-blank-ds-1869",
    "question": "The hug and hop Markov chain Monte Carlo algorithm alternates between two kernels, referred to as hug and hop. Hug is a nonreversible kernel that repeatedly applies the bounce mechanism from the recently proposed bouncy particle sampler to produce a proposal point that is far from the current position yet on almost the same contour of the target density, leading to a high acceptance probability. Hop complements hug by deliberately proposing jumps between contours and has an efficiency that degrades very slowly with increasing dimension. The reflection operator used in the hug kernel is given by [BLANK]. What is the correct formula for the reflection operator?",
    "gold_answer": "The reflection operator used in the hug kernel is given by R(ν;g) = ν - 2(νᵀĝ)ĝ, where ĝ = g/||g|| is the unit gradient vector. This formula is crucial for the hug kernel as it ensures the proposed moves remain on nearly the same contour of the target density, facilitating high acceptance probabilities."
  },
  {
    "qid": "fill-in-the-blank-ds-2048",
    "question": "For the multivariate t distribution, the prior for the location vector and the scale matrix is chosen to be minimally informative, specifically using the [BLANK] prior.",
    "gold_answer": "independence-Jeffreys. This prior is selected for its property of reflecting minimal prior information, making it suitable for objective Bayesian analysis."
  },
  {
    "qid": "fill-in-the-blank-ds-1809",
    "question": "In the algorithm for calculating the digamma function, if the argument Y is less than or equal to a certain threshold S, the function approximates DIGAMA as [BLANK]. What is the formula used in this approximation?",
    "gold_answer": "D1 - 1.0 / Y. This formula is used when the argument Y is less than or equal to the threshold S, providing a quick approximation for the digamma function under these conditions."
  },
  {
    "qid": "fill-in-the-blank-ds-2865",
    "question": "A key assumption in the Bayesian approach for estimating the ROC surface under verification bias is that the probability of a subject being verified does not depend on the disease status given the observed measurements, known as the [BLANK] assumption.",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the method's validity, allowing for the analysis without explicitly modeling the missing data mechanism."
  },
  {
    "qid": "fill-in-the-blank-ds-3414",
    "question": "In the analysis of survival times for patients not permanently cured of cancer, the distribution of survival times is found to be skew and can be made approximately normal by applying a [BLANK] transformation.",
    "gold_answer": "logarithmic. This transformation is used because the skew distributions of survival times can be closely approximated by a lognormal distribution, making the data more amenable to statistical analysis."
  },
  {
    "qid": "fill-in-the-blank-ds-348",
    "question": "In the model for analyzing paired comparison experiments, the difference in responses between two samples is given by Y_{isk} = τ_i - τ_s + (φ_1 - φ_2) + (α_{i1} - α_{s2}) + (ψ_{i1k} - ψ_{s2k}). Here, φ_1 - φ_2 can be represented by [BLANK], highlighting the order effect.",
    "gold_answer": "φ. This simplification is made to represent the order effect concisely in the model, emphasizing its role in the difference between responses."
  },
  {
    "qid": "fill-in-the-blank-ds-141",
    "question": "The class of bivariate exponential distributions in which we are interested, satisfy a strong stability relation. Exponential variables $(X,Y)$ satisfy the stability relation if and only if $W=\\operatorname*{min}{(a X,b Y)}$ is also exponentially distributed for all $a,b>0$ (Pickands, 1981). Therefore, the models we will consider have particular application in reliability and [BLANK] analysis.",
    "gold_answer": "survival. The blank is filled to indicate the field where the models discussed have particular applications, highlighting their relevance beyond theoretical statistics."
  },
  {
    "qid": "fill-in-the-blank-ds-1602",
    "question": "A key assumption in the closed population setting with no misclassification and independent captures is that the population is assumed to be [BLANK].",
    "gold_answer": "closed. This means there are no births, deaths, or migrations into or out of the population during the study period, ensuring that the population size remains constant."
  },
  {
    "qid": "fill-in-the-blank-ds-1406",
    "question": "In graded matching for large observational studies, the network is made sparse by grading potential pairings into different grades, with a preference for higher grade pairings. The method aims to match with pairs of the best grade, incorporating progressively lower grade pairs only to the degree they are needed. This approach is implemented in an R package called [BLANK].",
    "gold_answer": "RBestMatch. This package is designed to facilitate graded matching by optimizing the use of higher grade pairings before considering lower grades, thereby making large-scale matching computationally feasible."
  },
  {
    "qid": "fill-in-the-blank-ds-2336",
    "question": "In permutation-based linkages for hierarchical clustering, the similarity between two classes is computed by comparing observed similarities with those obtained from [BLANK] permutations of the data.",
    "gold_answer": "random. This method helps in assessing the significance of the observed similarities under the null hypothesis of independence."
  },
  {
    "qid": "fill-in-the-blank-ds-1652",
    "question": "A key assumption in the Heckman selection model is that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes, known as the [BLANK] assumption.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies the inference process by not requiring explicit modeling of the dropout mechanism."
  },
  {
    "qid": "fill-in-the-blank-ds-830",
    "question": "The Naga skulls were collected from an area known as the Triangle, within which [BLANK] was practiced before 1927.",
    "gold_answer": "human sacrifice. This practice was the reason behind the expedition and collection of skulls and bones from the Naga Hills."
  },
  {
    "qid": "fill-in-the-blank-ds-1554",
    "question": "In the proportional odds ratio model, the reliability coefficient R is defined as [BLANK], where X and Y are random variables with tilt parameters α₁ and α₂, respectively.",
    "gold_answer": "R = P(X > Y). This definition highlights the probability that a random variable X from one distribution exceeds a random variable Y from another distribution, serving as a measure of reliability or the difference between two populations."
  },
  {
    "qid": "fill-in-the-blank-ds-3201",
    "question": "In the context of judgment post-stratified (JPS) samples, the variance of the sign statistic for the pth quantile is given by V(√n S(η_p)) = σ²_{n,η_p} = B_{n,H}κ²_H(η_p) + C_{n,H}δ²_H(η_p), where κ²_H(η_p) = [BLANK]. What is the missing term in the equation for κ²_H(η_p)?",
    "gold_answer": "κ²_H(η_p) = (1/H) {∑_{k=1}^H (p - F_[k](η_p))²}. The term κ²_H(η_p) represents the average squared deviation of the judgment class cumulative distribution functions from the quantile order p, highlighting the variability due to the ranking process."
  },
  {
    "qid": "fill-in-the-blank-ds-3237",
    "question": "The paper discusses the application of the test to a dose–response problem where the isotonic likelihood ratio test gave a $p$-value slightly above 0.05. What was the $p$-value obtained by the bootstrap $D_{\\infty}$ test, and what does this suggest about the test's sensitivity?",
    "gold_answer": "The bootstrap $D_{\\infty}$ test gave a $p$-value of 0.0021, suggesting that it is more sensitive to detecting dose–response relationships, especially in cases with low event rates per dose group."
  },
  {
    "qid": "fill-in-the-blank-ds-13",
    "question": "In the context of block bootstrap methods for dependent data, the optimal block size for variance or bias estimation is of order [BLANK], where n is the length of the time series.",
    "gold_answer": "n^(1/3). This is derived from balancing the error-about-the-mean against bias to minimize mean squared error, with the optimal block size depending on the context of estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-1469",
    "question": "In the context of estimating the mean vector from mutually independent observations, the classic conjugate hierarchical model assumes that for each i, θi ∼ N(μ, λ), where λ is a hyper-parameter. The joint prior on θ₁, ..., θₚ is given by (θ₁, ..., θₚ)ᵀ ∼ N(μ, Σ), where Σ is defined as λ times a matrix with 1 on the diagonal and r elsewhere. The condition r ∈ [BLANK] ensures that Σ is positive definite when p is large.",
    "gold_answer": "[0,1). This condition ensures that the correlation r between any two θi and θj is non-negative and less than 1, guaranteeing the positive definiteness of the covariance matrix Σ for any large p."
  },
  {
    "qid": "fill-in-the-blank-ds-440",
    "question": "In the context of stochastic curtailment methods for early stopping in clinical trials, the method suggested by Lan et al. (1982) calculates the conditional power as the chance that the results at the end of the trial will be significant, given the current data. This can be expressed as [BLANK], where Rᵢ denotes the missingness indicators. What is the term used to describe this chance?",
    "gold_answer": "Conditional power. This term is used to describe the probability that the trial will achieve a statistically significant result by the end, based on the data observed up to the interim analysis."
  },
  {
    "qid": "fill-in-the-blank-ds-1848",
    "question": "The paper proposes a method to test the hypothesis H₀': σ(·) ∈ M' using a process based on the difference of residuals distributions. This process, denoted as Ŵ(y) = n^(1/2)(F̂_ε⁰(y) - F̂_ε₀(y)), is used to construct test statistics. The Kolmogorov-Smirnov type statistic is defined as T_KS = sup_{−∞ < y ≤ T} |Ŵ(y)|, and the Cramer-von Mises type statistic is T_CM = (1/F̂_ε⁰(T)) ∫_{−∞}^T Ŵ²(y) dF̂_ε⁰(y). What critical assumption about the point T is omitted here?",
    "gold_answer": "The point T must be less than τ_Hε⁰ = τ_Fε⁰ ∧ τ_Gε⁰, where τ_F is the infimum of {x: F(x) = 1}, ensuring that the estimators avoid the inconsistent parts of the distributions due to censoring."
  },
  {
    "qid": "fill-in-the-blank-ds-3260",
    "question": "In the context of testing for outliers when both $\\mu$ and $\\pmb{\\sigma}$ are unknown, the modified McKay criterion is given by $(x_{n}-{\\overline{{x}}})/\\pmb{\\delta}$, where $\\pmb{\\delta}$ is the [BLANK].",
    "gold_answer": "sample standard deviation. This is because when both population parameters are unknown, the sample standard deviation is used as an estimate for $\\sigma$."
  },
  {
    "qid": "fill-in-the-blank-ds-886",
    "question": "In high-dimensional quantile tensor regression using a general convex decomposable regularizer, the rates are stated in terms of the intrinsic dimension of the estimation problem, which is, roughly speaking, the dimension of the smallest subspace that contains the true coefficient. The intrinsic dimension is denoted by [BLANK].",
    "gold_answer": "s. This notation is used to represent the intrinsic dimension, which is crucial for understanding the complexity and structure of the estimation problem in high-dimensional quantile tensor regression."
  },
  {
    "qid": "fill-in-the-blank-ds-1830",
    "question": "In the analysis of variance for orthogonal designs, the degrees of freedom dF for a plot factor F with nF levels are calculated recursively. The formula involves subtracting the sum of the degrees of freedom for all plot factors G that are coarser than F from nF. The initial step in this recursive calculation starts with the universal factor U, for which dU = [BLANK].",
    "gold_answer": "1. This is because the universal factor U has only one level, making its degrees of freedom equal to 1, serving as the base case for the recursive calculation."
  },
  {
    "qid": "fill-in-the-blank-ds-1606",
    "question": "The class of multivariate survival functions being studied has the form $G(\\mathbf{x})=G_{0}(A(\\mathbf{x}))$ , where $G_{0}$ is a univariate survival function with support included in $[0,+\\infty)$ and $A:\\mathcal{R}_{+}^{n}\\to[0,\\infty)$ is a nondecreasing function such that $\\boldsymbol{A}(\\mathbf{0})=0$ and $A$ is homogeneous of order 1 (that is, $A(t\\mathbf{x})=t A(\\mathbf{x})$ for all $t>0$ and $\\mathbf{X}\\in{\\mathcal{R}}_{+}^{n}$ ). From a mixture of powers representation, it is known that this class includes $G$ for which $A$ is an exponent of a min-stable multivariate exponential distribution and $G_{0}$ is a [BLANK]. However, we find that the class contains much more than this.",
    "gold_answer": "Laplace transform. This is omitted to highlight that while the class includes cases where $G_{0}$ is a Laplace transform and $A$ is an exponent of a min-stable multivariate exponential distribution, the class is not limited to these cases, allowing for more general dependencies."
  },
  {
    "qid": "fill-in-the-blank-ds-2276",
    "question": "In the context of bootstrap and Edgeworth approximations, the bootstrap approximation to the tail probability Fₙ(x) is denoted by [BLANK], where Rᵢ denotes the missingness indicators.",
    "gold_answer": "F̂ₙ(x). This notation is used to represent the bootstrap approximation to the tail probability Fₙ(x), highlighting the bootstrap's role in estimating distribution functions."
  },
  {
    "qid": "fill-in-the-blank-ds-1971",
    "question": "In the context of surrogate evaluation in the presence of interference, the definition of a predictive cluster level surrogate is based on the association between causal effects on the clinical outcome and causal effects on the surrogate outcome at the cluster level. This definition is rooted in the [BLANK] paradigm.",
    "gold_answer": "causal-association. The causal-association paradigm focuses on the relationship between treatment effects on the surrogate and clinical outcomes, which is central to evaluating surrogates in settings with interference."
  },
  {
    "qid": "fill-in-the-blank-ds-3363",
    "question": "In the VAR-HME model, the conditional probability density function (pdf) of yₜ is given by fₜ(yₜ|Fₜ₋₁,Xₜ;θ), where θ is a parameter vector; Xₜ is the σ-field generated by {xₜ}₁ᵀ representing external information; and, for each t, Fₜ₋₁ is the σ-field generated by {yₛ}₁ᵗ⁻¹ representing the previous history at time t-1. The conditional pdf fₜ is assumed to depend on Xₜ through [BLANK] only.",
    "gold_answer": "xₜ. This is because the conditional pdf fₜ typically depends on the current covariate vector xₜ, not the entire history of covariates."
  },
  {
    "qid": "fill-in-the-blank-ds-2074",
    "question": "In the context of linear random fields, the Beveridge–Nelson decomposition can be expressed as $\\phi(\\mathbf{L}) = \\mu_1 + A_2(\\mathbf{L}) - A_1(\\mathbf{L})$, where $\\mu_1$ represents the sum of the coefficients $\\varphi_{k,l}$. What is the condition required for $\\sum_{k,l\\ge0}|\\varphi_{k,l}^{*}|^{p}<\\infty$ to hold, where $\\varphi_{k,l}^{*} = \\sum_{i\\geq k+1,j\\geq l+1}\\varphi_{i,j}$?",
    "gold_answer": "The condition required is either $\\mathcal{L}_{p}$ for $1 \\leq p < \\infty$ or $\\mathcal{L}_{1,p}$ for $0 < p < 1$. This ensures the convergence of the series $\\sum_{k,l\\ge0}|\\varphi_{k,l}^{*}|^{p}$, highlighting the interplay between the moment conditions for innovations and the conditions on the coefficients $\\varphi_{k,l}$."
  },
  {
    "qid": "fill-in-the-blank-ds-3561",
    "question": "In the context of extreme value theory, the condition that $L(x) = x^{\\alpha}\\mathcal{F}(x)$ should be slowly varying is a necessary and sufficient condition for (1.1) to hold with $G = \\Phi_{\\alpha}$. What is the term used to describe a strengthened form of this slow-variation condition that is necessary for large-deviation probabilities to hold?",
    "gold_answer": "Super-slow variation (SSV). This term is used to describe the condition that $L(x)$ must satisfy beyond regular slow variation to ensure the uniform convergence of large-deviation probabilities as described in the paper."
  },
  {
    "qid": "fill-in-the-blank-ds-1505",
    "question": "In the two-way analysis of variance model without interaction, the intraclass correlation coefficient (ICC) is defined as the ratio of the variance between subjects to the total variance, which includes the variance between subjects, the variance between labs or raters, and the error variance. The formula for ICC is given by [BLANK]. What is the correct formula for ICC in this context?",
    "gold_answer": "ICC = σ_b² / (σ_b² + σ_l² + σ_e²). This formula represents the proportion of the total variance that is attributable to the variance between subjects, highlighting the agreement among measurements across different labs or raters."
  },
  {
    "qid": "fill-in-the-blank-ds-2686",
    "question": "The consistency property of the principal component direction in high-dimensional settings is established under certain conditions. One such condition is that the eigenvalues of the covariance matrix Σ_d^(m) satisfy λ₁^(m) ~ d^α^(m), λ₂^(m) ~ d^θ^(m), and Σ_{i=2}^d λ_i^(m) ~ d, where θ^(m) ∈ [0, α^(m)) and α^(m) ∈ (0, 1]. This condition is referred to as the [BLANK] condition.",
    "gold_answer": "spike. This condition specifies the divergence rates of the eigenvalues, which is crucial for establishing the consistency of PCA and SPCA estimates in high-dimensional settings."
  },
  {
    "qid": "fill-in-the-blank-ds-2615",
    "question": "In the model $y_{i j}=\\mu_{i}+\\beta_{j}+\\epsilon_{i j}$, the term $\\epsilon_{i j}$ is assumed to be a normal variate with zero mean and variance [BLANK]. What is the variance of $\\epsilon_{i j}$?",
    "gold_answer": "$\\sigma_{j}^{2}$. This specifies the variance of the error term for each column (or observer) in the two-way classification model, highlighting the heterogeneity of variances across different observers or methods."
  },
  {
    "qid": "fill-in-the-blank-ds-754",
    "question": "The paper concludes that semiparametric models are flexible enough to forecast out-of-sample better than any linear or nonlinear Taylor rule model, highlighting the importance of not imposing a known functional form for [BLANK].",
    "gold_answer": "f(.). This represents the unknown function in the nonparametric part of the semiparametric model, emphasizing the model's ability to reveal structure in data without fixed assumptions."
  },
  {
    "qid": "fill-in-the-blank-ds-136",
    "question": "In the context of estimating a structural parameter in the presence of nuisance parameters, the Cramer-Rao bound does not necessarily give an attainable lower bound when the number of nuisance parameters increases in proportion to the sample size. The new lower bound proposed is expressed as the inverse of the sum of the partial information and a certain nonnegative term, which is derived by [BLANK] considerations.",
    "gold_answer": "differential-geometrical. This highlights the approach taken to derive the new lower bound, emphasizing the role of differential geometry in understanding the structure and efficiency of estimators in complex statistical models."
  },
  {
    "qid": "fill-in-the-blank-ds-1544",
    "question": "In the expansion of $C_{\\rho}^{*}(V+I)$ as a sum of zonal polynomials, the coefficients $\\boldsymbol{a}_{\\tau\\rho}$ are sometimes called [BLANK]. What is the term used to describe these coefficients?",
    "gold_answer": "generalized binomial coefficients. This term is used because these coefficients play a role analogous to binomial coefficients in the expansion of polynomials."
  },
  {
    "qid": "fill-in-the-blank-ds-2540",
    "question": "In the context of panel count data analysis, ignoring within-subject correlation may lead to [BLANK] in parameter estimation and inference.",
    "gold_answer": "serious problems. This includes biased parameter estimates and underestimated variances, which can result in misleading conclusions about the covariate effects."
  },
  {
    "qid": "fill-in-the-blank-ds-1447",
    "question": "In the context of testing hypotheses involving variance components, the statistic $F^{*}(\\mathbf{s})$ is used under the null hypothesis $H_{0}\\colon\\sum_{i=1}^{m}c_{i}\\sigma_{i}^{2}=\\sum_{i=m+1}^{l}c_{i}\\sigma_{i}^{2}$. The first moment of $F^{*}(\\mathbf{s})$ under $H_{0}$ can be approximated by $1 + 2V_{\\mathbf{u}}^{*} - 8V_{\\mathbf{s1}}^{*} + ...$. What does $V_{n}^{*}$ represent in this context?",
    "gold_answer": "$V_{n}^{*}$ represents the ratio of the sum of the $(c_{i}\\sigma_{i}^{2})^{r}/f_{i}^{r}$ terms for the denominator mean squares to the $r$-th power of the sum of the $c_{i}\\sigma_{i}^{2}$ terms for the denominator. It is part of the series expansion used to approximate the first moment of $F^{*}(\\mathbf{s})$ under the null hypothesis."
  },
  {
    "qid": "fill-in-the-blank-ds-2631",
    "question": "In the context of field trials for evaluating plant varieties, the use of composite samples for each variety is common for traits that are costly to measure. However, this approach precludes the use of an efficient statistical analysis. The proposed approach involves testing a proportion of varieties by using individual replicate samples, while the remaining varieties may be tested as composite samples or with reduced replication. This allows for the application of efficient mixed model analyses for both inexpensive and expensive traits. The missing element in this approach is [BLANK], which is crucial for accommodating spatial trend or design factors based on the original spatial coordinates of all plots.",
    "gold_answer": "the spatial analysis of data derived from a mixture of composite and individual plot samples. This is excluded to highlight the innovative aspect of the proposed approach, which allows for the accommodation of spatial trend and/or design factors based on the original spatial coordinates of all plots, including those used to form the composite samples."
  },
  {
    "qid": "fill-in-the-blank-ds-1038",
    "question": "The variance-based sensitivity model constrains how different the true weights can be from the observable weights by bounding the distributional differences that arise from omitting a confounder, parameterized by an [BLANK] value.",
    "gold_answer": "R². This approach focuses on the variance of the weights rather than worst-case errors, offering a more interpretable and stable sensitivity analysis."
  },
  {
    "qid": "fill-in-the-blank-ds-3112",
    "question": "In all three examples (Pseudo-Bayes Estimators, Aitchison and Aitken's Estimators, Nearest Neighbour Estimators) the bandwidth 9 has a high impact on the performance of the entire kernel estimator. Small bandwidths correspond to little smoothing, and under [BLANK] data are not smoothed at all; in the latter case the kernel estimators result in the frequency estimator.",
    "gold_answer": "ϑ=0. This specifies the condition under which kernel estimators do not apply any smoothing to the data, effectively reverting to the frequency estimator."
  },
  {
    "qid": "fill-in-the-blank-ds-3590",
    "question": "In the grading of apples for the experiment, three sizes were retained, with Grade 1 including those apples which rested on the 2¼-inch ring but passed through the [BLANK]-inch ring.",
    "gold_answer": "2½. This grading was part of the method to categorize apples by size, ensuring that only medium-sized apples were used in the experiment to reduce variability."
  },
  {
    "qid": "fill-in-the-blank-ds-1149",
    "question": "In the context of survival analysis models, the proportional hazard model is given by hY(y|x,m,u) = h0(y)exp(λ1x + λ2m + λ3u). A key condition for the parameters λ1 and λ2 to be identifiable when U is unobserved is that the function ψ1(X) in the model M = ψ1(X) + ψ2(U, εM) is [BLANK].",
    "gold_answer": "not a linear function of X. This non-linearity condition is necessary to ensure that the parameters λ1 and λ2 can be distinguished from each other in the estimation process, allowing for the identification of direct and indirect effects."
  },
  {
    "qid": "fill-in-the-blank-ds-1283",
    "question": "The two-term Edgeworth expansion for the density function fn(x) includes a term that is a homogeneous polynomial in x of degree [BLANK].",
    "gold_answer": "3j"
  },
  {
    "qid": "fill-in-the-blank-ds-73",
    "question": "In the context of nonformation, the concept where a submodel and the corresponding part of the data contain no available information with respect to the parameter of interest is termed as [BLANK].",
    "gold_answer": "nonformation. This term is introduced to describe the scenario where certain parts of the model or data do not contribute any information towards the parameter of interest, highlighting the importance of identifying informative versus non-informative components in statistical inference."
  },
  {
    "qid": "fill-in-the-blank-ds-2488",
    "question": "The conditional likelihood under the proportional risks model for NCC studies, which conditions on a failure of any type at each failure time, is denoted as [BLANK].",
    "gold_answer": "L2(β). This likelihood resembles the full cohort counterpart but with risk sets replaced by sampled risk sets, allowing for the pooling of controls from multiple NCC studies for more efficient estimates."
  },
  {
    "qid": "fill-in-the-blank-ds-1885",
    "question": "In the context of multinormal integrals, the function φₙ(y) is defined as (2π)⁻ⁿ/² exp(f(y)), where f(y) is given by [BLANK]. What is the expression for f(y)?",
    "gold_answer": "-½|y|². This expression represents the exponent in the multinormal density function, highlighting the quadratic form in the exponent."
  },
  {
    "qid": "fill-in-the-blank-ds-146",
    "question": "In the functional linear model (1), the time-varying long-run covariance function for the functional linear model is defined by Σ(t) = ∑_{j=−∞}^{∞} cov{U(t, F₀), U(t, Fⱼ)}, where U(t, Fᵢ) = W(t, Fᵢ)H(t, Fᵢ). What key term is omitted in this definition that is crucial for understanding the nonstationarity of the process?",
    "gold_answer": "The key term omitted is 't ∈ [0,1]', which specifies the time interval over which the long-run covariance function is defined, highlighting the nonstationarity by allowing the covariance to vary over time."
  },
  {
    "qid": "fill-in-the-blank-ds-2070",
    "question": "In the Bayesian hierarchical model for estimating derivative curves, the sequence of quotient differences is constructed using both forward and backward differences to mitigate [BLANK] effects.",
    "gold_answer": "boundary. This approach helps in reducing the bias at the boundaries of the data range, making the derivative estimates more reliable across the entire domain."
  },
  {
    "qid": "fill-in-the-blank-ds-1330",
    "question": "In the random dot product graph model, the edge probability between any two vertices is given by the dot product of their latent positions, formally expressed as [BLANK].",
    "gold_answer": "κ(xi, xj) = xi^T xj. This formula is fundamental to the random dot product graph model, defining how the probability of an edge between two vertices is calculated based on their latent positions."
  },
  {
    "qid": "fill-in-the-blank-ds-1683",
    "question": "In the context of adaptive group-sequential covariate-adjusted randomized clinical trials (RCTs), the parameter of scientific interest on the additive scale is denoted as [BLANK], where W is a vector of baseline covariates, A the treatment assignment, and Y the primary outcome of interest.",
    "gold_answer": "Ψ+ = E{E(Y|A=1,W)−E(Y|A=0,W)}. This represents the marginal effect of treatment a=1 relative to treatment a=0 on the additive scale, also known as the risk difference."
  },
  {
    "qid": "fill-in-the-blank-ds-2641",
    "question": "The condition that for every ${\\mathbf u}\\in[0,1]^{d}$, $C(\\mathbf{u})=0$ when at least one coordinate of $\\mathbf{u}$ is zero, is part of the definition of a [BLANK].",
    "gold_answer": "pseudo-copula. This condition ensures the pseudo-copula meets the basic requirements of a cumulative distribution function."
  },
  {
    "qid": "fill-in-the-blank-ds-675",
    "question": "In the context of optimal designs for $s^{n}$ factorial experiments with correlated observations within blocks, the variance–covariance matrix of the observational vector is given by $Var(\\mathbf{Y})=\\sigma^{2}D\\left(\\Sigma_{1},\\Sigma_{2},\\dots,\\Sigma_{b}\\right)$ where $\\boldsymbol{\\Sigma_{i}}=(1-\\rho)\\mathbf{I}_{k_{i}}+\\rho\\mathbf{J}_{k_{i}}$. What does $\\mathbf{J}_{k_{i}}$ represent in this equation?",
    "gold_answer": "$\\mathbf{J}_{k_{i}}$ represents a $k_{i} \\times k_{i}$ matrix of all ones. This is used to model the correlation structure within blocks, indicating that any two observations within the same block have a constant correlation $\\rho$."
  },
  {
    "qid": "fill-in-the-blank-ds-2639",
    "question": "In the prequential framework, the performance of a Statistical Forecasting System is assessed by comparing the forecast distributions with the realised outcomes using the [BLANK] score.",
    "gold_answer": "logarithmic. The logarithmic score is used because it is an example of a proper scoring rule that motivates honest probability assessment."
  },
  {
    "qid": "fill-in-the-blank-ds-1174",
    "question": "In the context of Bayesian variable selection with very large p, the proposed adaptive Markov chain Monte Carlo algorithms aim to improve performance by exploiting the observation that in large-p, small-n settings, the majority of the p variables will be approximately [BLANK] a posteriori.",
    "gold_answer": "uncorrelated. This observation allows the algorithms to adaptively build nonlocal proposals that result in moves with significantly larger squared jumping distances than standard methods."
  },
  {
    "qid": "fill-in-the-blank-ds-1086",
    "question": "The likelihood ratio spatial scan statistic has been widely used in spatial disease surveillance and spatial cluster detection applications. In order to better understand cluster mechanisms, an equivalent model-based approach is proposed to the spatial scan statistic that unifies currently loosely coupled methods for including ecological covariates in the spatial scan test. In addition, the utility of the model-based approach with a [BLANK]-based scan statistic is demonstrated to account for overdispersion and heterogeneity in background rates.",
    "gold_answer": "Wald. The Wald-based scan statistic is introduced as a method to account for overdispersion and heterogeneity, showcasing the flexibility of the model-based approach beyond the likelihood ratio method."
  },
  {
    "qid": "fill-in-the-blank-ds-383",
    "question": "The condition for the MS AMEM to be stationary and ergodic is given by Σ_{s_t=1}^n π_{s_t} E[log{(α_{s_t} + γ_{s_t} D_t) ε_t + β_{s_t}}] < 0. What does π_{s_t} represent in this condition?",
    "gold_answer": "π_{s_t} represents the ergodic probability of state s_t. This condition ensures that the model's parameters are set in such a way that the process does not explode over time, maintaining stability."
  },
  {
    "qid": "fill-in-the-blank-ds-602",
    "question": "In the proposed CMPMOB algorithm, to reduce computational complexity in split point estimation, tools from [BLANK] methodology are borrowed, proposing a new method that uses only the estimated score functions without fitting models for each split point.",
    "gold_answer": "change point estimation. This approach simplifies the exhaustive search traditionally used in the MOB algorithm, making it computationally more efficient."
  },
  {
    "qid": "fill-in-the-blank-ds-1546",
    "question": "In the context of analyzing sickness rates using Makeham's hypothesis, the force of sickness at any age is expressed in the form [BLANK], where A and B are constants, and c is a base for the exponential function.",
    "gold_answer": "A + Bc^x. This formula represents the Makeham's hypothesis for the force of sickness, combining a constant term A with an exponential term Bc^x to model the rate of sickness at age x."
  },
  {
    "qid": "fill-in-the-blank-ds-711",
    "question": "The familywise error rate, FWER, is the probability of making [BLANK] false discovery, while the FDR is the expected proportion of false positives.",
    "gold_answer": "one. This highlights the stringent control of Type I errors provided by FWER, focusing on the probability of at least one false discovery."
  },
  {
    "qid": "fill-in-the-blank-ds-1187",
    "question": "The approximate score equations derived from the random subsampling framework are equivalent to logistic regression score equations. This equivalence allows for the use of standard, 'off-the-shelf' software in fitting these models, significantly simplifying the implementation process. The key to this equivalence is the inclusion of an offset related to the [BLANK] in the logistic regression model.",
    "gold_answer": "subsampling rate. This offset accounts for the differential sampling probabilities across time points, ensuring that the logistic regression accurately reflects the underlying recurrent event process."
  },
  {
    "qid": "fill-in-the-blank-ds-919",
    "question": "The application of the cluster method based on redescending M-estimators to edge identification in noisy images involves estimating points that may belong to edges using the rotational density kernel estimator (RDKE). The choice of the window size $h_{N}$ for the RDKE method is critical and is often chosen relative to the size of the object to be detected, e.g., $10\\%$ of it. For a triangle with a diameter of 68 pixels, the window size would be $[BLANK]$.",
    "gold_answer": "6.8. This choice is based on the guideline to set the window size to approximately 10% of the object's size, ensuring that the RDKE method can effectively estimate points belonging to the edges without being too sensitive to noise."
  },
  {
    "qid": "fill-in-the-blank-ds-256",
    "question": "In bioequivalence studies, the FDA recommends a $2\\times2$ crossover design where typically 24 subjects are randomly divided into two groups. One group is given the brand-name drug first and then the new drug after a wash-out period, while the other group is treated in the reverse order. The blood samples are collected from each subject at various times to obtain a blood concentration curve against time of a certain ingredient. The three most typical characteristics of the blood concentration curve considered are the area under the concentration curve, [BLANK], the maximum concentration, $C_{\\mathrm{max}}$, and the time to reach the maximum concentration, $T_{\\mathrm{max}}$. Which characteristic is missing here?",
    "gold_answer": "AUC (Area Under the Curve). This is one of the key pharmacokinetic parameters used to assess the extent of drug absorption in bioequivalence studies."
  },
  {
    "qid": "fill-in-the-blank-ds-3082",
    "question": "In the context of conditional versions of Spearman’s rho, the measure ρ(g) is defined as the normalized average distance between the copula C and the independence copula Π, weighted by a function g. The formula is given by ρ(g) = [∫[0,1]d C(u)g(u)du - ∫[0,1]d Π(u)g(u)du] / [∫[0,1]d M(u)g(u)du - ∫[0,1]d Π(u)g(u)du]. What key function is omitted in the numerator to emphasize the weighted difference between the copula C and the independence copula Π?",
    "gold_answer": "C(u)g(u). This is omitted to highlight that the numerator represents the weighted difference between the copula C and the independence copula Π, emphasizing the role of the weighting function g in measuring dependence."
  },
  {
    "qid": "fill-in-the-blank-ds-1632",
    "question": "In the spiked population model, all the population eigenvalues are equal to 1 except for a few fixed, larger eigenvalues that carry the relevant information. The behavior of the sample eigenvalues of the spiked population model in the high-dimensional case has been thoroughly studied in the past decade; see, e.g., [3,2,19]. In a remarkable result, Baik et al. [2] proved that the asymptotic behavior of the sample eigenvalues experiences a phase transition. If a population eigenvalue from the spike is not big enough, its value cannot be recovered from the samples: the estimated eigenvalue gets pulled towards the bulk, the noisy section of the matrix. On the other hand, if the spike population eigenvalue is bigger than a certain threshold, its value can be recovered from the limit of the estimates, which are, however, [BLANK].",
    "gold_answer": "biased"
  },
  {
    "qid": "fill-in-the-blank-ds-3133",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a pattern–mixture perspective, where we distinguish subpopulations according to their missingness patterns. Suppose we rely on the ‘neighboring case missing value’ approach (NCMV) so that missing values in a partially observed sequence borrow information only from the next identified pattern. If we consider the subpopulation distribution $f(Y | pattern)$, we multiply this by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern ($f(pattern)$). We omit it to underscore that each pattern has a distinct distribution of Y, and combining them in a pattern–mixture approach requires weighting by the relative frequency of each pattern."
  },
  {
    "qid": "fill-in-the-blank-ds-967",
    "question": "The estimator F̂_B(z), proposed as an alternative to NP MLE and self-consistent estimators, is obtained by assigning heavier weights to all 'observed failures' and is defined as [BLANK].",
    "gold_answer": "F̂_B(z) = ∏_{z_j < z, δ_j = 1, A_j = 1} (1 - d_j / r_j)^{1/p̂}. This estimator adjusts for the uncertainty in cause-of-death assessments by emphasizing the contributions of observed failures, where p̂ is the estimated probability of observing the cause of death."
  },
  {
    "qid": "fill-in-the-blank-ds-1397",
    "question": "The limiting null distribution of the BHEP test statistic $T_{n,\\beta}$ under the hypothesis of multivariate normality is that of $\\sum_{j\\geq1}\\delta_{j}(\\beta)N_{j}^{2}$, where $N_{1},N_{2},...$ are i.i.d. standard normal random variables and $(\\delta_{j}(\\beta))_{j\\geqslant1}$ is a sequence of eigenvalues. These eigenvalues are associated with an integral operator defined by the covariance kernel $K(s,t)$. What is the expression for $K(s,t)$?",
    "gold_answer": "The covariance kernel $K(s,t)$ is given by $K(s,t)=\\exp\\bigg(-\\frac{\\|s-t\\|^{2}}{2}\\bigg)-\\bigg\\{1+s^{\\prime}t+\\frac{(s^{\\prime}t)^{2}}{2}\\bigg\\}\\exp\\bigg(-\\frac{\\|s\\|^{2}+\\|t\\|^{2}}{2}\\bigg)$. This kernel defines the covariance structure of the limiting Gaussian process."
  },
  {
    "qid": "fill-in-the-blank-ds-471",
    "question": "The wavelet variance provides a scale-based decomposition of the variance of a time series, and a large var. $(W_{\\tau,t}^{\\mathrm{H}})$ for a particular $\\tau$ should provide the basis for defining a characteristic scale that is in the neighbourhood of $\\tau$. The goal of the paper is to expand this key idea to define a wavelet-based characteristic scale and to provide theory for a corresponding statistically tractable [BLANK].",
    "gold_answer": "estimator. The blank is filled with 'estimator' to highlight the paper's focus on developing a method to estimate the wavelet-based characteristic scale statistically."
  },
  {
    "qid": "fill-in-the-blank-ds-3514",
    "question": "The joint composite estimating function approach to estimating spatiotemporal covariance structures is rooted in the construction of three sets of estimating functions from spatial, temporal, and [BLANK] cross-pairs, which results in overidentified estimating functions.",
    "gold_answer": "spatiotemporal. This highlights the method's unique approach by combining information from different types of pairs to improve estimation efficiency."
  },
  {
    "qid": "fill-in-the-blank-ds-2767",
    "question": "In the semiparametric transformation model $\\varLambda_{\\theta}(Y)=m(X)+\\varepsilon$, where $X$ is a $d$-dimensional covariate, $Y$ is a univariate dependent variable, and $\\varepsilon$ is an error term independent of $X$, the transformation $\\varLambda_{\\theta}(Y)$ is assumed to belong to a parametric family of strictly increasing functions. The parameter $\\theta$ is estimated using a [BLANK] estimator.",
    "gold_answer": "profile likelihood. The profile likelihood estimator is used for the parameter θ in the semiparametric transformation model, highlighting its role in estimating the transformation parameter within a parametric family of strictly increasing functions."
  },
  {
    "qid": "fill-in-the-blank-ds-490",
    "question": "The estimator 𝑇̂𝑛(𝑏) becomes efficient in the normal case when the tuning parameter 𝑏 is set to [BLANK].",
    "gold_answer": "𝑏∗ = −𝜌0 / (1 + 𝜌0^2). This optimal weight minimizes the variance of the estimator, making it efficient in estimating the correlation coefficient 𝜌0 in the normal case."
  },
  {
    "qid": "fill-in-the-blank-ds-2108",
    "question": "The generalized logit (GL) transformation for an original time series {x_t} is given by y_t = γ(x_t;ν) = ln(x_t^ν / (1 - x_t^ν)), where ν > 0 and x_t ∈ (0,1). The inverse transformation is x_t = γ^(-1)(y_t;ν) = [BLANK]. What is the correct expression for the inverse generalized logit transformation?",
    "gold_answer": "{1 + 1/exp(y_t)}^(-1/ν). This expression correctly represents the inverse transformation, allowing the original variable x_t to be recovered from the transformed variable y_t."
  },
  {
    "qid": "fill-in-the-blank-ds-7",
    "question": "The P.D.F. of the tth order statistic in a random sample of size k from a population with C.D.F. F(x) and P.D.F. f(x) at x satisfies the recurrence equation f_{i,k}(x) = [BLANK] - (k - i + 1)/(t - 1)f_{i-1,k}(x) for t=2,3,...,k.",
    "gold_answer": "k/(t - 1)f_{i-1,k-1}(x). This term is crucial for expressing the P.D.F. of the tth order statistic in terms of the P.D.F.s of order statistics from smaller samples."
  },
  {
    "qid": "fill-in-the-blank-ds-993",
    "question": "The auxiliary mixture sampler for the stochastic volatility model approximates the bivariate conditional density of (ξₜ, ηₜ)|dₜ by a [BLANK]-components mixture of bivariate Gaussian densities.",
    "gold_answer": "K. This approximation allows for the efficient sampling of the latent variables by transforming the model into a linear Gaussian state space model conditioned on the mixture component indicator."
  },
  {
    "qid": "fill-in-the-blank-ds-2195",
    "question": "In the mover-stayer model, the transition probabilities for an m state Markov chain are given by πᵢⱼ = (1 - sᵢ)pⱼ for i ≠ j and πᵢᵢ = (1 - sᵢ)pᵢ + sᵢ for i = j. Here, {pₖ} is a probability distribution and sᵢ represents the probability of staying in state i. The constraints on sᵢ are that [BLANK] must be non-negative for all i.",
    "gold_answer": "1 - sᵢ. This constraint ensures that the probability of moving from state i to any other state j (i ≠ j) is non-negative, maintaining the validity of the transition probabilities."
  },
  {
    "qid": "fill-in-the-blank-ds-3007",
    "question": "The study concluded that the inheritance of psychical characters, such as ability, follows the same laws as physical characters, with a slope of the regression line around [BLANK].",
    "gold_answer": "0.47. This finding supports the hypothesis that mental and moral characters are inherited in the same manner and with similar intensity as physical traits."
  },
  {
    "qid": "fill-in-the-blank-ds-2788",
    "question": "The Laplace transform of a real scalar random variable X with density f(x) is given by L_f(s) = {sum_{j=1}^{m'}(1 + beta_j s)^{-alpha_j}} exp{-tr A - s tr B + tr(I + s C)^{-1}A}, where R(alpha_j) > 0, R(1 + beta_j s) > 0 for j = 1, ..., m', and C is a real symmetric matrix. The term [BLANK] is crucial for ensuring that L_f(s) is indeed a Laplace transform.",
    "gold_answer": "R(alpha_j) > 0, R(1 + beta_j s) > 0. These conditions are necessary to ensure the convergence of the Laplace transform, making it a valid representation of the density function's transform."
  },
  {
    "qid": "fill-in-the-blank-ds-1777",
    "question": "In the context of Bayesian nonparametric models for circular data, the projected Pólya tree (PPT) model is centered around a parametric probability measure, typically a bivariate normal distribution. The projection of this bivariate distribution to the unit circle defines the PPT model, which is characterized by its depth M, precision parameter α, and a function ρ(m) that controls the speed of variance decay. The function ρ(m) is suggested to be ρ(m) = m^δ, where δ > 1 ensures the process is absolutely continuous. What value of δ is suggested to maximize the dispersion of a finite tree and make the prior less informative?",
    "gold_answer": "δ = 1.1. This value is suggested to maximize the dispersion of a finite tree and make the prior less informative, as it is close to one but still ensures the process is absolutely continuous."
  },
  {
    "qid": "fill-in-the-blank-ds-1966",
    "question": "In the context of wavelet-based functional linear mixed models, the discrete wavelet transform (DWT) is used to approximate the sample curve, x(t), using a finite basis expansion. The equation for this approximation is x(t) = Σ from l=1 to L_S of c_Sl φ_Sl(t) + Σ from s=1 to S Σ from l=1 to L_s of d_sl ψ_sl(t). What does the term [BLANK] represent in this equation?",
    "gold_answer": "d_sl ψ_sl(t). This term represents the detail coefficients at scale s and location l, capturing finer details of the curve."
  },
  {
    "qid": "fill-in-the-blank-ds-1064",
    "question": "In the context of microarray data analysis, the method that projects high-dimensional data onto a line and performs classification in this one-dimensional space, maximizing the distance between the means of the two classes while minimizing the variance within each class, is known as [BLANK].",
    "gold_answer": "Fisher’s linear discriminant analysis (FLDA). This method is highlighted for its approach to classification by optimizing the separation between classes while minimizing within-class variance, making it suitable for microarray data analysis where distinguishing between classes based on gene expression is crucial."
  },
  {
    "qid": "fill-in-the-blank-ds-1643",
    "question": "In the quantile regression model with power transformation, the basic assumption is that the transformation parameter and the regression coefficient depend on quantiles and may change from quantile to quantile. This model is referred to as [BLANK].",
    "gold_answer": "PQR (Power Transformed Quantile Regression). This is excluded to highlight the model's flexibility and complexity, which allows for different transformations and coefficients across quantiles."
  },
  {
    "qid": "fill-in-the-blank-ds-1448",
    "question": "In the model $Y_{i t}=X_{i t}\\beta+F_{t}A_{i}^{\\prime}+\\epsilon_{i t}$, the term $F_{t}A_{i}^{\\prime}$ represents the [BLANK] structure.",
    "gold_answer": "unobserved factor. This term captures the interaction between unobservable common time-varying factors and individual-specific factor loadings, highlighting the model's ability to account for unobserved heterogeneity."
  },
  {
    "qid": "fill-in-the-blank-ds-1868",
    "question": "In the context of testing the correct specification of general conditional location parametric functionals, the Cramér-von Mises (CvM) test statistic is given by CvM_{n,w,ψ} = ∫_π |R_{n,w}^1(x)|^2 ψ(dx), where R_{n,w}^1(x) is the residual marked empirical process and ψ is an integrating function. The term [BLANK] is crucial for the computation of the CvM test statistic as it represents the integrating function.",
    "gold_answer": "ψ(dx). This term is essential as it defines the measure over which the squared norm of the residual marked empirical process is integrated, thereby influencing the test statistic's value and its sensitivity to deviations from the null hypothesis."
  },
  {
    "qid": "fill-in-the-blank-ds-2770",
    "question": "The proposed semiparametric Wald statistic for testing H₀: AUC = AUC₀ versus H₁: AUC ≠ AUC₀ under model (1.2) is given by Ỹₙ = √n(ÃUC - AUC₀)/σ̃, where σ̃² is the [BLANK] of σ²(α₀, β₀, G).",
    "gold_answer": "maximum semiparametric likelihood estimator. This estimator is used to approximate the asymptotic variance of the test statistic under the null hypothesis."
  },
  {
    "qid": "fill-in-the-blank-ds-558",
    "question": "In the context of Bayesian density estimation using nonparametric hierarchical mixtures, the class of mixtures considered is very flexible in the detection of clusters in the data. This class is characterized by mixtures of parametric densities on the positive reals with a [BLANK] as mixing measure.",
    "gold_answer": "normalized generalized gamma process. This mixing measure is chosen for its flexibility in detecting clusters and its ability to model complex data structures effectively."
  },
  {
    "qid": "fill-in-the-blank-ds-3392",
    "question": "The expected number of orders per unit time under formulations A and B is given by [BLANK], where Q is the average quantity demanded per unit time and R is the average size of an order.",
    "gold_answer": "Q/R. This formula represents the ratio of the average quantity demanded per unit time to the average size of an order, giving the expected number of orders needed to meet demand."
  },
  {
    "qid": "fill-in-the-blank-ds-2177",
    "question": "In the context of two-stage maximum likelihood estimation for copulas, the estimator is consistent for a well-defined least false parameter value, different from the analogous least false parameter associated with the full maximum likelihood procedure. This least false parameter value is denoted as [BLANK].",
    "gold_answer": "η₀,₂ML. This notation is used to simplify the representation of the least false parameter value associated with two-stage maximum likelihood estimation, distinguishing it from the full maximum likelihood procedure's least false parameter."
  },
  {
    "qid": "fill-in-the-blank-ds-347",
    "question": "In the context of meta-analysis, the simple heterogeneity variance estimator proposed is denoted by [BLANK], which is derived from the weighted residual sum of squares in the framework of a linear regression model without covariates.",
    "gold_answer": "SH (Simple Heterogeneity). This notation is used to distinguish the proposed estimator from other estimators in the literature, emphasizing its simplicity and the method of derivation."
  },
  {
    "qid": "fill-in-the-blank-ds-2384",
    "question": "The Box–Cox class of power transformations for the response variable Y is defined as y^(ρ) = {(y^ρ - 1)/ρ for ρ ≠ 0, log(y) for ρ = 0}. In the methodology described, ρ is limited to the values [BLANK] to ensure interpretability of the transformed predictors.",
    "gold_answer": "(-1, 0, 0.5, 1). These values allow the transformed predictors to be roughly interpreted as the reciprocal, the logarithm, the square root, and the untransformed response, respectively."
  },
  {
    "qid": "fill-in-the-blank-ds-746",
    "question": "In the context of marked point processes, the nth order intensity/product density function ρ(n) can be expressed in terms of the nth order product density of the ground process ρg(n) and a conditional density function fx1,...,xn(·) on the mark space. The expression is ρ(n)((x1,m1),...,(xn,mn)) = [BLANK] × ρg(n)(x1,...,xn). What is the missing term that describes the joint distribution of n marks given their associated ground process points?",
    "gold_answer": "fx1,...,xn(m1,...,mn). This term is crucial as it describes how the marks are jointly distributed given the locations of their associated points in the ground process, linking the spatial and mark components of the point process."
  },
  {
    "qid": "fill-in-the-blank-ds-465",
    "question": "The gamma distribution with scale parameter θ and shape parameter ρ, denoted by Γ(ρ,θ), is the distribution with probability density f(x;ρ,θ) = {θ^ρ Γ(ρ)}^-1 x^(ρ-1) exp(-x/θ) for x, ρ, θ > 0. The detection of outliers is important for checking data for gross errors and in model-building, especially when the gamma distribution is suggested as a pragmatic fit to skewed data. In the context of testing for outliers in a gamma sample where both parameters are unknown, the test statistic proposed by Kimber (1979) for an outlier in an unspecified direction is Z = max D_i / Σ D_i, where D_i = -log U_i - (n-1)log{(n-U_i)/(n-1)} and U_i = x_i / x̄. A large value of Z is evidence against the null hypothesis H_0. For large ρ, the distribution of Z depends little on ρ, and √{(n-1)Z} approaches the [BLANK], which is the basis for the optimal two-sided test for a single outlier in the Normal (ρ=∞) case.",
    "gold_answer": "maximum absolute studentized residual (MASR). This is omitted to highlight the connection between the test statistic Z for gamma samples and its optimal counterpart in the Normal case, emphasizing the utility of Z across different distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-2239",
    "question": "The recurrence relation for the content of regular hyperspherical simplices is given by V_{β,β}(θ) = 1/2^β + (β(β-1))/(4π) ∫_{π/2}^{θ} V_{β-2,β-2}(φ(θ')) dθ', where φ(θ') = cos^{-1}(λ/(1-2λ)) and λ = [BLANK].",
    "gold_answer": "-cos(θ'). This defines the transformation used in the recurrence relation for simplifying the integral."
  },
  {
    "qid": "fill-in-the-blank-ds-1888",
    "question": "In the context of binomial sampling schemes, the information about the unknown proportion θ can be measured using Shannon's concept of information, which is expressed as Iθ = ∫ p(θ)log p(θ)dθ. This integral is unique apart from an arbitrary multiplying constant, which is incorporated in the arbitrariness of the [BLANK].",
    "gold_answer": "base of the logarithm. This highlights the flexibility in choosing the logarithmic base when calculating Shannon's information measure, without affecting the fundamental properties of the measure."
  },
  {
    "qid": "fill-in-the-blank-ds-2356",
    "question": "In the penalized h-likelihood (HL) method for variable selection in general semiparametric frailty models, the penalty function that is unbounded at the origin and gives a very good performance in various high-dimensional problems is known as [BLANK].",
    "gold_answer": "HL penalty. This penalty is unbounded at the origin, distinguishing it from other penalties like LASSO and SCAD, and is particularly effective in high-dimensional problems due to its ability to provide oracle shrinkage estimators."
  },
  {
    "qid": "fill-in-the-blank-ds-2730",
    "question": "In the context of stepped wedge cluster randomized experiments (SW-CREs), the model-assisted ANCOVA estimator that includes treatment-by-covariate interactions but without period-specific covariate effects is referred to as [BLANK].",
    "gold_answer": "ANCOVA III. This model is highlighted for its efficiency and robustness in estimating treatment effects, especially when the number of clusters is limited."
  },
  {
    "qid": "fill-in-the-blank-ds-3035",
    "question": "The higher criticism test statistic is the supremum of a standardized empirical process under the null hypothesis and follows a [BLANK] distribution asymptotically, but its convergence is very slow and its $p$ -value cannot be reliably computed analytically based on asymptotic theory unless $d$ is very large.",
    "gold_answer": "Gumbel. This distribution is mentioned as the asymptotic distribution of the higher criticism test statistic, highlighting the challenge of relying on asymptotic theory for $p$-value computation when $d$ is not sufficiently large."
  },
  {
    "qid": "fill-in-the-blank-ds-2616",
    "question": "In the context of estimating $c$-level partial correlation graphs, the proposed method is adaptive to the 'large $p$, small $n$' scenario commonly seen in whole brain studies. The method incorporates the variation of the estimated partial correlations, which results in higher power compared to the existing methods. The key innovation of the proposed method over graphical Lasso and neighborhood selection is its ability to provide [BLANK] to each pair of partial correlations.",
    "gold_answer": "confidence intervals. This is omitted to highlight the method's capability to offer more detailed statistical inference, distinguishing it from other methods that lack this feature."
  },
  {
    "qid": "fill-in-the-blank-ds-2569",
    "question": "In the proposed model, the total damage incurred up to time t, X(t), is modeled as the sum of damages from N(t) storms, where N(t) is a [BLANK] process for storm counts.",
    "gold_answer": "Poisson. This term is critical to define the stochastic process used for modeling the number of storm events over time."
  },
  {
    "qid": "fill-in-the-blank-ds-77",
    "question": "In the context of testing linearity of regression, the simple formula suggested for Σₚ² is Σₚ² = (1/N) * ( (1/r²) - (1/η²) ), under the assumption that [BLANK] is small.",
    "gold_answer": "ζ/r"
  },
  {
    "qid": "fill-in-the-blank-ds-366",
    "question": "A proportional-integral-plus (PIP) controller includes an integrated error term to ensure the output tracks the target INR at steady state, despite modelling errors, by adding the term [BLANK] to the control equation.",
    "gold_answer": "k₂eₜ. This term is crucial for the PIP controller's ability to adjust for cumulative errors over time, enhancing its robustness against model inaccuracies and disturbances."
  },
  {
    "qid": "fill-in-the-blank-ds-3036",
    "question": "In the context of generalized estimating equations (GEE), valid inference requires the mean for the response at time $t$ to be expressed properly as a function of the complete past, present, and future values of any time-varying covariate. This condition is especially important with environmental exposures, where it may be necessary to express the response as a function of multiple lagged values of the covariate series. The condition that ensures the mean, given all past, present, and future covariate values, is equal to the cross-sectional mean is known as [BLANK].",
    "gold_answer": "the full covariate conditional mean (FCCM) equality to the cross-sectional mean (CSM). This condition is crucial to avoid bias in parameter estimates for time-varying covariates when using nonindependence working correlation matrices in GEE."
  },
  {
    "qid": "fill-in-the-blank-ds-2914",
    "question": "In the context of soft calibration for selection bias problems under mixed-effects models, the main idea is to calibrate the biased sample to the benchmark by adjusting the subject weights. However, hard calibration can produce enormous weights when an exact calibration is enforced on a large set of extraneous covariates. To address this, the article proposes a [BLANK] scheme, where the outcome and the selection indicator follow mixed-effect models.",
    "gold_answer": "soft calibration. This approach imposes an exact calibration on the fixed effects and an approximate calibration on the random effects, offering a more efficient estimation compared to hard calibration."
  },
  {
    "qid": "fill-in-the-blank-ds-1882",
    "question": "In the context of nonparametric drift estimation from diffusions with correlated Brownian motions, the integrated mean squared risk of the proposed nonparametric estimator is bounded and an adaptive procedure is proposed. The dependency is modeled through correlations between the Brownian motions driving the diffusion processes, and the estimator does not use the knowledge of the [BLANK]. What is the missing term?",
    "gold_answer": "correlation matrix. The missing term highlights that the estimator is designed to work without prior knowledge of the correlation structure between the Brownian motions, making it adaptable to various dependency scenarios."
  },
  {
    "qid": "fill-in-the-blank-ds-1266",
    "question": "In the non-homogeneous two-state Markov chain model described, the transition probabilities at week t are represented by a matrix where p(t) = P[Y_{t+1} = 0 | Y_t = 0] and q(t) = P[Y_{t+1} = 0 | Y_t = 1]. These probabilities are made to depend on k explanatory variables through the multiple logistic function, where α_t = exp[θ_{00} + θ_{01}x_1(t) + ... + θ_{0k}x_k(t)] and β_t = exp[θ_{10} + θ_{11}x_1(t) + ... + [BLANK]]. What is the missing part of the equation for β_t?",
    "gold_answer": "θ_{1k}x_k(t). This part is crucial for defining how the transition probability from state 1 to state 0 depends on the k-th explanatory variable at week t."
  },
  {
    "qid": "fill-in-the-blank-ds-3571",
    "question": "The estimator for the reciprocal-shape parameter of the Weibull distribution, as described, uses two suitably selected order statistics from a sample of N failure times and is given by the formula: \\(\\widehat{\\gamma}=(\\ln T_{(m)}-\\ln T_{(l)})B(N,l,m)\\), where \\(B(N,l,m)\\) is an unbiasing factor determined by \\(E(\\hat{\\gamma})=\\gamma\\). The normalized variance of the estimator is denoted by [BLANK]. What term is used to denote this normalized variance?",
    "gold_answer": "\\(g^{2}(N,l,m)\\). This term represents the variance of the estimator \\(\\widehat{\\gamma}\\) normalized by \\(\\gamma^{2}\\), highlighting its relative variability."
  },
  {
    "qid": "fill-in-the-blank-ds-1273",
    "question": "In the context of estimating parameters with values in a manifold, the Cramér-Rao type lower bound for minimum loss unbiased estimators is derived, and the corresponding notion of [BLANK] is investigated.",
    "gold_answer": "efficiency. This term is omitted to highlight the focus on how well an estimator performs relative to the lower bound, which is a key aspect of the investigation."
  },
  {
    "qid": "fill-in-the-blank-ds-1529",
    "question": "In the RKHS functional regression model, the expression ⟨X, β⟩_K must be interpreted as ψ_X^{-1}(β), where ψ_X is defined in terms of the process X. What does ψ_X(Y)(t) represent?",
    "gold_answer": "ψ_X(Y)(t) = E[Y{X(t) - m(t)}]. This represents the function that maps a random variable Y to its covariance with the centered process X(t) - m(t), highlighting the role of ψ_X in connecting the RKHS with the space of random variables."
  },
  {
    "qid": "fill-in-the-blank-ds-666",
    "question": "In the context of high-dimensional generalized linear models, ridge estimators regularize the squared Euclidean lengths of parameters and involve tuning parameters that need to be calibrated. The paper suggests modifying ridge estimators to avoid tuning parameters altogether, leading to an estimator referred to as [BLANK].",
    "gold_answer": "t-ridge. This modification integrates the calibration of the tuning parameter directly into the estimation process, eliminating the need for external calibration methods like cross-validation."
  },
  {
    "qid": "fill-in-the-blank-ds-126",
    "question": "In the context of generalized structured models, the equation $$\\Lambda(Y)=G\\{Z,\\beta,g(X)\\}+S\\{U,\\gamma,s(T)\\}\\epsilon,$$ with $E(\\epsilon\\mid Z,X,U,T)\\:=\\:0$, includes known functions $\\Lambda, G$, and $S$, unknown finite-dimensional parameters $\\beta,\\gamma$, and unknown nonparametric functions $g(\\cdot),s(\\cdot)$. The dependent variable $Y$ and observed covariates $(Z,X,U,T)$ are part of this model. What critical element is represented by [BLANK] in this equation?",
    "gold_answer": "$\\epsilon$, which represents the error term with conditional mean zero given the covariates. This element is crucial as it captures the random variation in the dependent variable $Y$ not explained by the model's systematic part."
  },
  {
    "qid": "fill-in-the-blank-ds-2249",
    "question": "In the context of robust regression, the DCML estimator is defined by maximizing the likelihood under the constraint that the distance between the initial robust estimator and the proposed estimator is less than a given threshold. This distance is based on the [BLANK] divergence.",
    "gold_answer": "Kullback–Leibler (KL). The KL divergence is chosen for this purpose because it yields easily manageable results and is a measure of the difference between two probability distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-2072",
    "question": "A key assumption in the model for missing response values is that the missingness mechanism is [BLANK], allowing the full data model to be specified independently of the observed data model.",
    "gold_answer": "ignorable. This assumption simplifies the analysis by enabling the use of the same inference techniques without explicitly modeling the missingness mechanism."
  },
  {
    "qid": "fill-in-the-blank-ds-3203",
    "question": "In the context of length-biased sampling, the density of the length-biased version $T_{\\mathrm{LB}}$ is given by $F_{\\mathrm{LB}}(t)=\\int_{0}^{t}x d F_{T}(x)\\mu_{T}^{-1}$ , $t\\geq0$ , where $\\mu_{T}$ is the mean of the distribution given by $\\textstyle\\int_{0}^{\\infty}x d F_{T}(x)$. The term [BLANK] is crucial for understanding the transformation from the original distribution to its length-biased counterpart.",
    "gold_answer": "$\\mu_{T}^{-1}$. This term scales the integral to ensure the length-biased distribution is properly normalized, reflecting the increased likelihood of observing longer intervals under length-biased sampling."
  },
  {
    "qid": "fill-in-the-blank-ds-306",
    "question": "In the Poisson field of discs model, the probability that a primary disc of radius r₀ will remain a circular clump of radius r₀ in the final pattern is given by P(r₀) = exp[-λπ{4r₀∫₀^{r₀} r f(r) dr + ∫_{r₀}^∞ (r₀ + r)² f(r) dr}]. The secondary density f* is then proportional to [BLANK].",
    "gold_answer": "P(r₀)f(r₀). This is because the secondary density f* accounts for the probability that a disc remains a circular clump and its original distribution f(r₀)."
  },
  {
    "qid": "fill-in-the-blank-ds-709",
    "question": "In the context of estimating a patterned covariance matrix Σ, the decomposition Σ = ∑_{i=1}^k θ_i M_i involves θ_i as the distinct unknown eigenvalues and M_i as a known complete orthogonal set of projection matrices. The problem of estimating Σ under the loss function L_q(Σ̂, Σ) = tr(Σ̂ - Σ)^2 is dual to the problem of estimating the scale parameters of independent χ^2 distributions under the loss L(θ̂, θ) = ∑_{i=1}^k p_i (θ̂_i - θ_i)^2, where p_i = rank(M_i). What is the form of the maximum likelihood estimator (MLE) of θ_i^s in this context?",
    "gold_answer": "Q_i^s / p_i^s. The MLE of θ_i^s is derived from the likelihood function of the independent χ^2 random variables Q_i, which are scaled by θ_i, highlighting the direct relationship between the estimation problems under the specified loss functions."
  },
  {
    "qid": "fill-in-the-blank-ds-528",
    "question": "A key constraint for a function $_g$ to be the density generator of an elliptical distribution is $s_{d}\\int_{0}^{\\infty}r^{d-1}g(r^{2})d r=s_{d}\\int_{0}^{\\infty}t^{d/2-1}g(t)d t/2=[BLANK]$.",
    "gold_answer": "1. This value is omitted to underscore the normalization condition that density generators must satisfy."
  },
  {
    "qid": "fill-in-the-blank-ds-3303",
    "question": "The statistic $M_{\\sun}$ is defined as $(F/t_{m s}-1)(F/t_{m s}+1)^{-1}$. It approaches $+1\\cdot0$ when $F\\gg t_{m s}$, equals zero when $F=t_{m s}$, and approaches $-1{\\cdot}0$ if $F\\ll t_{m\\pmb{\\theta}}$. For the special case $p=2$, regression algebra shows that a lower value is not possible, giving $\\pmb{M}$ a lower bound of [BLANK].",
    "gold_answer": "-0·33. This value is derived from regression algebra for the special case when there are two regressors, indicating the minimum possible value of the M statistic under these conditions."
  },
  {
    "qid": "fill-in-the-blank-ds-1157",
    "question": "In the context of multivariate branching-Markov processes (BMP), the limit distributions of the estimators are shown to be mixtures of normals rather than normal. This is due to the models discussed in this paper belonging to the [BLANK] family.",
    "gold_answer": "local asymptotic mixed normal (LAMN). This family is significant because it leads to non-standard limit results for estimators and tests, distinguishing BMP models from those with standard normal limit distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-1249",
    "question": "In the context of group selection and shrinkage for semiparametric additive models, the group subset estimator with shrinkage can be expressed as minimizing the sum of the loss function and two penalty terms. The first penalty term controls group sparsity via group subset selection, and the second penalty term introduces shrinkage via group lasso. The missing term in the equation is [BLANK], where λ0k and λ1k are tuning parameters for the k-th group.",
    "gold_answer": "λ0k𝟙(‖βk‖≠0) + λ1k‖βk‖. This term combines the penalties for group subset selection (λ0k𝟙(‖βk‖≠0)) and group lasso (λ1k‖βk‖), allowing for both sparsity within groups and shrinkage of the coefficients."
  },
  {
    "qid": "fill-in-the-blank-ds-258",
    "question": "In the proximal distance algorithm for sparse covariance estimation, the objective function is minimized subject to the constraint that the covariance matrix belongs to the sparsity set. The sparsity set is defined as all symmetric matrices with at most [BLANK] nonzero entries in their upper triangle.",
    "gold_answer": "2K. The sparsity set is defined to include all symmetric matrices with at most 2K nonzero entries in their upper triangle, where K is the number of nonzero entries specified for the upper triangle, and the diagonal entries are unconstrained."
  },
  {
    "qid": "fill-in-the-blank-ds-216",
    "question": "In the context of testing the randomness of points on a line, the sum of squares of intervals along a line was first discussed by [BLANK].",
    "gold_answer": "Greenwood (1946). This reference is omitted to highlight the historical context and the foundational work in the field of randomness tests on a line."
  },
  {
    "qid": "fill-in-the-blank-ds-3223",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yᵢⱼ can be written as logit[ P(Yᵢⱼ ≤ r) ] = αᵣ + xᵢⱼᵀβ + [BLANK], where αᵣ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "bᵢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-84",
    "question": "When analyzing correlated ordinal responses, a common approach involves modeling the association between outcomes through shared random effects. The covariance matrix of these random effects, often denoted as [BLANK], captures the degree of association between the outcomes.",
    "gold_answer": "Σ (the covariance matrix of random effects). This is omitted to highlight the importance of the covariance matrix in modeling the association between outcomes through shared random effects."
  },
  {
    "qid": "fill-in-the-blank-ds-368",
    "question": "The robust stability margin, denoted as R(K,Δₜᵃ), quantifies the system's stability under parameter uncertainty, where a value greater than [BLANK] indicates no parameter in the uncertainty set destabilizes the system.",
    "gold_answer": "1. This threshold signifies that the system remains stable across the entire range of parameter variations considered, a key indicator of controller robustness."
  },
  {
    "qid": "fill-in-the-blank-ds-1798",
    "question": "In the context of matrix completion, the Adaptive-Impute algorithm iteratively applies thresholded SVD with data-dependent thresholding parameters. The algorithm's estimate enjoys the minimax error rate, and the thresholding scheme can be viewed as a solution to a [BLANK] optimization problem.",
    "gold_answer": "nonconvex. The thresholding scheme of Adaptive-Impute is attempting to solve a nonconvex optimization problem, which is challenging for theoretical guarantees but provides superior empirical performances."
  },
  {
    "qid": "fill-in-the-blank-ds-1310",
    "question": "In the supercritical case of a BRW, if the process begins with a single particle at the origin and condition C(i,j) holds for all pairs i,j, then Nₙ(yₙ)/ρⁿ → vφᵣ(y)W as n→∞, where W is the almost sure limit of [BLANK].",
    "gold_answer": "Nₙu′/ρⁿ. This result is part of the limit theorems for supercritical BRWs, showing convergence to a limiting distribution scaled by the largest eigenvalue ρ."
  },
  {
    "qid": "fill-in-the-blank-ds-657",
    "question": "The [BLANK] allocation method distributes the sample size in proportion to the size of each stratum.",
    "gold_answer": "proportional"
  },
  {
    "qid": "fill-in-the-blank-ds-290",
    "question": "In the context of multivariate linear regression, the Akaike information criterion (AIC) and the Mallows' $C_{p}$ criterion are proposed as approximately unbiased estimators for their risks or underlying criterion functions. The paper proposes modified versions of AIC and $C_{p}$ to reduce bias in situations where the collection of candidate models includes both underspecified and overspecified models. The modified AIC is intended to provide better approximations to their risk functions, and better model selection, than the original AIC and $C_{p}$. The modified AIC is defined by $\\mathbf{MAIC}=n\\log|\\hat{\\Sigma}_{j}|+p n\\log2\\pi+B_{A}^{(1)}+\\hat{B}_{A}^{(2)}$, where $B_{A}^{(1)}$ is defined as $\\frac{n(n+k_{j})p}{n-k_{j}-p-1}$. What is the term $\\hat{B}_{A}^{(2)}$ in the modified AIC formula?",
    "gold_answer": "$\\hat{B}_{A}^{(2)}$ is defined from $B_{A}^{(2)}$ by substituting $\\hat{\\Lambda}$ for $\\pmb{\\Lambda}$ in the equation $B_{A}^{(2)}=2k_{j}\\mathrm{tr}(\\Lambda-I_{p})-\\{\\mathrm{tr}(\\Lambda-I_{p})\\}^{2}-\\mathrm{tr}\\left\\{(\\Lambda-I_{p})^{2}\\right\\}$. This term is crucial for adjusting the bias in the modified AIC, especially in underspecified cases, by accounting for the latent roots of $\\Lambda$ through the estimator $\\widehat{\\Lambda}=\\frac{n-k}{n-k_{\\omega}}\\widehat{\\Sigma}_{\\omega}\\widehat{\\Sigma}_{j}^{-1}$."
  },
  {
    "qid": "fill-in-the-blank-ds-1121",
    "question": "In the context of partially nonstationary multivariate autoregressive models with conditional heteroscedasticity, the least squares estimator of the matrix F is given by [BLANK]. What is the correct formula for the least squares estimator?",
    "gold_answer": "The least squares estimator of F is given by (∑_{t=1}^n W_t X_{t-1}′)(∑_{t=1}^n X_{t-1} X_{t-1}′)^{-1}. This formula is derived by minimizing the sum of squared errors in the model, providing an initial estimate for further refinement through full-rank or reduced-rank maximum likelihood estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-2098",
    "question": "The 2-term Edgeworth expansion, or the expansion up to order $1/n$ , of the distribution of the sample correlation coefficient in nonnormal observations is obtained. For the expansion, the formula of the [BLANK] of the function of sample variances and covariances of the associated observable variables is given.",
    "gold_answer": "fourth cumulant. This is critical because it provides the necessary information to approximate the distribution of the sample correlation coefficient under nonnormality."
  },
  {
    "qid": "fill-in-the-blank-ds-798",
    "question": "In the sensitivity analysis for publication bias in meta-analyses, the publication process is modeled such that 'statistically significant' results are more likely to be published than negative or 'non-significant' results by an unknown ratio, denoted as [BLANK].",
    "gold_answer": "η. This ratio represents the relative likelihood of publishing statistically significant results compared to non-significant ones, serving as a key parameter in assessing the impact of publication bias."
  },
  {
    "qid": "fill-in-the-blank-ds-265",
    "question": "In the context of multi-phase case-control studies, the semiparametric maximum likelihood approach can be implemented by including additional intercept terms in the logistic model and then making some simple corrections to the score and information equations used in a Newton–Raphson or Fisher-scoring maximization of the prospective loglikelihood. The theoretical derivations apply to arbitrary binary regression models but results are presented for [BLANK] regression.",
    "gold_answer": "logistic. The focus on logistic regression is due to its widespread use in case-control studies and the ease with which the approach can be implemented and interpreted within this framework."
  },
  {
    "qid": "fill-in-the-blank-ds-1254",
    "question": "In the context of ordinal data analysis, the method of mean square contingency and corrections for the grouping of both variates assumes that the marginal totals for both variates follow approximately [BLANK] distributions.",
    "gold_answer": "normal"
  },
  {
    "qid": "fill-in-the-blank-ds-1609",
    "question": "When analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response $Y_{ij}$ can be written as $\\text{logit}[ P(Y_{ij} \\leq r) ] = \\alpha_r + x_{ij}^T\\beta + [BLANK]$, where $\\alpha_r$ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "$b_i$ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subject’s repeated measurements."
  },
  {
    "qid": "fill-in-the-blank-ds-747",
    "question": "In the context of mean field variational Bayesian inference for nonparametric regression with measurement error, the model for the responses is given by yᵢ = f(xᵢ) + εᵢ, where εᵢ are i.i.d. N(0, [BLANK]). What is the variance of the error terms εᵢ?",
    "gold_answer": "σᵢ². This represents the variance of the error terms in the nonparametric regression model, indicating the spread of the residuals around the function f(xᵢ)."
  },
  {
    "qid": "fill-in-the-blank-ds-1336",
    "question": "In the context of testing uniformity on a circle, the Rayleigh test rejects uniformity for large values of R, where R is defined as the square root of the sum of the squares of the sums of cosine and sine components of the angles. The formula for R is given by R = √[(∑cosθᵢ)² + (∑sinθᵢ)²], where θᵢ are the angles made by the radii through the observations on the circle and an arbitrary fixed reference radius. What critical mathematical operation is applied to the sums of cosine and sine components before taking the square root to compute R?",
    "gold_answer": "Squaring the sums of cosine and sine components. This operation is crucial as it ensures that both components contribute positively to the value of R, regardless of their individual signs, and it is part of the process that leads to the computation of the resultant vector length, which is central to the Rayleigh test."
  },
  {
    "qid": "fill-in-the-blank-ds-1076",
    "question": "In the computation of minimal covering ellipsoids, the probability measure λ can be regarded without confusion as a design weighting on 𝒱 or 𝒰. The theory of optimal design tells us that, no matter what n is, at least [BLANK] of the λ_i's are non-zero.",
    "gold_answer": "k+1. This is a fundamental property of the optimal design measure, ensuring that the ellipsoid is defined by at least k+1 points, which is necessary for its minimal covering property."
  },
  {
    "qid": "fill-in-the-blank-ds-2392",
    "question": "The product moments of existing and new noncentral bimatrix variate beta distributions with bounded domain are derived. From these, exact expressions for the distributions of statistics are obtained by using the [BLANK] transform.",
    "gold_answer": "Mellin. The Mellin transform is used to derive exact expressions for the distributions of statistics from the product moments of noncentral bimatrix variate beta distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-2331",
    "question": "In the Cox proportional hazards model, the baseline hazard function is denoted as [BLANK].",
    "gold_answer": "h0(t). This function represents the hazard when all covariates are zero, serving as a reference for comparing the hazard rates across different groups or levels of covariates."
  },
  {
    "qid": "fill-in-the-blank-ds-2099",
    "question": "From a simulation, the partially weighted 2-term Edgeworth expansion is found to give smaller errors than those by the single-term or fully weighted 2-term Edgeworth expansions. This suggests that the optimal weight on the added term of order $n^{-1}$ is [BLANK].",
    "gold_answer": "between 0 and 1. This indicates that a partially weighted expansion, rather than fully weighted or unweighted, provides the best approximation under certain conditions."
  },
  {
    "qid": "fill-in-the-blank-ds-1639",
    "question": "In the context of estimating probability density functions, the Bayesian predictive method uses the estimate q(y|x) = ∫p(y|θ)p(θ|x)dθ, where p(θ|x) is a Bayesian posterior density function based on a prior distribution p(θ) and the data x. The classical estimative method, in contrast, uses q(y|x) = p{y|θ=θ^(x)}, where θ^(x) is some efficient estimate of θ. A goodness-of-fit criterion based on an information measure introduced by Aitchison (1975) evaluates the deviation of an estimate r(y|x) from the true density p(y|θ) as ∫X p′(x|θ)dx ∫Y p(y|θ)log{p(y|θ)/r(y|x)}dy. For the multivariate normal case, the predictive method based on vague prior knowledge is shown to be superior to the estimative method, leading to the estimate q(y|x) = St_d{ν, m, (1+1/n)S}, where St_d denotes a d-dimensional Student's t distribution. The key element omitted here is the degrees of freedom parameter ν, which is defined as ν = [BLANK].",
    "gold_answer": "ν = n - d + 1. This parameter is crucial because it adjusts the tails of the Student's t distribution to account for the uncertainty in estimating the covariance matrix from the data, especially in small samples."
  },
  {
    "qid": "fill-in-the-blank-ds-1669",
    "question": "In the context of estimating multiple precision matrices with cluster fusion regularization, the CRF estimator is defined as minimizing a function that includes a term promoting similarities in precision matrices within the same cluster. This term is controlled by the tuning parameter [BLANK].",
    "gold_answer": "λ₂. The term is the cluster fusion penalty, which encourages precision matrices within the same cluster to be similar, controlled by the positive tuning parameter λ₂."
  },
  {
    "qid": "fill-in-the-blank-ds-2649",
    "question": "For covariance estimation, a perturbation resampling method is proposed. Perturbed versions of the estimators are obtained by solving S^*(γ; τ) = 0, where S^*(γ; τ) involves weights θ_i. What distribution are the θ_i generated from?",
    "gold_answer": "The θ_i are generated from a unit exponential distribution, which is used to create perturbed versions of the estimators for covariance estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-1516",
    "question": "The improvement function introduced in the paper is based on the \"modified maximin fitness function\" which is known to identify well-spaced non-dominated outputs when used in [BLANK].",
    "gold_answer": "multiobjective evolutionary algorithms (MOEAs). This function helps in directing the search towards well-spaced designs close to the true Pareto front."
  },
  {
    "qid": "fill-in-the-blank-ds-2644",
    "question": "In the estimation of conditional pseudo-copulas, the nonparametric estimator $\\widehat C(\\mathbf{u}\\mid\\mathbf{X}_{n-1}^{n-p}=\\mathbf{y}^{*})$ is constructed using estimates of the joint conditional distribution and the [BLANK].",
    "gold_answer": "conditional marginal cdf's. This approach allows for flexible modeling of dependencies conditional on past observations."
  },
  {
    "qid": "fill-in-the-blank-ds-3549",
    "question": "The MAVE method is proposed within the context of semiparametric models and is called the (conditional) minimum average variance estimation (MAVE) method. One of its advantages is that it can achieve a faster rate of consistency for the estimator of the parameters even without [BLANK] the nonparametric link function estimator.",
    "gold_answer": "undersmoothing. This is highlighted to emphasize that, unlike most existing methods which require undersmoothing to achieve a faster consistency rate for parameter estimators, the MAVE method achieves this faster rate without the need to undersmooth the nonparametric link function estimator."
  },
  {
    "qid": "fill-in-the-blank-ds-1931",
    "question": "In the mixed-effect two-stage polytomous model score test (MTOP), the score statistic for the fixed effect θ_f under the global null hypothesis is given by [BLANK].",
    "gold_answer": "Q_θ_f = (Y - P_f)^T G_M Z_f I_f^{-1} Z_f^T G_M^T (Y - P_f) ~ χ_{l_f}^2. This statistic tests the association between the SNP and disease subtypes, accounting for fixed effects and missing data through the EM algorithm."
  },
  {
    "qid": "fill-in-the-blank-ds-2757",
    "question": "The iterative scheme (2.11) is an example of the [BLANK], which is known for its efficiency in solving optimization problems by breaking them into smaller, more manageable parts.",
    "gold_answer": "alternating direction method of multipliers (ADMM). This highlights the method's foundation in distributed optimization and statistical learning, leveraging parallel processing to enhance computational efficiency."
  },
  {
    "qid": "fill-in-the-blank-ds-3033",
    "question": "In the context of testing the error distribution in regression models, the proposed jackknife empirical likelihood method is advantageous because it has a [BLANK] limit, making critical values readily available without the need for bootstrap methods.",
    "gold_answer": "chi-square. This highlights the method's ease of use and computational simplicity compared to traditional approaches that require more complex procedures to determine critical values."
  },
  {
    "qid": "fill-in-the-blank-ds-681",
    "question": "A key property of dose-finding designs, which stipulates that a design should not escalate the dose after observing a toxic outcome, is called [BLANK].",
    "gold_answer": "Coherence. This principle ensures the safety of dose escalation in clinical trials."
  },
  {
    "qid": "fill-in-the-blank-ds-1976",
    "question": "In the context of signal extraction for nonstationary time series, the method that builds up optimal full model filters from reduced model filters through an iteration scheme is reminiscent of the [BLANK] program's approach.",
    "gold_answer": "X-11. The iterative approach discussed in the paper shares conceptual similarities with the nonparametric method used in the US Census Bureau's X-11 program for seasonal adjustment."
  },
  {
    "qid": "fill-in-the-blank-ds-2962",
    "question": "In the context of envelope methods for reducing estimative variation in multivariate linear regression, the optimization is essentially over the set of all u-dimensional subspaces of ℝᵏ, which is a Grassmann manifold denoted as [BLANK].",
    "gold_answer": "𝒢_{u,k}. This notation is used to represent the Grassmann manifold, which is the space of all u-dimensional subspaces in ℝᵏ, crucial for the optimization process in envelope estimation methods."
  },
  {
    "qid": "fill-in-the-blank-ds-1950",
    "question": "In the context of functional mixed effects models, the proposed approach avoids complex modeling and implementation by estimating the fixed effects under the assumption of [BLANK] and then using a nonparametric bootstrap of independent units to construct confidence intervals and conduct tests.",
    "gold_answer": "independence of functional residuals. This approach simplifies the inference process by not requiring the specification of the complex correlation structure of the data, leveraging the bootstrap method to account for all known sources of data dependence."
  },
  {
    "qid": "fill-in-the-blank-ds-664",
    "question": "In the context of estimating a copula when a covariate affects only marginal distributions, the conditional copula of Y₁ and Y₂ given X does not depend on the value of X. This independence is often referred to as the [BLANK] assumption.",
    "gold_answer": "simplifying assumption. This assumption is crucial for simplifying the estimation process by allowing the dependence structure between Y₁ and Y₂ to be modeled independently of the covariate X."
  },
  {
    "qid": "fill-in-the-blank-ds-1091",
    "question": "In the simulation study, the performance of the proposed test is evaluated under the presence of outliers, with the degree of contamination represented by p, where p=0.5% indicates a [BLANK] degree of contamination.",
    "gold_answer": "low. This setting allows the assessment of the test's performance under minimal outlier influence, contrasting with higher contamination levels."
  },
  {
    "qid": "fill-in-the-blank-ds-619",
    "question": "The variance of the number of points in a region for a log Gaussian Cox process increases when the [BLANK] and hence the correlation increases.",
    "gold_answer": "β"
  },
  {
    "qid": "fill-in-the-blank-ds-1140",
    "question": "The dependence function A(w) in bivariate extreme value distributions is convex and satisfies the inequalities [BLANK] for 0 ≤ w ≤ 1.",
    "gold_answer": "max(w,1-w) ≤ A(w) ≤ 1. This is crucial as it defines the range within which the dependence function must lie, ensuring it adheres to the properties of bivariate extreme value distributions."
  },
  {
    "qid": "fill-in-the-blank-ds-2340",
    "question": "In the context of nonlinear regression models with heteroscedasticity, the general form of the model is given by Y_i = f(x_i, β) + ε_i, where ε_i ~ N(0, σ_i^2). To model the variance σ_i^2, the equation σ_i^2 = σ^2 m(z_i, λ) = σ^2 m_i is used. The test for heterogeneity of variance is equivalent to testing the hypotheses H_0: λ = λ_0 vs. H_1: λ ≠ λ_0. The log-likelihood function for θ = (λ^T, β^T, σ^2)^T is given by l(θ) = C - (n/2)logσ^2 - (1/2)Σ_{i=1}^n log m_i - (1/(2σ^2))Σ_{i=1}^n m_i^{-1}(Y_i - f(x_i, β))^2. The Fisher information matrix under H_0 is I_Y(θ) = [ (1/2)M^T M^{-2} M 0 (1/(2σ^2))M^T M^{-1} 1_n; 0 (1/σ^2)F^T M^{-1} F 0; (1/(2σ^2))1_n^T M^{-1} M 0 n/(2σ^4) ], where M = diag(m_1, ..., m_n), Ṁ = (∂m(z_i, λ)/∂λ_j)_{n×q}, 1_n = (1, ..., 1)^T, and Ḟ = (∂f(x_i, β)/∂β_j)_{n×p}. The score test statistic for hypothesis (2) is based on the score function ∂l(θ)/∂λ|_{θ̂_0} = { Ṁ^T u / (2σ^2) }|_{θ̂_0}, where u = (ε_1^2, ..., ε_n^2)^T, θ̂_0 = (λ_0^T, γ̂_0^T)^T, γ̂_0 is the MLE of γ under H_0, and Ṁ = (I_n - 1_n 1_n^T /n) Ṁ. The score statistic is computed as SC_1 = { (∂l(θ)/∂λ)^T I^{λλ} (∂l(θ)/∂λ) }|_{θ̂_0} = { u^T Ṁ (Ṁ^T Ṁ)^{-1} Ṁ^T u / (2σ^4) }|_{θ̂_0}, where I^{λλ} = 2 { Ṁ^T (I_n - 1_n 1_n^T /n) Ṁ }^{-1} = 2 (Ṁ^T Ṁ)^{-1}, which is the upper left corner of I_Y^{-1}(θ) under H_0. The asymptotic distribution of SC_1 under H_0 is a central χ^2 distribution with q degrees of freedom. The approximate power of the score test under local alternatives is given by ALP_1(λ) = 1 - F_χ^2(χ_α^2(q) | q, δ), where F_χ^2(x | q, δ) is the noncentral χ^2 distribution function with q degrees of freedom and noncentrality parameter δ = μ^T Σ^{-1} μ, with μ = (σ^2 / (2σ_0^2)) Ṁ_0^T M 1_n + (1 / (2σ_0^2)) Ṁ_0^T G 1_n and Σ = (σ^4 / (2σ_0^4)) Ṁ_0^T M^2 Ṁ_0 + (σ^2 / σ_0^4) Ṁ_0^T M G Ṁ_0. Here, χ_α^2(q) is the critical value of the central χ^2 distribution with q degrees of freedom at level α, Ṁ_0 is the value of Ṁ at λ_0, and Ṁ = (I_n - 1_n 1_n^T /n) Ṁ. The noncentrality parameter δ is crucial for calculating the approximate power under local alternatives. What is the expression for the noncentrality parameter δ in terms of μ and Σ?",
    "gold_answer": "δ = μ^T Σ^{-1} μ. The noncentrality parameter δ is calculated as the quadratic form of μ multiplied by the inverse of Σ, where μ represents the expected value of the score function under the alternative hypothesis, and Σ represents the variance of the score function. This parameter is essential for determining the approximate power of the score test under local alternatives, as it quantifies the deviation from the null hypothesis in terms of the score function's distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-3013",
    "question": "The MSCAL distribution is fitted using a Monte Carlo expectation-maximization (MCEM) algorithm that uses a Monte Carlo method to estimate the [BLANK] matrix of eigenvectors.",
    "gold_answer": "orthogonal. The MCEM algorithm's use of a Monte Carlo method for estimating the orthogonal matrix of eigenvectors is crucial for the model's ability to handle complex data structures."
  },
  {
    "qid": "fill-in-the-blank-ds-2585",
    "question": "In the context of canonical correlation analysis (CCA), the purpose is to describe the linear interrelations between p- and q-variate random vectors by finding new coordinate systems for both vectors. The covariance matrix between the two random vectors in these new systems is (R,0), where R is a diagonal matrix with descending positive diagonal elements. The new variables and their correlations are called [BLANK] and canonical correlations, respectively.",
    "gold_answer": "canonical variates. This term is used to describe the new variables obtained after transforming the original variables into a new coordinate system where the interrelations are described by canonical correlations."
  },
  {
    "qid": "fill-in-the-blank-ds-975",
    "question": "In the Hartley-Khamis procedure, the grouped frequencies' estimates are determined by the conditions involving the moments of the distribution and the missingness indicators. The equation representing this is given by f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK], where Rᵢ denotes the missingness indicators. What is the omitted term that represents the missingness mechanism?",
    "gold_answer": "f(Rᵢ | Yᵢ). This term is crucial as it represents the conditional distribution of the missingness indicators given the outcomes, highlighting the dependency of missingness on the observed and unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-3563",
    "question": "In the context of testing for genetic effects in semiparametric models with interaction, the score test statistic for a fixed value of γ is given by Tₙ,pro(γ) = n⁻¹/² Σᵢ₌₁ⁿ Ψᵢ(γ) + oₚ(1). What term is represented by Ψᵢ(γ) in this equation?",
    "gold_answer": "Ψᵢ(γ) represents the individual contribution of the ith observation to the score statistic, adjusted for the interaction parameter γ. It is derived from the model's likelihood and includes terms for the main effects, the interaction effects, and the non-parametric components, ensuring the test statistic's validity under the null hypothesis."
  },
  {
    "qid": "fill-in-the-blank-ds-2354",
    "question": "For a tight Gaussian measure μ in a Banach space X with zero mean, its characteristic functional can be expressed as χ(x*) = exp{-1/2⟨R x*, x*⟩}, where R is the [BLANK] operator.",
    "gold_answer": "covariance. This formula represents the Fourier transform of the Gaussian measure, with R capturing the measure's variance structure through its action on the dual space X*."
  },
  {
    "qid": "fill-in-the-blank-ds-3029",
    "question": "In the proposed method, kernel density estimation is employed within [BLANK]-type procedures to use data from Monte Carlo generations and tabulated critical values jointly.",
    "gold_answer": "Bayesian"
  },
  {
    "qid": "fill-in-the-blank-ds-1919",
    "question": "The performance of the Gaussian process AFT model is evaluated using metrics such as the C-index, integrated Brier score, and integrated AUC. The C-index measures the [BLANK] of the predicted survival times or risk scores.",
    "gold_answer": "concordance. This metric evaluates how well the model predicts the relative ordering of survival times, which is a key aspect of survival analysis."
  },
  {
    "qid": "fill-in-the-blank-ds-102",
    "question": "The measure of dependence between two statistical variables proposed by J. F. Steffensen, which is designed to remain applicable even when the number of distinct values the variables can assume becomes infinite, is denoted by [BLANK].",
    "gold_answer": "ψ (psi). This measure is highlighted to show its applicability in both finite and infinite scenarios, emphasizing its versatility in statistical dependence measurement."
  },
  {
    "qid": "fill-in-the-blank-ds-3045",
    "question": "In the context of Bayesian latent class models with structural zeros, the basic idea is to treat the observed data as a truncated sample from an augmented dataset. This approach allows us to exploit the conditional independence assumptions for computational expediency. The model can be expressed as f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK], where Rᵢ denotes the missingness indicators. What missingness-related term is deliberately omitted in this equation?",
    "gold_answer": "f(Rᵢ | Yᵢ). This term is omitted to highlight that, in a selection framework, the distribution of the missingness (Rᵢ) may depend on the observed and unobserved outcomes (Yᵢ), distinguishing selection models from pattern–mixture approaches."
  },
  {
    "qid": "fill-in-the-blank-ds-1956",
    "question": "In the two-stage model for estimating the long-term health effects of air pollution, the first stage involves a spatio-temporal fusion model linking modeled and measured pollution data, while the second stage links these predictions to the disease data. The methodology is motivated by a study investigating the effects of multiple pollutants on respiratory hospitalizations in England between 2007 and 2011, using pollution and disease data relating to local and unitary authorities on a [BLANK] time scale.",
    "gold_answer": "monthly. The study utilizes a monthly time scale to match the granularity of the pollution and disease data, allowing for less aggregation away from the individual level and capturing both chronic and acute pollution exposure effects."
  },
  {
    "qid": "fill-in-the-blank-ds-2420",
    "question": "In the context of directional multiple hypotheses testing, the loss function considered is of the form L(θ, d^X) = Σ L_i(θ_i, d_i^X), where d_i^X ∈ {−1, 0, 1}. Here, d_i^X = −1 means that [BLANK] is selected.",
    "gold_answer": "H_-^i. This indicates the selection of the hypothesis that θ_i is less than 0, representing a directional alternative."
  },
  {
    "qid": "fill-in-the-blank-ds-870",
    "question": "The first four conditional moments of the integrated variance implied by the GARCH diffusion process are derived analytically. Based on these moments and on a power series method an analytical approximation formula to price European options under the GARCH diffusion model is obtained. Monte Carlo simulations show that this approximation formula up to order [BLANK] is accurate for a large set of reasonable parameters and highlight potential instabilities of the fourth term.",
    "gold_answer": "three. The missing element is 'three' because the text specifies that the approximation formula up to order three is accurate, highlighting potential instabilities of the fourth term."
  },
  {
    "qid": "fill-in-the-blank-ds-282",
    "question": "In the bivariate regression model with arbitrary error structure, two simple but inefficient approaches to analysis are (i) to work with the differences between the two components of each response and (ii) to derive working independence estimators as if the two component responses were independent. The former strategy does well if the explanatory variables are balanced over pairs and the correlation between the two components of the response is high; the latter strategy does well when the response correlation is low or the covariates are highly unbalanced. Combining the two estimators can give a procedure with high efficiency in all situations, especially when an adjusted marginal score is calculated that is uncorrelated with the within-pair score. The covariance matrix between the score functions for the two analyses and the variance matrix of the paired score function are each scalar multiples of the matrix [BLANK].",
    "gold_answer": "W = ∑(xᵢ₁ - xᵢ₂)(xᵢ₁ - xᵢ₂)ᵀ. This matrix is crucial as it represents the configuration of the explanatory variables across pairs, affecting the efficiency of the combined estimator."
  },
  {
    "qid": "fill-in-the-blank-ds-117",
    "question": "A key assumption for the pseudo-partial likelihood estimators is that the matrix APPLE(π) is [BLANK], ensuring the identifiability of the parameter β.",
    "gold_answer": "positive definite. This assumption guarantees that the parameter β can be uniquely identified from the profiled partial likelihood within a compact set."
  },
  {
    "qid": "fill-in-the-blank-ds-260",
    "question": "In the context of testing hypotheses about the mean of a normal population with unknown variance, the sequential test procedure that modifies Baker's approach and is analogous to Stein's procedure is referred to as test [BLANK].",
    "gold_answer": "T. This refers to the sequential test procedure discussed in the paper, which is a modification of Baker's approach and serves as an analog to Stein's two-stage test procedure."
  },
  {
    "qid": "fill-in-the-blank-ds-3215",
    "question": "In the multiple-imputation strategy under a pattern–mixture perspective, the overall mixture distribution for the data is obtained by multiplying the subpopulation distribution f(Y | pattern) by [BLANK].",
    "gold_answer": "the proportion of that missingness pattern (f(pattern)). This weighting by the relative frequency of each pattern is essential for combining distributions in a pattern–mixture approach."
  },
  {
    "qid": "fill-in-the-blank-ds-3012",
    "question": "In the context of the MSCAL distribution, the parameters that model the proportion of good points and degree of contamination are the same across every dimension of the data, which is restrictive because it implies that all dimensions have the same amount of [BLANK].",
    "gold_answer": "leptokurtosis. This restriction is addressed by the MSCAL distribution by allowing these parameters to vary across dimensions, providing more flexibility in modeling tail behavior."
  },
  {
    "qid": "fill-in-the-blank-ds-3365",
    "question": "Estimation of the VAR-HME model parameters is achieved via the [BLANK] algorithm, which is an iterative method for finding maximum likelihood estimates.",
    "gold_answer": "EM (expectation–maximization). The EM algorithm is used due to its effectiveness in handling missing data and latent variables in statistical models."
  },
  {
    "qid": "fill-in-the-blank-ds-2826",
    "question": "In the context of continuous-time information sources, the notion of continuity introduced by Pinsker is equivalent to [BLANK] for stationary processes with a separable metric space as their state space.",
    "gold_answer": "continuity in probability. This equivalence highlights the relationship between two fundamental concepts in the study of stochastic processes and their applications in information theory."
  },
  {
    "qid": "fill-in-the-blank-ds-2809",
    "question": "A diffusion is said to be [BLANK] if there exists a sigma-finite (but not finite) invariant measure $m$ which is unique up to a constant multiple.",
    "gold_answer": "null recurrent. Null recurrence implies that while the process will return to any state with probability one, the expected time for such returns is infinite."
  },
  {
    "qid": "fill-in-the-blank-ds-3322",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a pattern–mixture perspective, where we distinguish subpopulations according to their missingness patterns. If we rely on the ‘neighboring case missing value’ approach (NCMV) so that missing values in a partially observed sequence borrow information only from the next identified pattern, we multiply the subpopulation distribution f(Y | pattern) by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern (f(pattern)). This step is essential for combining distinct distributions of Y in a pattern–mixture approach by weighting by the relative frequency of each pattern."
  },
  {
    "qid": "fill-in-the-blank-ds-634",
    "question": "In the AFT-SDAR algorithm, the step size τ must satisfy the condition 0 < τ < [BLANK] to ensure the algorithm's convergence. What is the missing term in this inequality?",
    "gold_answer": "1/(√T U). This condition ensures that the step size is sufficiently small to guarantee the convergence of the AFT-SDAR algorithm by balancing the trade-off between the algorithm's speed and stability."
  },
  {
    "qid": "fill-in-the-blank-ds-2924",
    "question": "In the context of threshold diffusion processes, the maximum likelihood estimator for the drift parameters (b₊, b₋) can be expressed as βₜ⁺ = (Rₜ⁺ / Qₜ⁺) and βₜ⁻ = (Rₜ⁻ / Qₜ⁻), where Rₜ⁺ and Rₜ⁻ are defined based on the process's behavior above and below the threshold, and Qₜ⁺ and Qₜ⁻ are the occupation times. The term [BLANK] is crucial for calculating Rₜ⁺ and Rₜ⁻ from the process's observations.",
    "gold_answer": "the symmetric local time Lₜ(ξ) at the threshold. This term is essential because it accounts for the time the process spends at the threshold, influencing the calculation of Rₜ⁺ and Rₜ⁻ by adjusting for crossings between the positive and negative sides of the threshold."
  },
  {
    "qid": "fill-in-the-blank-ds-464",
    "question": "Fisher's linear discriminant function (LDF) provides a linear combination of observations with the property that the mean difference in y for the two populations divided by the (common) standard deviation of y within populations is a maximum. This property does not depend on X being [BLANK].",
    "gold_answer": "multivariate normal. This highlights that Fisher's LDF can be useful for a wide variety of distributions of the observations, not just those that are multivariate normal."
  },
  {
    "qid": "fill-in-the-blank-ds-1507",
    "question": "In the context of high dimensional mean–variance optimization through factor analysis, the proposed estimator for the high dimensional covariance matrix is applied to solve the mean–variance portfolio optimization problem. The consistency of the proposed estimator is established by imposing a factor model structure with a relatively weak assumption on the relationship between the dimension and the sample size. The proposed estimator is shown to outperform the plugin, linear shrinkage, and bootstrap-corrected approaches. Which approach is NOT mentioned as being outperformed by the proposed estimator?",
    "gold_answer": "Nearest Neighbor approach. The text mentions the plugin, linear shrinkage, and bootstrap-corrected approaches as being outperformed by the proposed estimator, but does not mention the Nearest Neighbor approach."
  },
  {
    "qid": "fill-in-the-blank-ds-3066",
    "question": "In the context of testing for normality, the paper highlights a cautionary note regarding the assumption about the mean. It suggests that even if one believes the true mean is known, one should still assume the mean is [BLANK] in making the test to avoid a significant loss in power.",
    "gold_answer": "unknown. This is because assuming the mean to be unknown when it is actually known can lead to a significant loss in the power of the test, as demonstrated by the comparative results in the paper."
  },
  {
    "qid": "fill-in-the-blank-ds-858",
    "question": "For modeling skewed error distributions in spatial models, one approach is to introduce a term λdᵢ, where dᵢ follows a [BLANK] distribution truncated below at zero.",
    "gold_answer": "normal"
  },
  {
    "qid": "fill-in-the-blank-ds-1616",
    "question": "In the context of estimating multivariate binary density using orthonormal functions, the shrinkage estimator proposed by Liang and Krishnaiah can be expressed as [BLANK], where λᵣ are the shrinkage coefficients and ϕᵣ(x) are the orthonormal functions.",
    "gold_answer": "∑ᵣ∈R λᵣ âᵣ ϕᵣ(x). This formula represents the shrinkage estimator that adjusts the coefficients âᵣ towards zero to reduce variance in the estimation process."
  },
  {
    "qid": "fill-in-the-blank-ds-2847",
    "question": "In the context of longitudinal canonical correlation analysis (LCCA), the model for each observation is given by Xᵢⱼ = μᵢⱼˣ + Zᵢ,₀ˣ + tᵢⱼZᵢ,₁ˣ + εᵢⱼˣ, where Zᵢ,₀ˣ and Zᵢ,₁ˣ represent the [BLANK] and random slopes, respectively.",
    "gold_answer": "random intercepts. This highlights the model's use of random effects to account for individual variability in both the baseline levels and the rates of change over time."
  },
  {
    "qid": "fill-in-the-blank-ds-2332",
    "question": "In the context of analyzing the first occurrence of elements in a fair coin-tossing process, for each element A in Ωₙ, the stopping time T_A is defined as the infimum of m such that A equals (Y_{m-n+1}, ..., Y_m). If no such m exists, T_A is defined as [BLANK]. What is the value assigned to T_A when the sequence A does not occur in the process?",
    "gold_answer": "∞ (infinity). This is because T_A is defined as the first time the sequence A appears in the process, and if A never appears, by definition, T_A is set to infinity to indicate that the event does not occur."
  },
  {
    "qid": "fill-in-the-blank-ds-773",
    "question": "The multivariate Laplace distribution is defined by a density function that includes a normalizing constant a(Σ) and a vector function t(y-μ) = (±√|y₁-μ₁|, ..., ±√|yₚ-μₚ|)^T, where the sign of each component is determined by [BLANK].",
    "gold_answer": "the sign of yⱼ - μⱼ. This specifies how the absolute differences are signed, ensuring the correct construction of the residual vector for the Laplace distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-667",
    "question": "The t-ridge estimator for generalized linear models is defined by minimizing an objective function that includes the data-fitting function divided by the L2 norm of the score function, plus the L2 norm of the parameter vector. Specifically, the objective function is given by D(θ|Z)/||s(θ)||₂ + ||θ||₂, where s(θ) is the score function defined as [BLANK].",
    "gold_answer": "s(θ) = -∂D(θ|Z)/∂θ. The score function represents the gradient of the data-fitting function with respect to the parameter vector, crucial for the optimization process in the t-ridge estimator."
  },
  {
    "qid": "fill-in-the-blank-ds-2758",
    "question": "In the context of solving fused penalty estimation problems, the term [BLANK] refers to the method of introducing auxiliary variables to decouple the linear constraints, facilitating parallel computation.",
    "gold_answer": "block splitting. This technique is crucial for reformulating the problem in a way that allows for separable optimization tasks, significantly improving scalability and computational speed."
  },
  {
    "qid": "fill-in-the-blank-ds-3511",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). We remove it from the question because it represents the core assumption that simplifies inference: once we condition on the observed responses, the missingness no longer depends on the unobserved data."
  },
  {
    "qid": "fill-in-the-blank-ds-3170",
    "question": "In the context of nonparametric regression for model checking, a pseudo likelihood ratio test is developed to provide a global assessment of fit. The test statistic is derived from a likelihood ratio argument but its distribution is not approximately chi-squared. Instead, simulation is used to examine the null hypothesis behavior of the test statistic. For Finney's data, the observed significance level is [BLANK] with a simulation size N=500.",
    "gold_answer": "0.4%. This value is reported to illustrate how the significance level is calculated from the position of the observed test statistic in the ordered test statistics derived from simulated data, emphasizing the practical application of the pseudo likelihood ratio test in assessing model fit."
  },
  {
    "qid": "fill-in-the-blank-ds-748",
    "question": "The method introduced for reducing bias of a wide variety of density estimators involves 'sharpening' the data by making them slightly more [BLANK] than before, and then computing the estimator in the usual way, but from the sharpened data rather than the original data.",
    "gold_answer": "clustered. This is excluded to highlight the key action in the data-sharpening method, which is adjusting the data distribution to reduce bias in density estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-1743",
    "question": "In the analysis of variance under spatial correlation, if $R \\neq I$, then the usual $F$ ratio will not have an $F$ distribution. Exceptions are when $R$ is formed from the appropriate randomization induced correlations or the corresponding random effects model. For a particular $R$, the distribution of $F$ could be obtained numerically, or approximated by independent $\\chi^2$ distributions with the same first two moments, a method introduced by [BLANK].",
    "gold_answer": "Box (1954) and Andersen, Jensen & Schou (1981). This approximation method is crucial for practical analysis when the error structure deviates from independence."
  },
  {
    "qid": "fill-in-the-blank-ds-3519",
    "question": "In the development of local Bayes factors, a uniform prior density over an appropriate volume in R^(p₁ - p₀) is used to ensure non-decreasing probability is assigned to a local neighbourhood of θ = 0. This approach can be seen as a special case of a [BLANK] prior.",
    "gold_answer": "Jeffreys invariant. The use of a uniform prior in this context aligns with Jeffreys' principle of invariance, emphasizing the role of prior specification in Bayesian model comparison."
  },
  {
    "qid": "fill-in-the-blank-ds-2226",
    "question": "In the semiparametric approach where the missing-data mechanism is nonparametric, the model becomes identifiable if the outcome model is correctly specified and [BLANK].",
    "gold_answer": "the missing-data mechanism is unspecified. This leverages the flexibility of the nonparametric component to achieve identifiability without strict parametric assumptions."
  },
  {
    "qid": "fill-in-the-blank-ds-1823",
    "question": "The Hilbert–Schmidt Independence Criterion (HSIC) is a nonparametric dependence measure that uses the distance between the kernel embeddings of probability measures in a [BLANK].",
    "gold_answer": "reproducing kernel Hilbert space (RKHS). This space is crucial for measuring dependency not only between univariate or multivariate random variables but also between random variables in more complex structures like high-dimensional or functional data."
  },
  {
    "qid": "fill-in-the-blank-ds-2549",
    "question": "In the context of ordinal data analysis, the [BLANK] model is often used to account for the ordered nature of the response categories.",
    "gold_answer": "proportional odds. This model is chosen because it specifically handles the ordinal nature of the data by assuming that the relationship between each pair of outcome groups is the same."
  },
  {
    "qid": "fill-in-the-blank-ds-3108",
    "question": "In the context of multivariate normal mixtures, the EM algorithm generates a sequence of estimates {Ψ(m)}m where Ψ(0) denotes the initial guess and Ψ(m) ∈ Ψ for m ∈ ℕ, ensuring that the sequence of the log-likelihood values {ℒ(Ψ(m))}m is [BLANK].",
    "gold_answer": "not decreasing. This ensures that each iteration of the EM algorithm does not decrease the likelihood, aiming for convergence to a local maximum."
  },
  {
    "qid": "fill-in-the-blank-ds-70",
    "question": "The joint probability density function of the ordered observations remaining after censoring in a normal population is given by f(x_{r_{1}+1},...,x_{n-r_{2}};μ,σ)= [BLANK]. What is the correct expression for this density function?",
    "gold_answer": "The correct expression is (n!/(r_{1}!r_{2}!))*(1/(sqrt(2π)σ))^m * exp[-∑_{i=r_{1}+1}^{n-r_{2}}(x_{i}-μ)^2/(2σ^2)] * [F((x_{r_{1}+1}-μ)/σ)]^{r_{1}} * [1-F((x_{n-r_{2}}-μ)/σ)]^{r_{2}}. This formula accounts for the censoring from both ends of the sample, where F is the cumulative distribution function of the standard normal distribution."
  },
  {
    "qid": "fill-in-the-blank-ds-2558",
    "question": "In the context of nonlinear regression with censored responses, the parameter θ₀ can be estimated through a standard least squares procedure if [BLANK] were available. What is the missing element?",
    "gold_answer": "Y*. The missing element is Y*, which represents the synthetic data transformations that have the same conditional expectation as Y, allowing for the estimation of θ₀ in the presence of censoring."
  },
  {
    "qid": "fill-in-the-blank-ds-2320",
    "question": "In the context of heteroscedastic regression models, the log-likelihood function, L(β,α), is given by L(β,α)=-∑ᵢlogσᵢ(α)+∑ᵢlogf{(yᵢ-μᵢ(β))/σᵢ(α)}. What critical condition causes the likelihood to diverge to infinity when σⱼ→0 and σᵢ→sᵢ (0<sᵢ<∞, i≠j)?",
    "gold_answer": "μⱼ(b₀)=yⱼ. This condition is critical because it signifies that at a certain value of β, the location function equals the observed value for the j-th observation, leading to the likelihood diverging to infinity as σⱼ approaches zero."
  },
  {
    "qid": "fill-in-the-blank-ds-504",
    "question": "In the orthogonal decomposition $Y=m(X)+\\varepsilon$, the function $m$ is the regression function of $Y$ on $X$ and is usually unknown. It is often assumed that $m$ belongs to a given parametric family $\\mathcal{M}$ of functions, so that $m$ is completely specified up to a [BLANK]. Which term completes this statement?",
    "gold_answer": "finite-dimensional parameter. This term is crucial because it specifies that the regression function $m$ can be fully described by a finite number of parameters within the parametric family $\\mathcal{M}$."
  },
  {
    "qid": "fill-in-the-blank-ds-2076",
    "question": "In the context of the GTL distribution, the condition for the kth moment mk of a GTL(α, δ)-distributed random variable ε to exist is that α−δ > −1/k and [BLANK].",
    "gold_answer": "α+δ > −1/k"
  },
  {
    "qid": "fill-in-the-blank-ds-76",
    "question": "For a normal distribution, the relationship between the correlation ratio η and the correlation coefficient r is given by [BLANK] = r.",
    "gold_answer": "η"
  },
  {
    "qid": "fill-in-the-blank-ds-740",
    "question": "In the context of local manifold approximation classification, the general algorithm assigns a feature to the class having the closest support, which is referred to as [BLANK].",
    "gold_answer": "local manifold approximation classification. This term is used to describe the algorithm's approach of approximating the support of the data within each class locally around the feature to be classified."
  },
  {
    "qid": "fill-in-the-blank-ds-3583",
    "question": "In the context of Approximate Bayesian Computation (ABC), the ABC posterior is defined in terms of a function S(·) which maps the data onto a d-dimensional summary statistic, a density kernel K(x), and a bandwidth h > 0. The ABC posterior can be expressed as πABC(θ|sobs) ∝ π(θ) × [BLANK]. What is the term that completes this equation to define the ABC posterior?",
    "gold_answer": "p(θ|sobs). This term represents the approximation to the likelihood as defined by the integral of the product of the true likelihood π(y|θ) and the kernel function K[{S(y) - sobs}/h] over all possible data y, thus linking the parameter θ to the observed summary statistic sobs through the kernel density estimation."
  },
  {
    "qid": "fill-in-the-blank-ds-1415",
    "question": "The efficiency of a design ignoring correlations compared to a design accounting for correlations is calculated using the formula ϕ_Eff = {ϕ(ξ_ρ=0,θ⁰)/ϕ(ξ_ρ>0,θ⁰)}^(1/p), where p is the number of parameters. This efficiency measure is used to assess the [BLANK] of the design ignoring correlations.",
    "gold_answer": "relative performance. This measure quantifies how much less efficient a design ignoring correlations is compared to one that accounts for them, with values closer to 1 indicating better performance."
  },
  {
    "qid": "fill-in-the-blank-ds-1698",
    "question": "The musk data application involves predicting the binding strength between molecules (bags) with different conformations (instances) and target receptors. The covariates or explanatory variables in this context are the distances measured from the origin to the surface of each conformation of the molecule along many rays, and the response is the [BLANK] between the molecule and the target receptor.",
    "gold_answer": "binding affinity. This continuous response variable measures the strength of the interaction between the molecule and its target receptor, which is the focus of the prediction task in the musk data application."
  },
  {
    "qid": "fill-in-the-blank-ds-1156",
    "question": "In the context of finite population sampling, the conditional bias attached to unit i of the Horvitz-Thompson estimator is defined as [BLANK], where πi is the first-order inclusion probability of unit i.",
    "gold_answer": "B1iHT = EP(θ̂HT | Ii = 1) - θ = ∑j∈U (πij / (πiπj) - 1) yj. This definition highlights the conditional bias as a measure of the influence of unit i on the estimation error, accounting for the sampling design through the inclusion probabilities."
  },
  {
    "qid": "fill-in-the-blank-ds-1588",
    "question": "The Breslow estimator Λₙ(x) for the baseline cumulative hazard function in the Cox model is given by ∑_{i|Xᵢ ≤ x} dᵢ / ∑_{j=1}^n {Tⱼ ≥ Xᵢ} e^(β̂ₙ'Zⱼ), where dᵢ is the number of events at Xᵢ and β̂ₙ is the maximum partial likelihood estimator of the regression coefficients. The term {Tⱼ ≥ Xᵢ} is an indicator function that equals 1 if [BLANK].",
    "gold_answer": "Tⱼ ≥ Xᵢ. This indicator function ensures that only individuals at risk at time Xᵢ contribute to the denominator of the Breslow estimator."
  },
  {
    "qid": "fill-in-the-blank-ds-313",
    "question": "In the likelihood ratio test for comparing two variances from a bivariate normal population, the test statistic is given by λ = {1 - [(δ₁² - δ₂²)² / ((δ₁² + δ₂²)² - 4r₁₂²δ₁²δ₂²)]}^(n/2). The hypothesis that σ₁ = σ₂ becomes less likely as λ approaches [BLANK].",
    "gold_answer": "0. This is because as λ moves towards 0, it indicates a greater discrepancy between the sample variances δ₁² and δ₂², making the hypothesis that σ₁ = σ₂ less plausible."
  },
  {
    "qid": "fill-in-the-blank-ds-46",
    "question": "The assumption that the probability of dropout does not depend on unobserved outcomes, conditional on observed data, is known as [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the validity of likelihood-based or multiple-imputation methods without explicitly modeling the dropout process."
  },
  {
    "qid": "fill-in-the-blank-ds-1211",
    "question": "The condition that any two vertices in the clan of a vertex v* are adjacent in the DAG unless both are in pa(v*) is equivalent to stating that v* is [BLANK] from the DAG.",
    "gold_answer": "removable. This condition ensures that the vertex v* can be removed without affecting the model's collapsibility, provided the adjacency condition is met."
  },
  {
    "qid": "fill-in-the-blank-ds-343",
    "question": "In the context of marked point processes, the joint conditional intensity function can be factorized into the product of the conditional intensity of the ground process and the conditional probability density or mass function of the mark at time t. This is expressed as λ*(t,m) = λg*(t) × [BLANK]. What term completes this equation?",
    "gold_answer": "f*(m∣t). This term represents the conditional probability density or mass function of the mark m at time t, highlighting how the mark's distribution depends on time."
  },
  {
    "qid": "fill-in-the-blank-ds-2263",
    "question": "In the selection modeling framework for analyzing ordinal outcomes and their missingness, the likelihood is factorized into the product of the outcome model and the missingness mechanism, expressed as f(Y_i, R_i) = f(Y_i) × [BLANK], where R_i denotes the missingness indicators.",
    "gold_answer": "f(R_i | Y_i). This term is omitted to emphasize that, in selection models, the distribution of missingness may depend on both observed and unobserved outcomes, distinguishing these models from pattern-mixture approaches."
  },
  {
    "qid": "fill-in-the-blank-ds-2421",
    "question": "Gaussian elimination was originally introduced by Gauss as a way of determining the precision of least squares estimates and only later described as a computational algorithm. The key function Gauss introduced for this purpose is proportional to e^(-h^2Ω), where Ω is the [BLANK].",
    "gold_answer": "residual sum of squares. This is because Ω represents the sum of the squares of the differences between the observed and predicted values, which is central to the method of least squares."
  },
  {
    "qid": "fill-in-the-blank-ds-1012",
    "question": "In the context of epidemic dynamics, the normalized Markov jump process is defined as $\\mathcal{Z}_{N}(t) = \\frac{\\mathcal{Z}(t)}{N} \\in E^{N} = \\{k/N, k \\in E\\}$. The associated jump functions are, for $\\boldsymbol{x} \\in E^{N}$, $\\alpha_{\\ell}^{N}(x) = \\frac{1}{N}\\alpha_{\\ell}([N x])$. The process $(\\mathcal{Z}(t))$ is density-dependent, meaning for all $\\ell$, $\\forall \\boldsymbol{x} \\in [0,1]^{d}$, $\\frac{1}{N}\\alpha_{\\ell}([N \\boldsymbol{x}]) \\underset{N \\to +\\infty}\\rightarrow \\beta_{\\ell}(\\boldsymbol{x})$, and $\\forall \\ell$, $\\beta_{\\ell} \\in C^{2}([0,1]^{d}, \\mathbb{R})$. The drift function $b(\\cdot)$ and the diffusion matrix $\\Sigma(\\cdot)$ are defined as $b(x) = \\sum_{\\ell \\in E^{-}}\\ell\\beta_{\\ell}(x); \\quad \\Sigma(x) = \\sum_{\\ell \\in E^{-}}\\beta_{\\ell}(x)\\ell\\ell^{t}$. For the SIR model, the jumps are $(S,I) \\rightarrow (S-1,I+1)$ with rate $\\lambda S I / N$ and $(S,I) \\rightarrow (S,I-1)$ with rate $\\gamma I$. The drift function for the SIR model is [BLANK].",
    "gold_answer": "$b(\\eta, s, i) = \\left(\\begin{array}{c}{-\\lambda s i}\\\\{\\lambda s i - \\gamma i}\\end{array}\\right)$. This is the drift function for the SIR model, representing the expected change in the number of susceptible and infectious individuals over time."
  },
  {
    "qid": "fill-in-the-blank-ds-3597",
    "question": "In the context of non-Gaussian Ornstein–Uhlenbeck stochastic volatility processes, the volatility process is modeled as a stationary, latent OU process, driven by a non-Gaussian Lévy process. This specification forces the volatility to move up entirely by jumps and then to tail off exponentially. The jump times and corresponding sizes are controlled by the increment distribution of the driving [BLANK] process.",
    "gold_answer": "Lévy. The Lévy process is crucial for modeling the jumps in volatility, with its increment distribution determining the timing and size of these jumps, which then tail off exponentially."
  },
  {
    "qid": "fill-in-the-blank-ds-1713",
    "question": "In the partially varying coefficient model (PVCM), the likelihood can be factorized into a product of the outcome model and the missingness mechanism. In selection modeling, this is expressed as f(Yᵢ, Rᵢ) = f(Yᵢ) × [BLANK], where Rᵢ denotes the missingness indicators. Which term is deliberately omitted in this equation?",
    "gold_answer": "f(Rᵢ | Yᵢ). This term is omitted to highlight that, in a selection framework, the distribution of the missingness (Rᵢ) may depend on the observed and unobserved outcomes (Yᵢ), distinguishing selection models from pattern–mixture approaches."
  },
  {
    "qid": "fill-in-the-blank-ds-144",
    "question": "In the context of hierarchical testing of variable importance, the null hypothesis for a cluster C of variables can be formulated as H₀,C: βₖ = 0 for all k ∈ C, versus Hₐ,C: βₖ ≠ 0 for at least one k ∈ C. The adjustment for multiplicity in the p-values is achieved by multiplying the p-value of each cluster C by the inverse of the fraction of variables it contains, expressed as [BLANK]. What is the correct term or formula used for this adjustment?",
    "gold_answer": "m/|C|. This adjustment is resolution-dependent, applying a weaker penalty for coarser resolutions and increasing for finer resolutions, ensuring that the root node's p-value is unadjusted while individual variables receive a Bonferroni-type adjustment."
  },
  {
    "qid": "fill-in-the-blank-ds-3165",
    "question": "In the context of group divisible designs, the condition that distinguishes a regular subtype from singular and semiregular is given by [BLANK].",
    "gold_answer": "r > λ₁ and rk > λ₂. This condition is crucial for identifying regular group divisible designs, which are the most numerous among the partially balanced designs."
  },
  {
    "qid": "fill-in-the-blank-ds-1178",
    "question": "The estimator of location, $J_{n}$, is defined as $J_{n}=\\frac{6}{n}\\sum_{i=1}^{n}\\frac{i}{n+1}\\bigg(1-\\frac{i}{n+1}\\bigg)Y_{i}$, where $Y_{1}<...<Y_{n}$ are the order statistics for a sample $X_{1},...,X_{n}$ of size $n$. This estimator is an asymptotically best linear unbiased estimator of the location parameter of the [BLANK] distribution.",
    "gold_answer": "logistic. The logistic distribution is specified as the context in which $J_{n}$ is an asymptotically best linear unbiased estimator, highlighting its relevance in statistical estimation for this particular distribution."
  }
]
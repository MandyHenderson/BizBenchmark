[
  {
    "qid": "fill-in-the-blank-ds-979",
    "folder": "",
    "question": "In the context of Hertzian fracture data, the hypothesis about the distribution of critical loads can be expressed as P(X>x) = exp{-dÂ²Î±(x)}, where X=w/dÂ² and Î±(x) is an unknown function that increases continuously from 0 to âˆž with x. What is the term that represents the critical load on an indenter of diameter d required to produce a fracture?",
    "gold_answer": "w. This term is crucial as it directly relates to the physical measurement of the load at which fracture occurs, forming the basis for the hypothesis about the distribution of critical loads.",
    "source": [
      "A Non-Parametric Test for Hertzian Fracture Data.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_24_Issue_2\\A Non-Parametric Test for Hertzian Fracture Data\\A Non-Parametric Test for Hertzian Fracture Data.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "w",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"w\"\n}",
      "model_answer": "w",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3317",
    "folder": "",
    "question": "In the context of stochastic differential equation mixed-effects models (SDEMEMs), the likelihood function is typically intractable, motivating the use of sampling-based approaches such as [BLANK].",
    "gold_answer": "Markov chain Monte Carlo (MCMC). This is because MCMC methods allow for the approximation of the posterior distribution of parameters when the likelihood is not analytically tractable.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2021\\ScienceDirect_articles_03Mar2025_08-51-04.413\\Efficient-inference-for-stochastic-differential-eq\\Efficient-inference-for-stochastic-differential-eq.md",
      "Efficient-inference-for-stochastic-differential-eq.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Markov chain Monte Carlo (MCMC)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"particle filters\"\n}",
      "model_answer": "particle filters",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1117",
    "folder": "",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies the analysis by allowing valid inferences without modeling the dropout process explicitly.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3295",
    "folder": "",
    "question": "The SCAD penalty function is defined for a given tuning parameter Î¶ > 0 and a threshold a. For |Î¸| â‰¤ Î¶, the penalty is pe_Î¶(Î¸) = [BLANK].",
    "gold_answer": "Î¶|Î¸|. This part of the SCAD penalty applies a linear penalty to coefficients that are within the threshold Î¶, encouraging sparsity.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¶|Î¸|",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¶|Î¸|\"\n}",
      "model_answer": "Î¶|Î¸|",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3162",
    "folder": "",
    "question": "In the estimation of the conditional density function f of the interarrival times for a PDMP, the function H(x, y, t) is defined for any x, y âˆˆ E and 0 â‰¤ t â‰¤ t*(x) as H(x, y, t) = âˆ«â‚œáµ—*(x) fQÌƒ(x, s, y) ds + GQÌƒ(x, t*(x), y). Here, GQÌƒ(x, t*(x), y) represents the [BLANK].",
    "gold_answer": "survival function multiplied by the transition kernel at the exit time. This term accounts for the scenario where the jump occurs upon hitting the boundary of the state space.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "survival function multiplied by the transition kernel at the exit time",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"jump part of the conditional density\"\n}",
      "model_answer": "jump part of the conditional density",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2712",
    "folder": "",
    "question": "In the hierarchical modeling approach for clustering probability density functions, the method is introduced in the univariate context and then extended to multivariate densities by means of a [BLANK] model performing dimension reduction.",
    "gold_answer": "factorial. This is omitted to highlight the specific type of model used for extending the method to multivariate settings, emphasizing the approach's adaptability and efficiency in handling higher-dimensional data.",
    "source": [
      "A-hierarchical-modeling-approach-for-clustering_20.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2014\\ScienceDirect_articles_04Mar2025_11-06-53.618\\A-hierarchical-modeling-approach-for-clustering_20\\A-hierarchical-modeling-approach-for-clustering_20.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "factorial",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"factor analysis\"\n}",
      "model_answer": "factor analysis",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2708",
    "folder": "",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by stating that the missingness mechanism depends only on observed data, not on unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1760",
    "folder": "",
    "question": "In the context of penalized singular value decomposition (SVD) for a data matrix where the left singular vector is sparse and the right singular vector is a discretized function, the method uses two penalties to impose sparsity and smoothness. However, it is shown that the value of only [BLANK] has to be chosen, which is in contrast to previous penalized SVD models.",
    "gold_answer": "one parameter. This highlights the efficiency of the proposed method by reducing the complexity of parameter selection compared to earlier approaches.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2013\\ScienceDirect_articles_01Mar2025_03-34-28.593\\Sparse-smooth-regularized-singular-value-dec_2013_\\Sparse-smooth-regularized-singular-value-dec_2013_.md",
      "Sparse-smooth-regularized-singular-value-dec_2013_.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "one parameter",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"one tuning parameter\"\n}",
      "model_answer": "one tuning parameter",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3430",
    "folder": "",
    "question": "In the analysis of screening processes, the variance of $G$ between independent runs for the finite model can be expressed as $\\operatorname{var}\\left(G\\right)=\\frac{N_{0}\\sigma^{2}}{N_{0}+N_{1}V}\\{h(N_{1},N_{2})+V\\}$, where $h(u_{1},u_{2})$ is the variance of the mean of the largest $u_{2}$ values in a random sample of $u_{1}$ members from $N(0,1)$. For $N_{1}=N_{0}$, this simplifies to $\\operatorname{var}\\left(G\\right)=\\frac{\\sigma^{2}\\{h(N_{1},N_{2})+V\\}}{1+V}$. The function $h(u_{1},u_{2})$ can be computed from tables provided by Teichroew (1956), who tabulated expected squares and products of the first, second, ... largest values in random samples of 20 or less from $N(0,1)$. The variance of $G$ is crucial for assessing the reliability of the screening process, especially in ensuring that the risk of having only a small gain is minimized. For $N_{1}=N_{0}=16$, $N_{2}=4$, and $V=1.0$, the estimated $\\operatorname{var}(G)/\\sigma^{2}$ is approximately [BLANK].",
    "gold_answer": "0.533. This value is derived from empirical studies and highlights the variability in the expected gain $G$ for specific parameters of the finite model, emphasizing the importance of understanding the variance in screening processes.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0.533\"\n}",
      "model_answer": "0.533",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2054",
    "folder": "",
    "question": "The MC-SIS procedure selects important variables based on the magnitudes of $\\widehat{\\lambda_{j1}^*$, which is the estimate of the largest eigenvalue $\\lambda_{j1}^*$ from the generalized eigenvalue problem involving the matrices $\\mathbf{A}_{j00}$, $\\mathbf{A}_{j0X}$, and $\\mathbf{A}_{jXX}$. The selected set of variables is defined as $\\widehat{\\mathcal{D}_{\\nu_n}} = \\{1 \\leq j \\leq p : \\widehat{\\lambda_{j1}^*} \\geq \\nu_n\\}$, where $\\nu_n$ is a pre-specified threshold. The threshold $\\nu_n$ is often chosen such that the size of $\\widehat{\\mathcal{D}_{\\nu_n}}$ is $n$ or $[n / \\ln n]$. The term [BLANK] is used to denote the cardinality of the selected set $\\widehat{\\mathcal{D}_{\\nu_n}}$.",
    "gold_answer": "$|\\widehat{\\mathcal{D}_{\\nu_n}}|$. This notation represents the number of variables selected by the MC-SIS procedure, indicating the size of the reduced dimensionality set that retains the active predictors.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$|\\widehat{\\mathcal{D}_{\\nu_n}}|$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"d\"\n}",
      "model_answer": "d",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1146",
    "folder": "",
    "question": "In the context of testing the randomness of a sequence using the longest run criterion, the hypothesis to be tested, denoted as Hâ‚€, is that the elements of the sequence are in a [BLANK] order.",
    "gold_answer": "random. This is the null hypothesis in statistical tests for randomness, assuming no specific pattern or dependency in the sequence.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_35_Issue_1-2\\ON_THE_POWER_FUNCTION_OF_THE_LONGEST_RUN_AS_A_TEST_FOR_RANDOMNESS_IN_A_SEQUENCE_OF_ALTERNATIVES\\ON_THE_POWER_FUNCTION_OF_THE_LONGEST_RUN_AS_A_TEST_FOR_RANDOMNESS_IN_A_SEQUENCE_OF_ALTERNATIVES.md",
      "ON_THE_POWER_FUNCTION_OF_THE_LONGEST_RUN_AS_A_TEST_FOR_RANDOMNESS_IN_A_SEQUENCE_OF_ALTERNATIVES.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "random",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"random\"\n}",
      "model_answer": "random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3330",
    "folder": "",
    "question": "The recursive kernel density estimator for directional data proposed in the paper is based on the stochastic approximation method for successive experiments proposed in [BLANK].",
    "gold_answer": "Robbins & Monro (1951). This reference is crucial as it lays the foundation for the recursive estimation technique used in the paper, highlighting the methodological basis of the proposed estimator.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Robbins & Monro (1951)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Robbins and Monro (1951)\"\n}",
      "model_answer": "Robbins and Monro (1951)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1707",
    "folder": "",
    "question": "In the context of estimating the precision matrix of a singular Wishart distribution, the Steinâ€“Haff identity is established for a singular Wishart distribution with a positive definite mean matrix but with the dimension larger than the degrees of freedom. This identity is then used to obtain estimators of the precision matrix improving on the estimator based on the [BLANK] inverse of the Wishart matrix under the Efronâ€“Morris loss function and its variants.",
    "gold_answer": "Mooreâ€“Penrose. The Mooreâ€“Penrose inverse is used as a generalized inverse for matrices that are not invertible, making it suitable for the singular Wishart distribution scenario discussed.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2008\\ScienceDirect_articles_01Mar2025_10-40-41.753\\Estimation-of-the-precision-matrix-of-a-singular-W\\Estimation-of-the-precision-matrix-of-a-singular-W.md",
      "Estimation-of-the-precision-matrix-of-a-singular-W.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Mooreâ€“Penrose",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Moore-Penrose\"\n}",
      "model_answer": "Moore-Penrose",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2831",
    "folder": "",
    "question": "Substationarity means that the distribution of a spatial point process (SPP) can only be invariant under location shifts within a [BLANK] of the domain.",
    "gold_answer": "linear subspace. This term is omitted to emphasize that substationarity is a concept that lies between stationarity and nonstationarity, focusing on invariance within specific subspaces.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "linear subspace",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"subset\"\n}",
      "model_answer": "subset",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3257",
    "folder": "",
    "question": "The stationary complex boundary for AR(2) processes is located at [BLANK], where unit root cycles at any frequency Ï‰ can be generated for values of Ï•â‚ in the range [âˆ’2,2].",
    "gold_answer": "Ï•â‚‚ = âˆ’1. This condition defines the stationary complex boundary for AR(2) processes, allowing for unit root cycles at any frequency Ï‰.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï•â‚‚ = âˆ’1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï•â‚‚ = -1\"\n}",
      "model_answer": "Ï•â‚‚ = -1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3278",
    "folder": "",
    "question": "In the context of estimating linear functionals of a bivariate distribution with equal marginals, the empirical estimator is efficient if the distribution Q is completely unknown. However, if X and Y are independent, a better estimator is given by [BLANK].",
    "gold_answer": "the U-statistic based on the pooled sample. This estimator is efficient under the minimal assumptions for which it was derived, providing significant improvements over the empirical estimator when additional information about Q is available.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2005\\ScienceDirect_articles_01Mar2025_10-57-04.491\\Efficient-estimation-of-linear-functionals-of-a-bi\\Efficient-estimation-of-linear-functionals-of-a-bi.md",
      "Efficient-estimation-of-linear-functionals-of-a-bi.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the U-statistic based on the pooled sample",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the product of the marginal empirical distributions\"\n}",
      "model_answer": "the product of the marginal empirical distributions",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-878",
    "folder": "",
    "question": "For subjects who will never experience a recurrence of the event, referred to as zero-recurrence subjects, the first gap time is considered to be [BLANK].",
    "gold_answer": "infinite. This conceptualization allows the model to differentiate between subjects who are at risk of experiencing the event and those who are not, by assigning an infinite gap time to the latter.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "infinite",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"censored\"\n}",
      "model_answer": "censored",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1274",
    "folder": "",
    "question": "In the Bayesian method for estimating a mean in the face of mean-shift contamination, the posterior distribution is approximated to simplify computation. This approximation is given by $\\widetilde{\\theta}|y,k\\sim S t[n-k-1,\\hat{\\theta}_{k},\\widetilde{\\lambda}_{k}^{2}]$, where $\\widetilde{\\lambda}_{k}$ is defined as $(n-k-3)^{(1/2)}(n-k-1)^{-(\\bar{1/2})}\\tilde{\\lambda}_{k}$. What is the missing term in the definition of $\\widetilde{\\lambda}_{k}$?",
    "gold_answer": "$\\tilde{\\lambda}_{k}$ is defined as $(n-k-3)^{(1/2)}(n-k-1)^{-(\\bar{1/2})}\\hat{\\lambda}_{k}$. The missing term, $\\hat{\\lambda}_{k}$, is the posterior standard deviation of $\\theta$ given $y$ and $k$, highlighting the adjustment made for degrees of freedom in the approximation.",
    "source": [
      "Bayesian Robust Estimation of the Mean.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_35_Issue_1\\Bayesian Robust Estimation of the Mean\\Bayesian Robust Estimation of the Mean.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\tilde{\\lambda}_{k}$ is defined as $(n-k-3)^{(1/2)}(n-k-1)^{-(\\bar{1/2})}\\hat{\\lambda}_{k}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"hat\"\n}",
      "model_answer": "hat",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2657",
    "folder": "",
    "question": "The uniform distribution on the Stiefel manifold is a unit invariant measure on $O(n,\\phi)$ which we denote by [BLANK].",
    "gold_answer": "$[d{\\bf X}]$. This notation represents the uniform distribution on the Stiefel manifold, highlighting its invariance property under orthogonal transformations.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1977\\ScienceDirect_articles_02Mar2025_09-13-41.951\\Uniform-distribution-on-a-Stiefel-manifo_1977_Jour\\Uniform-distribution-on-a-Stiefel-manifo_1977_Jour.md",
      "Uniform-distribution-on-a-Stiefel-manifo_1977_Jour.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$[d{\\bf X}]$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¼\"\n}",
      "model_answer": "Î¼",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2875",
    "folder": "",
    "question": "The second approach developed to help understand EPICs is called the [BLANK] method, which aims at identifying easy-to-describe regions in the sample space that are dominated by one EPIC.",
    "gold_answer": "Prominent Region (PR). This method seeks to find regions in the feature space where one EPIC predominates, described by simple conditions on individual variables, aiding in the interpretation of EPICs.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Prominent Region (PR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"geometric\"\n}",
      "model_answer": "geometric",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-429",
    "folder": "",
    "question": "Low tidal volume ventilation (LTVV) is recommended as an effective ventilation strategy for patients with acute lung injury (ALI), based on the results of a randomized clinical trial comparing low versus high tidal volume strategies. The recommendation was made despite high non-adherence rates in the LTVV arm, where non-adherence occurred because treating physicians felt that deviating from the prescribed regime would improve patientsâ€™ outcomes. To address this controversy, researchers sought to estimate the survival distribution in the counterfactual setting where all patients assigned to LTVV followed the regime, using a fully Bayesian implementation of Robinsâ€™s [BLANK] formula.",
    "gold_answer": "G-computation. This formula is used to estimate the potential survival distribution under a specific treatment regime by integrating over the distribution of observed data, accounting for time-dependent confounders and missing data mechanisms.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_60_Issue_4\\Estimating the Causal Effect of Low Tidal Volume V\\Estimating the Causal Effect of Low Tidal Volume V.md",
      "Estimating the Causal Effect of Low Tidal Volume V.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "G-computation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"g\"\n}",
      "model_answer": "g",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2481",
    "folder": "",
    "question": "In the context of testing for serial correlation in least squares regression, the statistic used is denoted by [BLANK]. This statistic is calculated as the ratio of the sum of squared first differences of the residuals to the sum of squared residuals.",
    "gold_answer": "d. The statistic d is central to the Durbin-Watson test for serial correlation, measuring the degree of autocorrelation in the residuals from a regression analysis.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_38_Issue_1-2\\TESTING_FOR_SERIAL_CORRELATION_IN_LEAST_SQUARES_REGRESSION._II\\TESTING_FOR_SERIAL_CORRELATION_IN_LEAST_SQUARES_REGRESSION._II.md",
      "TESTING_FOR_SERIAL_CORRELATION_IN_LEAST_SQUARES_REGRESSION._II.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "d",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"d\"\n}",
      "model_answer": "d",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-899",
    "folder": "",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). We remove it from the question because it represents the core assumption that simplifies inference: once we condition on the observed responses, the missingness no longer depends on the unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3047",
    "folder": "",
    "question": "The reliability ratio (RR), defined as Var(X)/Var(W), is frequently used to quantify the amount of measurement error. In simulations studies with sample sizes of at least n=1000 and reliability ratios as low as [BLANK], the researchers rarely encountered an invalid set of estimated moments.",
    "gold_answer": "0.5. This value demonstrates the robustness of the MAI method under conditions of substantial measurement error, indicating its applicability even when the reliability of the measurements is relatively low.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0.3\"\n}",
      "model_answer": "0.3",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1489",
    "folder": "",
    "question": "In adaptive rejection sampling, the upper hull háµ¤(x) of h(x) consists of the tangents at {xáµ¢}. It is defined by the slope of the tangents h'(xáµ¢), the abscissae {zâ‚áµ¢â‚Ž} of the intersection between the tangents at xâ‚áµ¢â‚Ž and at xâ‚áµ¢â‚Šâ‚â‚Ž, and the values [BLANK]. Which term completes the definition of the upper hull?",
    "gold_answer": "háµ¤(zâ‚áµ¢â‚Ž). This term is essential as it represents the value of the upper hull at the intersection points, which are used to define the piecewise linear approximation of the log-density function.",
    "source": [
      "Adaptive Rejection Sampling from Log-Concave Densi.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_42_Issue_4\\Adaptive Rejection Sampling from Log-Concave Densi\\Adaptive Rejection Sampling from Log-Concave Densi.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "háµ¤(zâ‚áµ¢â‚Ž)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"h(xáµ¢)\"\n}",
      "model_answer": "h(xáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1945",
    "folder": "",
    "question": "In the context of identifying differentially expressed genes, the ODP approach transforms the data by centering each gene around zero to achieve nuisance parameter invariance. This transformation involves subtracting the estimated mean expression level of each gene from its observations. What is the purpose of this transformation?",
    "gold_answer": "The purpose is to approximately achieve the condition where the average null distribution across all genes equals the average null distribution of only the true null genes, thus ensuring that the nuisance parameters do not bias the ODP's performance.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The purpose is to approximately achieve the condition where the average null distribution across all genes equals the average null distribution of only the true null genes, thus ensuring that the nuisance parameters do not bias the ODP's performance",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"to achieve nuisance parameter invariance\"\n}",
      "model_answer": "to achieve nuisance parameter invariance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1000",
    "folder": "",
    "question": "In the application to polymer chemistry, the stress relaxation modulus G(Ï‰) can be represented as an integral involving the relaxation spectral measure Î¼, specifically G(Ï‰) = âˆ«_0^âˆž (1/x) e^(-Ï‰/x) dÎ¼(x). The measure Î¼ is assumed to be [BLANK].",
    "gold_answer": "finite. The assumption that Î¼ is a finite measure on (â„_+, â„›_+) is fundamental to the model, as it allows for the representation of the stress relaxation modulus in terms of an integral with respect to Î¼.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "finite",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nonnegative\"\n}",
      "model_answer": "nonnegative",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1175",
    "folder": "",
    "question": "The skew-normal random process is defined by the transformation of a stationary Gaussian process. If we let $X(s)$ be a stationary Gaussian random process with zero-mean, unit variance, and correlation function $\\rho(h)$, then the skew-normal random process $Z(s)$ can be defined as $Z(s) = \\sqrt{1-\\delta(s)^2}X(s) + \\delta(s)X''(s)$, where $X''(s) = X' | X' + \\varepsilon > 0$ and $X'$ is independent of $X(s)$. The slant function $\\delta(s)$ must satisfy [BLANK] for all $s \\in \\mathbb{S}$ to ensure the process is well-defined.",
    "gold_answer": "-1 < \\delta(s) < 1. This condition ensures that the transformation remains valid and the process retains the properties of a skew-normal distribution across its domain.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2017_Volume_44_Issue_1\\Scandinavian J Statistics - 2016 - Beranger - Mode\\Scandinavian J Statistics - 2016 - Beranger - Mode.md",
      "Scandinavian J Statistics - 2016 - Beranger - Mode.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "-1 < \\delta(s) < 1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"|\\delta(s)| < 1\"\n}",
      "model_answer": "|\\delta(s)| < 1",
      "error": "è­¦å‘Š: åŽŸå§‹JSONæ— æ•ˆï¼Œå·²é€šè¿‡json_repairä¿®å¤ã€‚"
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1504",
    "folder": "",
    "question": "The Maximum Likelihood Histogram (ML histogram) is defined as the maximizer of the log-likelihood in $\\mathcal{F}_{\\mathbb{Z}}$ and is given by $\\widehat{f}_{\\mathcal{Z}} := \\mathrm{argmax}_{f\\in\\mathcal{F}_{\\mathcal{Z}}}L(f,x_{1},\\ldots,x_{n}) = \\frac{1}{n}\\sum_{j=1}^{D}\\frac{N_{j}}{|I_{j}|}\\mathbb{1}_{I_{j}}$, where $N_{j} = \\sum_{i=1}^{n}\\mathbf{1}_{I_{j}}(x_{i})$. The log-likelihood is $L(\\hat{f}_{\\mathcal{T}},x_{1},\\dots,x_{n}) = \\sum_{j=1}^{D}N_{j}\\log\\frac{N_{j}}{n|I_{j}|}$. What is the term that represents the count of observations in the interval $I_{j}$?",
    "gold_answer": "$N_{j}$. This term counts the number of observations that fall into the interval $I_{j}$, which is crucial for calculating the height of the histogram bars in the ML histogram.",
    "source": [
      "Combining-regular-and-irregular-histograms-b_2010_.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2010\\ScienceDirect_articles_04Mar2025_11-16-58.341\\Combining-regular-and-irregular-histograms-b_2010_\\Combining-regular-and-irregular-histograms-b_2010_.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$N_{j}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"N_j\"\n}",
      "model_answer": "N_j",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3422",
    "folder": "",
    "question": "In the context of testing whether the proportion of failures of Type I varies in time, a simple test involves grouping the times of failure and testing by Ï‡Â² the hypothesis that the probability Ï€â‚(t) that a failure is of Type I is [BLANK].",
    "gold_answer": "constant. This test checks for temporal variation in the probability of Type I failures, a key assumption in distinguishing between different models of failure mechanisms.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "constant",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"constant\"\n}",
      "model_answer": "constant",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-271",
    "folder": "",
    "question": "In the context of analyzing three binary variables, $X$, $U_{1}$, and $U_{2}$, the measure $D_{P} = P_{X|U_{1}}(1|1) - P_{X|U_{1}}(1|0)$ is considered a measure of discrimination between the events $X=1$ and $X=0$ based on the information from $U_{1}$. The larger the value of $D_{P}$, the better the discriminator $U_{1}$. This discriminating ability may change according to the association level of the two $U$ variables, specifically as the [BLANK] between $U_{1}$ and $U_{2}$ increases.",
    "gold_answer": "cross-product ratio (CPR). The cross-product ratio between $U_{1}$ and $U_{2}$ is a key measure of their association level, and as it increases, the discriminating ability $D_{P}$ of $U_{1}$ for $X$ also increases, under the assumption that $X$ is positively associated with both $U_{1}$ and $U_{2}$.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_94_Issue_4\\Positive_Association_Among_Three_Binary_Variables_and_Cross-Product_Ratios\\Positive_Association_Among_Three_Binary_Variables_and_Cross-Product_Ratios.md",
      "Positive_Association_Among_Three_Binary_Variables_and_Cross-Product_Ratios.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "cross-product ratio (CPR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"correlation\"\n}",
      "model_answer": "correlation",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1920",
    "folder": "",
    "question": "In the Bayesian approach to estimating COVID-19 incidence and infection fatality rates, the probability that individual i has been infected with COVID-19 is given by logit(p_i) = [BLANK], where x_i is a vector of covariates and Î² is a vector of regression coefficients.",
    "gold_answer": "Î²^T x_i. This formula represents the logistic regression model used to relate an individualâ€™s covariates to their probability of infection.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î²^T x_i",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"x_i'Î²\"\n}",
      "model_answer": "x_i'Î²",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2522",
    "folder": "",
    "question": "In the approach to fitting sparse Seasonal Vector Autoregressive (SVAR) models based on Partial Spectral Coherences (PSCs), the seasonal filter Î¦_s(B^s) accounts for the between-cycle dependence structure. The sparse filter Î¦_s(B^s) can be estimated by following the approach of Davis et al. (2015) applied to the series Y_t^(m) = X_((t-1)s + m), where m is a fixed season. A new issue arising here is how to combine the information across different seasons m. Once the sparse seasonal filter is estimated, its seasonal effect on X_n can be removed, and then the between-season filter Î¦(B) can be estimated sparsely by following again the approach of Davis et al. (2015). The key step involves calculating the PSCs for each season m and then defining the rank of the seasonal PSC for the pair (j, k) as r(j, k) = sum from m=1 to s of R^(m)(j, k), where R^(m)(j, k) is the rank of the PSC for the pair (j, k) in season m. The term [BLANK] is used to rank the partial correlations in the between-cycle time series Y_t^(m).",
    "gold_answer": "r(j, k)",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "r(j, k)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"PSC\"\n}",
      "model_answer": "PSC",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1778",
    "folder": "",
    "question": "In the linear instrumental variables regression framework, the model averaging estimator is a weighted average of individual estimates obtained using different lists of valid instruments. The weights for averaging across individual estimates are obtained by direct smoothing of [BLANK] arising from the estimation stage.",
    "gold_answer": "selection criteria",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "selection criteria",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"t-statistics\"\n}",
      "model_answer": "t-statistics",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2882",
    "folder": "",
    "question": "In the context of multivalued functions, the integral of a function F is defined as the set of integrals of all measurable selections of F. This is known as the [BLANK] integral.",
    "gold_answer": "Aumann. The Aumann integral generalizes the concept of integration to multivalued functions by considering the integral of all measurable selections.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Aumann",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Aumann\"\n}",
      "model_answer": "Aumann",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2091",
    "folder": "",
    "question": "The likelihood ratio test for the hypothesis that the smaller of two canonical correlations is zero is nonsimilar; the distribution of the test statistic depends on the value of the largest canonical correlation. In applications the nuisance parameter usually has to be estimated, and this paper describes the distributional properties of the test, conditional on the estimator. Although these properties depend on the nuisance parameter, the dependency seems to be negligible for practical purposes. The hypothesis of interest is that the rank of the covariance matrix is at most one, or equivalently that [BLANK]. The likelihood ratio test statistic, suggested by Bartlett (1938), is given by LR = -n log(1 - râ‚‚Â²).",
    "gold_answer": "Î»Â² = 0. This is the hypothesis being tested, indicating that the smaller canonical correlation is zero, which implies the rank of the covariance matrix is at most one.",
    "source": [
      "Conditional_test_for_rank_in_bivariate_canonical_correlation_analysis.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_88_Issue_3\\Conditional_test_for_rank_in_bivariate_canonical_correlation_analysis\\Conditional_test_for_rank_in_bivariate_canonical_correlation_analysis.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î»Â² = 0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the smaller canonical correlation is zero\"\n}",
      "model_answer": "the smaller canonical correlation is zero",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-778",
    "folder": "",
    "question": "In the power studies section, the paper compares the performance of the proposed tests with that of Delgado's test. For the AR(1) model $U_{t}=b*U_{t-1}+\\delta_{t}$, Delgado's statistic performs slightly better, but for the nonlinear alternative $U_{t}=b\\delta_{t-1}^{2}+\\delta_{t}$, the proposed tests $V,~\\bar{V},~V^{*}$ or $\\bar{V}^{*}$ are more powerful. This illustrates the tests' ability to detect [BLANK].",
    "gold_answer": "nonlinear dependencies. The proposed tests show superior performance in detecting nonlinear relationships in the data, highlighting their versatility and robustness beyond linear alternatives.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "nonlinear dependencies",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nonlinear dependence\"\n}",
      "model_answer": "nonlinear dependence",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-613",
    "folder": "",
    "question": "The distribution of a stationary log Gaussian Cox process is completely characterized by its intensity and the [BLANK] function.",
    "gold_answer": "pair correlation",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "pair correlation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"covariance\"\n}",
      "model_answer": "covariance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-813",
    "folder": "",
    "question": "The estimator of the error density f_U proposed in the paper involves a deconvolution technique that requires the Fourier transform of the error density, f_U^Ft, to be real-valued and not vanish at any point on the real line. This condition is referred to as [BLANK].",
    "gold_answer": "Assumption 3. This assumption ensures that the deconvolution problem is well-posed and that the estimator of f_U can be accurately computed.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Assumption 3",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"identifiability\"\n}",
      "model_answer": "identifiability",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3243",
    "folder": "",
    "question": "In the context of extreme conditional expectile estimation, the expectile at level Î± is defined as the solution to a minimization problem involving the expectile check function Î·Î±(y). The expectile check function is given by Î·Î±(y) = [BLANK]. What is the correct form of the expectile check function?",
    "gold_answer": "|Î± âˆ’ ðŸ™{yâ‰¤0}|yÂ². The expectile check function is used in the minimization problem to define expectiles, which are analogous to quantiles but are based on squared loss rather than absolute loss, making them sensitive to the magnitude of deviations.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2022_Volume_49_Issue_1\\Scandinavian J Statistics - 2020 - Girard - Nonpar\\Scandinavian J Statistics - 2020 - Girard - Nonpar.md",
      "Scandinavian J Statistics - 2020 - Girard - Nonpar.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "|Î± âˆ’ ðŸ™{yâ‰¤0}|yÂ²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î±(y)â‚ŠÂ² + (1-Î±)(y)â‚‹Â²\"\n}",
      "model_answer": "Î±(y)â‚ŠÂ² + (1-Î±)(y)â‚‹Â²",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2240",
    "folder": "",
    "question": "For the extreme members in samples from normal populations, the second moment about the mean, Î¼â‚‚, for a sample size n=2 is [BLANK].",
    "gold_answer": "0.68169011. This value is derived from the specific calculations for the second moment of the extreme order statistic in samples of size 2 from a normal distribution.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2933",
    "folder": "",
    "question": "In the proposed Bayesian framework for VAR models, the shrinkage parameter Î» is selected at the minimum point of a newly proposed score function which is asymptotically equivalent to the [BLANK] of the model coefficients.",
    "gold_answer": "mean squared error. The score function is designed to approximate the mean squared error, providing a computationally feasible method for selecting the shrinkage parameter without relying on traditional MCMC sampling methods.",
    "source": [
      "Bayes-shrinkage-estimation-for-high-dimensional-VA.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2016\\ScienceDirect_articles_03Mar2025_09-01-58.435\\Bayes-shrinkage-estimation-for-high-dimensional-VA\\Bayes-shrinkage-estimation-for-high-dimensional-VA.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "mean squared error",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"mean squared error\"\n}",
      "model_answer": "mean squared error",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2250",
    "folder": "",
    "question": "In the context of tests for cointegration with structural breaks, the approach involves computing one of the usual test statistics from subsamples of the data. The breaks hypothesis asserts that there are periods in which fixed cointegrating relationships hold. The possibility of a consistent test requires that these periods must grow in length with the overall sample, and hence, the detection of a relationship should be possible by choosing an appropriate subsample for the test. In its most general form, this approach suggests some sort of [BLANK] sequence of subsamples.",
    "gold_answer": "incremental or rolling. This is because the approach aims to detect cointegrating relationships that may exist over varying subsamples of the data, by either incrementally adding observations or rolling through the dataset to evaluate different segments.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2010\\ScienceDirect_articles_04Mar2025_11-17-06.726\\Tests-for-cointegration-with-structural-brea_2010_\\Tests-for-cointegration-with-structural-brea_2010_.md",
      "Tests-for-cointegration-with-structural-brea_2010_.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "incremental or rolling",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"recursive\"\n}",
      "model_answer": "recursive",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1942",
    "folder": "",
    "question": "The most widely used approach for analyzing data from a multi-reader multi-test study is the [BLANK] method, which utilizes a standard analysis of variance (ANOVA) model for the jackknife pseudovalues of the area under the ROC curves (AUCs).",
    "gold_answer": "Dorfmanâ€“Berbaumâ€“Metz (DBM). This method is highlighted for its common use in analyzing multi-reader multi-test ROC data, despite lacking a clear theoretical basis.",
    "source": [
      "A marginal model approach for analysis of multi-re.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_6_Issue_2\\A marginal model approach for analysis of multi-re\\A marginal model approach for analysis of multi-re.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Dorfmanâ€“Berbaumâ€“Metz (DBM)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Dorfman-Berbaum-Metz\"\n}",
      "model_answer": "Dorfman-Berbaum-Metz",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2485",
    "folder": "",
    "question": "In the context of testing one hypothesis multiple times (TOHM), the global p-value is approximated using the expected Euler characteristic (EC) of the excursion set of the underlying random field. This approximation relies on the so-called [BLANK] heuristic.",
    "gold_answer": "EC heuristic. This heuristic is used to approximate the probability of observing a supremum of a random field above a certain threshold by considering the expected Euler characteristic of the excursion set, which simplifies the computation of global p-values in multidimensional settings.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_29\\Issue_2\\Testing_One_Hypothesis_Multiple_Times_The_Multidimensional_Case__Testing_One_Hypothesis_Multiple_Times__The_Multidimensional_Case\\Testing_One_Hypothesis_Multiple_Times_The_Multidimensional_Case__Testing_One_Hypothesis_Multiple_Times__The_Multidimensional_Case.md",
      "Testing_One_Hypothesis_Multiple_Times_The_Multidimensional_Case__Testing_One_Hypothesis_Multiple_Times__The_Multidimensional_Case.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "EC heuristic",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Poisson\"\n}",
      "model_answer": "Poisson",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2707",
    "folder": "",
    "question": "The Birnbaumâ€“Saunders distribution is receiving considerable attention due to its good properties. One of its extensions is the class of scale-mixture Birnbaumâ€“Saunders (SBS) distributions, which shares its good properties, but it also has further properties. The autoregressive conditional duration models are the primary family used for analyzing high-frequency financial data. We propose a methodology based on SBS autoregressive conditional duration models, which includes in-sample inference, goodness-of-fit and out-of-sample forecast techniques. We carry out a Monte Carlo study to evaluate its performance and assess its practical usefulness with real-world data of financial transactions from the New York stock exchange. The main objective of this work is to propose a methodology based on ACD models generated from SBS distributions (SBSâ€“ACD models). This methodology includes in-sample techniques considering estimation of the model parameters via the [BLANK] algorithm, inference about these parameters and model checking based on residual analysis, and out-of-sample forecast techniques.",
    "gold_answer": "EM (Expectationâ€“Maximization). The EM algorithm is highlighted as a method for efficiently computing the maximum likelihood (ML) estimates of the model parameters, which is crucial for the in-sample techniques mentioned.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "EM (Expectationâ€“Maximization)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"EM\"\n}",
      "model_answer": "EM",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-749",
    "folder": "",
    "question": "In the context of multiple imputation for missing data, Rubin & Schenker (1986) proposed the approximate Bayesian bootstrap method, which involves a two-stage resampling procedure. The first stage involves resampling [BLANK] values with replacement from the observed data.",
    "gold_answer": "n. This refers to the number of observed values resampled in the first stage of the approximate Bayesian bootstrap method, a critical step in creating multiple imputations for missing data.",
    "source": [
      "A_note_on_reducing_the_bias_of_the_approximate_Bayesian_bootstrap_imputation_variance_estimator.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_92_Issue_4\\A_note_on_reducing_the_bias_of_the_approximate_Bayesian_bootstrap_imputation_variance_estimator\\A_note_on_reducing_the_bias_of_the_approximate_Bayesian_bootstrap_imputation_variance_estimator.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "n",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"n\"\n}",
      "model_answer": "n",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1204",
    "folder": "",
    "question": "In penalized spline regression, the smoothness of the fitted curve is controlled by the parameter [BLANK], which is often estimated using restricted maximum likelihood (REML).",
    "gold_answer": "Î» (lambda). This parameter determines the influence of the penalty matrix on the smoothness of the spline, with higher values leading to smoother curves.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î» (lambda)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"lambda\"\n}",
      "model_answer": "lambda",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-618",
    "folder": "",
    "question": "In the context of log Gaussian Cox processes, the 'scale' parameter Î² is with respect to [BLANK].",
    "gold_answer": "locations",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "locations",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the covariance function\"\n}",
      "model_answer": "the covariance function",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1930",
    "folder": "",
    "question": "The EM algorithm is used in the two-stage model to handle missing data on tumor characteristics under the assumption that the data are [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the EM algorithm to provide valid inferences without explicitly modeling the missingness process, by allowing the missingness to depend only on observed data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-825",
    "folder": "",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yáµ¢â±¼ can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where Î±áµ£ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "báµ¢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_59_Issue_1\\Order_statistics_from_nonnormal_populations\\Order_statistics_from_nonnormal_populations.md",
      "Order_statistics_from_nonnormal_populations.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2713",
    "folder": "",
    "question": "In structural equation models for benchmark analysis, the observed exposures and outcomes are assumed to depend on underlying latent variables and a random measurement error. The latent exposure is denoted as [BLANK], and the latent response is denoted as Î·â‚‚.",
    "gold_answer": "Î·â‚. This is excluded to highlight the distinction between the latent exposure (Î·â‚) and the latent response (Î·â‚‚) in the model, emphasizing the structural relationships between these unobserved variables.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_8_Issue_4\\Estimation of the benchmark dose by structural equ\\Estimation of the benchmark dose by structural equ.md",
      "Estimation of the benchmark dose by structural equ.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î·â‚",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î·â‚\"\n}",
      "model_answer": "Î·â‚",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1555",
    "folder": "",
    "question": "In the intraclass correlation model, the covariance matrix Î£ is expressed as ÏƒÂ²[(1-Ï)I + Ï11'], where [BLANK] is the intraclass correlation coefficient.",
    "gold_answer": "Ï. This coefficient measures the degree of correlation among the observations within the same class or group.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï\"\n}",
      "model_answer": "Ï",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1037",
    "folder": "",
    "question": "In the variance-based sensitivity model, the residual variation in the true weights not explained by the estimated weights is parameterized by an [BLANK] value.",
    "gold_answer": "RÂ². This parameter represents the proportion of variance in the true weights that is not explained by the estimated weights, providing a measure of imbalance due to omitted confounders.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "RÂ²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"error\"\n}",
      "model_answer": "error",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1136",
    "folder": "",
    "question": "The Akaike Information Criterion, AIC, and a bias-corrected version, [BLANK], are two methods for selection of regression and autoregressive models.",
    "gold_answer": "AICc. The bias-corrected version of AIC is denoted as AICc and is used to adjust for small sample sizes.",
    "source": [
      "Bias_of_the_corrected_AIC_criterion_for_underfitted_regression_and_time_series_models.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_78_Issue_3\\Bias_of_the_corrected_AIC_criterion_for_underfitted_regression_and_time_series_models\\Bias_of_the_corrected_AIC_criterion_for_underfitted_regression_and_time_series_models.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "AICc",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"AICc\"\n}",
      "model_answer": "AICc",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-384",
    "folder": "",
    "question": "The Dickeyâ€“Fuller test evaluates the null hypothesis of unit root non-stationarity, under no missing data. Beyond recommendations under data missing completely at random for complete case analysis or last observation carry forward imputation, researchers have not extended unit root nonstationarity testing to more complex missing data mechanisms. Multiple imputation with chained equations, Kalman smoothing imputation, and linear interpolation have also been used for time-series data, however such methods impose constraints on the autocorrelation structure and impact unit root testing. We propose maximum likelihood estimation and multiple imputation using state space model approaches to adapt the augmented Dickeyâ€“Fuller test to a context with missing data. We further develop sensitivity analyses to examine the impact of [BLANK] data.",
    "gold_answer": "MNAR (Missing Not at Random). This term is omitted to highlight the focus on examining the impact of data that is missing not at random, which is a more complex missingness mechanism than MCAR or MAR.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_73_Issue_3\\Testing unit root non-stationarity in the presence\\Testing unit root non-stationarity in the presence.md",
      "Testing unit root non-stationarity in the presence.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "MNAR (Missing Not at Random)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing\"\n}",
      "model_answer": "missing",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-44",
    "folder": "",
    "question": "In the simplified model for a panel of time series observations, the equation is given by X_{(i)t} = âˆ‘_{j=1}^{p}a_{j}X_{(i)t-j} + Î·_{t} + Îµ_{(i)t}, where Î·_{t} represents [BLANK].",
    "gold_answer": "effects over time influencing all of the series. This term captures the common temporal effects across the panel, highlighting the intercorrelation among the series.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "effects over time influencing all of the series",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"a common shock\"\n}",
      "model_answer": "a common shock",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2124",
    "folder": "",
    "question": "The EM algorithm for the TCFA model involves an E-step that calculates the conditional expectations of the complete log-likelihood function. Specifically, it requires the computation of $\\widehat{\\mathbf{y}_{i}}^{(k)} = E\\left[\\mathbf{y}_{i}|\\mathbf{V}_{i},\\mathbf{C}_{i},\\pmb{\\theta}^{(k)}\\right]$ and $\\widehat{\\mathbf{y}_{i}\\mathbf{y}_{i}^{\\top}}^{(k)} = E\\left[\\mathbf{y}_{i}\\mathbf{y}_{i}^{\\top}|\\mathbf{V}_{i},\\mathbf{C}_{i},\\pmb{\\theta}^{(k)}\\right]$. These expectations are the first and second moments of a [BLANK] distribution, which are essential for the E-step computations.",
    "gold_answer": "multivariate truncated normal. These moments are crucial for updating the parameters in the M-step of the EM algorithm, as they account for the censoring in the data.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "multivariate truncated normal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"truncated multivariate normal\"\n}",
      "model_answer": "truncated multivariate normal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-434",
    "folder": "",
    "question": "In network meta-analysis, it is often desirable to synthesize different types of studies, featuring aggregated data and individual patient level data. However, existing methods do not sufficiently consider the quality of studies across different types of data and assume that the treatment effects are exchangeable across all studies regardless of these types. We propose Bayesian hierarchical network meta-analysis models that allow us to borrow information adaptively across aggregated data and individual patient level data studies by using [BLANK] and commensurate priors. The power parameter in the power priors and spike-and-slab hyperprior in the commensurate priors govern the level of borrowing information among study types.",
    "gold_answer": "power priors. This is excluded to highlight the method's ability to adaptively borrow information across different types of studies by adjusting the influence of each study type based on its quality.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_67_Issue_4\\Power and Commensurate Priors for Synthesizing Agg\\Power and Commensurate Priors for Synthesizing Agg.md",
      "Power and Commensurate Priors for Synthesizing Agg.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "power priors",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"power priors\"\n}",
      "model_answer": "power priors",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3423",
    "folder": "",
    "question": "For the Weibull distribution, the distribution function is given by 1-exp{-(Î³t)^(1+[BLANK])}.",
    "gold_answer": "Î². This parameter adjusts the shape of the Weibull distribution, allowing it to model various types of failure rate behaviors over time.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î²\"\n}",
      "model_answer": "Î²",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-385",
    "folder": "",
    "question": "Edwards' test for seasonality and a suggested alternative likelihood ratio test are compared. The tests are almost identical for samples of [BLANK] observations or more, but for small samples the likelihood ratio test is considerably superior.",
    "gold_answer": "200. This highlights the threshold sample size beyond which both tests perform similarly, emphasizing the likelihood ratio test's advantage with smaller datasets.",
    "source": [
      "Comparison of Two Tests for Seasonality in Epidemi.md",
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_25_Issue_3\\Comparison of Two Tests for Seasonality in Epidemi\\Comparison of Two Tests for Seasonality in Epidemi.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "200",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"50\"\n}",
      "model_answer": "50",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-289",
    "folder": "",
    "question": "In the context of additive and causal interactions under exposure misclassification, the condition for positive interaction on the linear additive scale is given by p11 - p10 - p01 + p00 > 0. If this condition is satisfied, it implies that the effects of X1 and X2 together exceed the sum of the effects of X1 and X2 considered individually, that is, (p11 - p00) > (p10 - p00) + (p01 - p00). The standard condition for positive interaction on the linear additive scale is expressed as [BLANK] > 0.",
    "gold_answer": "p11 - p10 - p01 + p00. This condition is fundamental for identifying when the combined effect of two exposures exceeds the sum of their individual effects, indicating a synergistic interaction.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_99_Issue_2\\Inference_for_additive_interaction_under_exposure_misclassification\\Inference_for_additive_interaction_under_exposure_misclassification.md",
      "Inference_for_additive_interaction_under_exposure_misclassification.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "p11 - p10 - p01 + p00",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"p11 - p10 - p01 + p00\"\n}",
      "model_answer": "p11 - p10 - p01 + p00",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3535",
    "folder": "",
    "question": "In the analysis of a dam with infinite depth and unit release per unit time, the inputs form a compound Poisson process with parameter [BLANK]. What is the parameter of the Poisson process that models the inputs?",
    "gold_answer": "Î». This parameter represents the rate of the Poisson process, which is crucial for modeling the timing of inputs into the dam.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_28_Issue_2\\The Almost Full Dam with Poisson Input\\The Almost Full Dam with Poisson Input.md",
      "The Almost Full Dam with Poisson Input.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î»",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-827",
    "folder": "",
    "question": "In the context of censored samples from truncated normal distributions, the probability density function of a normal distribution with mean, m, and standard deviation, Ïƒ, truncated on the left at a fixed terminus, xâ‚€, can be written as f(x) = (Iâ‚Ïƒâˆš(2Ï€))â»Â¹exp{-[(x - m)Â²/(2ÏƒÂ²)]} for xâ‚€ â‰¤ x â‰¤ âˆž, and f(x) = 0 for x < xâ‚€. Here, Iâ‚ = I(Î¾â‚) represents the proportion of the complete distribution retained after truncation, where Î¾â‚ is the left terminus in standard units of the complete distribution, defined as Î¾â‚ = [BLANK].",
    "gold_answer": "(xâ‚€ - m)/Ïƒ. This formula calculates the truncation point in standard units, which is essential for determining the proportion of the distribution that remains after truncation.",
    "source": [
      "Censored_samples_from_truncated_normal_distributions.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_42_Issue_3-4\\Censored_samples_from_truncated_normal_distributions\\Censored_samples_from_truncated_normal_distributions.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "(xâ‚€ - m)/Ïƒ",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"(xâ‚€ - m)/Ïƒ\"\n}",
      "model_answer": "(xâ‚€ - m)/Ïƒ",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2339",
    "folder": "",
    "question": "In the AR(1) model with heteroscedasticity, the error term u_t is defined as u_t = Ïu_{t-1} + e_t, where e_t are normally and independently distributed with mean 0 and variance [BLANK]. What is the correct term to fill in the blank?",
    "gold_answer": "w_tÏƒ^2. This term represents the variance of the error term e_t, which is a function of a known vector z_t and parameters Î», highlighting the heteroscedastic nature of the model.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_73_Issue_2\\Score_test_for_the_first-order_autoregressive_model_with_heteroscedasticity\\Score_test_for_the_first-order_autoregressive_model_with_heteroscedasticity.md",
      "Score_test_for_the_first-order_autoregressive_model_with_heteroscedasticity.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "w_tÏƒ^2",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ïƒ_t^2\"\n}",
      "model_answer": "Ïƒ_t^2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-489",
    "folder": "",
    "question": "In the context of elliptical distributions, the sample covariance is not an efficient estimator unless the condition [BLANK] is met.",
    "gold_answer": "E(R^2) = 8. This condition is crucial for the sample covariance to be efficient in the general case of elliptical distributions, as it relates to the variance of the underlying random variable R.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "E(R^2) = 8",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"p = 1\"\n}",
      "model_answer": "p = 1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1050",
    "folder": "",
    "question": "A key assumption for the convergence of empirical Gittins indices to the true Gittins indices is that the transition probability páµ(x, x') is [BLANK] for all k âˆˆ K and x, x' âˆˆ Ï‡áµ.",
    "gold_answer": "greater than zero. This ensures that every state is accessible from any other state, facilitating the estimation process and ensuring the Markov chains are ergodic.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "greater than zero",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"known\"\n}",
      "model_answer": "known",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-902",
    "folder": "",
    "question": "In the context of particle counting, the concentration of particles on the plate is measured by the quantity Ïˆ = Ï€NÎ´Â²/4A, where Ïˆ represents the ratio of the sum of the areas of the particles to the area of the plate. For the model to be justifiable, we assume that for a given concentration Ïˆ, N is sufficiently large, and [BLANK] is sufficiently small to neglect certain 'edge effects' and deal merely with the expected numbers of clumps of various sizes. What is the term that is deliberately omitted here?",
    "gold_answer": "Î´Â²/A. This term is omitted to highlight the condition that the square of the particle diameter divided by the area of the plate must be sufficiently small to justify neglecting edge effects and focusing on expected clump numbers without considering sampling variation.",
    "source": [
      "AN_OVERLAP_PROBLEM_ARISING_IN_PARTICLE_COUNTING.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_36_Issue_3-4\\AN_OVERLAP_PROBLEM_ARISING_IN_PARTICLE_COUNTING\\AN_OVERLAP_PROBLEM_ARISING_IN_PARTICLE_COUNTING.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î´Â²/A",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î´\"\n}",
      "model_answer": "Î´",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3534",
    "folder": "",
    "question": "In the linear functional relationship model where Î·áµ¢ = Î² + Î±Î¾áµ¢, and given that Î¾áµ¢ and Î·áµ¢ are normally distributed with the same variances and zero correlations, the maximum likelihood estimate of Î± when Î» = Î´yÂ²/Î´xÂ² is known is given by a formula involving Î˜. What is the formula for Î˜?",
    "gold_answer": "Î˜ = (Î£(y - È³)Â² - Î»Î£(x - xÌ„)Â²) / (2Î£(x - xÌ„)(y - È³)). This formula is crucial for estimating the slope Î± in the presence of known variance ratio Î», highlighting the relationship between the variances of y and x and their covariance.",
    "source": [
      "Confidence Limits for the Gradient in the Linear F.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_18_Issue_1\\Confidence Limits for the Gradient in the Linear F\\Confidence Limits for the Gradient in the Linear F.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î˜ = (Î£(y - È³)Â² - Î»Î£(x - xÌ„)Â²) / (2Î£(x - xÌ„)(y - È³))",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î» - 1 + [(Î» - 1)Â² + 4Î»rÂ²]^(1/2)\"\n}",
      "model_answer": "Î» - 1 + [(Î» - 1)Â² + 4Î»rÂ²]^(1/2)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-595",
    "folder": "",
    "question": "In the proposed multi-dimensional functional principal component analysis, the first FPC Ïˆâ‚(u,Î½,t) is obtained by minimizing a specific objective function subject to ||Ïˆâ‚||Â² = 1. What is the critical element omitted in the objective function?",
    "gold_answer": "The critical element omitted is the estimated mean function Î¼Ì‚(uáµ¢â±¼,Î½áµ¢â±¼,táµ¢â±¼). This highlights the importance of centering the data by subtracting the mean function before estimating the functional principal components, ensuring that the analysis focuses on the variation around the mean.",
    "source": [
      "Dynamic_Survival_Prediction_Using_Sparse_Longitudinal_Images_via_Multi-Dimensional_Functional_Principal_Component_Analys__Dynamic_Survival_Prediction_Using_Sparse_Longitudinal_Images_via_Multi-Dimensional_Functional_Principal_Component_Analysis.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_33\\Issue_4\\Dynamic_Survival_Prediction_Using_Sparse_Longitudinal_Images_via_Multi-Dimensional_Functional_Principal_Component_Analys__Dynamic_Survival_Prediction_Using_Sparse_Longitudinal_Images_via_Multi-Dimensional_Functional_Principal_Component_Analysis\\Dynamic_Survival_Prediction_Using_Sparse_Longitudinal_Images_via_Multi-Dimensional_Functional_Principal_Component_Analys__Dynamic_Survival_Prediction_Using_Sparse_Longitudinal_Images_via_Multi-Dimensional_Functional_Principal_Component_Analysis.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The critical element omitted is the estimated mean function Î¼Ì‚(uáµ¢â±¼,Î½áµ¢â±¼,táµ¢â±¼)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»â‚Ïˆâ‚\"\n}",
      "model_answer": "Î»â‚Ïˆâ‚",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-419",
    "folder": "",
    "question": "In the context of extreme value analysis, the generalized extreme value (GEV) distribution is used to model the behavior of extreme events. The GEV distribution is characterized by three parameters: location (Î¼), scale (Ïƒ), and shape (Î¾). The shape parameter Î¾ determines the heaviness of the tail, where Î¾ < 0 corresponds to distributions with a finite upper end point, and Î¾ â‰¥ 0 corresponds to distributions with an infinite upper end point. The formula for the GEV distribution is given by: exp[-{1 + Î¾((x - Î¼)/Ïƒ)}+^(-1/Î¾)]. What is the term inside the curly braces {} that is raised to the power of -1/Î¾?",
    "gold_answer": "1 + Î¾((x - Î¼)/Ïƒ). This term is crucial as it defines the behavior of the tail of the distribution, influencing how extreme values are modeled.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1 + Î¾((x - Î¼)/Ïƒ)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1 + Î¾((x - Î¼)/Ïƒ)\"\n}",
      "model_answer": "1 + Î¾((x - Î¼)/Ïƒ)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1822",
    "folder": "",
    "question": "The kernel method of estimating the cell probabilities of a multivariate categorical distribution, due to Aitchison & Aitken (1976), depends crucially on an unknown smoothing parameter [BLANK]. A method of estimating this parameter is introduced which is explicitly connected to multivariate discrimination.",
    "gold_answer": "Î» (lambda). This is the smoothing parameter that plays a critical role in the kernel method for estimating cell probabilities in multivariate categorical distributions, as highlighted by Aitchison & Aitken (1976).",
    "source": [
      "An_alternative_choice_of_smoothing_for_kernel-based_density_estimates_in_discrete_discriminant_analysis.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_73_Issue_2\\An_alternative_choice_of_smoothing_for_kernel-based_density_estimates_in_discrete_discriminant_analysis\\An_alternative_choice_of_smoothing_for_kernel-based_density_estimates_in_discrete_discriminant_analysis.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î» (lambda)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»\"\n}",
      "model_answer": "Î»",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-435",
    "folder": "",
    "question": "In the penalized hazard model, the log-hazard function is expressed as a sum of functions, each representing a marginal basis or a tensor product of marginal bases. The general form is given by log{h(t;x)} = Î£gâ±¼(t;x), where h is the hazard function, t is the follow-up time, and x is a vector of continuous covariates. The function gâ±¼ can be a marginal basis of time, a marginal basis of a covariate, or the tensor product of the marginal bases of any elements of (t, x). For a marginal basis, gâ±¼(x) = Î£Î²â±¼áµ¢bâ±¼áµ¢(x), where bâ±¼áµ¢ are known functions and Î²â±¼áµ¢ are coefficients to estimate. For a tensor product involving time t and covariates xâ‚ and xâ‚‚, gâ±¼(t, xâ‚, xâ‚‚) = Î£Î£Î£Î²áµ¢â‚œ,áµ¢â‚,áµ¢â‚‚bâ‚œáµ¢â‚œ(t)bâ‚“â‚áµ¢â‚(xâ‚)bâ‚“â‚‚áµ¢â‚‚(xâ‚‚). The key element omitted here is the [BLANK], which controls the trade-off between model fit and model smoothness.",
    "gold_answer": "smoothing parameters (Î»â‚˜). These parameters are crucial as they determine the extent to which the model penalizes roughness in the fitted functions, thus balancing the fit to the data against the smoothness of the model.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_68_Issue_5\\Multi-Dimensional Penalized Hazard Model with Cont\\Multi-Dimensional Penalized Hazard Model with Cont.md",
      "Multi-Dimensional Penalized Hazard Model with Cont.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "smoothing parameters (Î»â‚˜)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"penalty term\"\n}",
      "model_answer": "penalty term",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-730",
    "folder": "",
    "question": "In the context of the MESV model, the term [BLANK] refers to the correlation between the ith asset return at time t and the function of jth asset volatility at time t+1.",
    "gold_answer": "cross leverage",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "cross leverage",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"leverage effect\"\n}",
      "model_answer": "leverage effect",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1226",
    "folder": "",
    "question": "In certain longitudinal clinical studies, two ordinal variables (e.g., a therapeutic effect rating and a side-effect rating) are repeatedly measured at scheduled visits but may be missing for some patients who do not return. If we let Yáµ¢ = (Yáµ¢â‚, ..., Yáµ¢â±¼) represent the patientâ€™s responses over time, one method to jointly analyze both ordinal outcomes and their missingness is to factorize the likelihood into a product of the outcome model and the missingness mechanism. In selection modeling, this can be expressed as f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK], where Ráµ¢ denotes the missingness indicators. Which missingness-related term is deliberately omitted in this equation?",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). We remove it to highlight that, in a selection framework, the distribution of the missingness (Ráµ¢) may depend on the observed and unobserved outcomes (Yáµ¢), which is precisely what distinguishes selection models from patternâ€“mixture approaches.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1315",
    "folder": "",
    "question": "A sufficient condition for the identifiability of the contaminated Gaussian HMM is that if k â‰  kâ‚ implies ||Î¼â‚– - Î¼â‚–â‚||â‚‚Â² + ||Î£â‚– - aÎ£â‚–â‚||â‚‚Â² â‰  0 for all a > 0, where ||Â·||â‚‚ is the Frobenius norm. This ensures that the finite mixture of contaminated Gaussian distributions is identifiable if two of the K Gaussian distributions representing the good observations have distinct component means and/or [BLANK]. What is the missing condition?",
    "gold_answer": "nonproportional component covariance matrices. This condition is crucial for distinguishing between different states based on their covariance structures, ensuring the model's identifiability.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "nonproportional component covariance matrices",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"covariance matrices\"\n}",
      "model_answer": "covariance matrices",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2274",
    "folder": "",
    "question": "The sample frequency spectrum (SFS) is a summary statistic which describes the distribution of mutant alleles at a polymorphic site in a sample of DNA sequences and provides a highly efficient dimensional reduction of large-scale population genomic variation data. The joint SFS data from multiple populations can be used to infer parameters of complex demographic histories, including variable population sizes, population split times, migration rates, admixture proportions, and so on. SFS-based inference methods require accurate computation of the expected SFS under a given demographic model. The expected joint SFS for thousands of individuals sampled from hundreds of populations related by a complex demographic model with arbitrary population size histories can be computed using new analytic formulas and algorithms implemented in a software package called [BLANK].",
    "gold_answer": "momi (MOran Models for Inference). The blank is filled with the name of the software package that implements the new analytic formulas and algorithms for computing the expected joint SFS, highlighting its role in demographic inference.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_26\\Issue_1\\Efficient_Computation_of_the_Joint_Sample_Frequency_Spectra_for_Multiple_Populations__Efficient_Computation_of_the_Joint_Sample_Frequency_Spectra_for_Multiple_Populations\\Efficient_Computation_of_the_Joint_Sample_Frequency_Spectra_for_Multiple_Populations__Efficient_Computation_of_the_Joint_Sample_Frequency_Spectra_for_Multiple_Populations.md",
      "Efficient_Computation_of_the_Joint_Sample_Frequency_Spectra_for_Multiple_Populations__Efficient_Computation_of_the_Joint_Sample_Frequency_Spectra_for_Multiple_Populations.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "momi (MOran Models for Inference)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"moments\"\n}",
      "model_answer": "moments",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3323",
    "folder": "",
    "question": "In the context of constructing a joint confidence region for an overall ranking of populations, the main result states that for each population k, the rank r_k is contained in the set {|Î›_Lk| + 1, |Î›_Lk| + 2, ..., |Î›_Lk| + |Î›_Ok| + 1}, where Î›_Lk and Î›_Ok are defined based on the overlap of confidence intervals. What critical element is missing from this description that defines Î›_Lk and Î›_Ok?",
    "gold_answer": "The definition of Î›_Lk as the set of populations j where U_j â‰¤ L_k, and Î›_Ok as the set of populations j where U_j > L_k and U_k > L_j. This is crucial for understanding how the overlap or lack thereof between confidence intervals influences the possible ranks of each population.",
    "source": [
      "A Joint Confidence Region for an Overall Ranking o.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_69_Issue_3\\A Joint Confidence Region for an Overall Ranking o\\A Joint Confidence Region for an Overall Ranking o.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The definition of Î›_Lk as the set of populations j where U_j â‰¤ L_k, and Î›_Ok as the set of populations j where U_j > L_k and U_k > L_j",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"confidence intervals\"\n}",
      "model_answer": "confidence intervals",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3321",
    "folder": "",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK]. This assumption is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by stating that once we condition on the observed responses, the missingness no longer depends on the unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-566",
    "folder": "",
    "question": "In the context of interval-censored failure time data analysis, the joint distribution of the failure time T and the censoring interval length W given covariates Z can be expressed using a copula function as K(t, w) = CÎ±(FT(t), FW(w)), where FT and FW are the marginal distributions of T and W given Z, respectively. The term [BLANK] in this equation represents the association parameter that captures the dependence between T and W.",
    "gold_answer": "Î±. This term is crucial as it quantifies the degree of dependence between the failure time and the censoring interval length, which is essential for accurately modeling and analyzing interval-censored data when the censoring mechanism is dependent on the failure time.",
    "source": [
      "Cox-regression-analysis-of-dependent-interval-_201.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2016\\ScienceDirect_articles_03Mar2025_09-01-52.515\\Cox-regression-analysis-of-dependent-interval-_201\\Cox-regression-analysis-of-dependent-interval-_201.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î±",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î±\"\n}",
      "model_answer": "Î±",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2574",
    "folder": "",
    "question": "In the analysis of the Lachish skulls, the percentage of cases with no teeth lost before death is high, but it must be remembered that the age constitution, judging from the state of the sutures, indicates a younger group, on the average, than that expected in a cemetery population. The frequencies of adult upper jaws with one or both third molars absent are not unusual, but it is customary to find the female percentage greater than the male. The samples are too small, however, to give a reliable sexual comparison in this respect. The condition where one or both third molars are absent is referred to as [BLANK].",
    "gold_answer": "congenitally absent. This term is used to describe the absence of third molars from birth, which is a common dental anomaly observed in the study.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_31_Issue_1-2\\REMARKS_ON_THE_CONDITION_AND_ANOMALIES_OF_THE_JAWS_OF_THE_LACHISH_SKULLS\\REMARKS_ON_THE_CONDITION_AND_ANOMALIES_OF_THE_JAWS_OF_THE_LACHISH_SKULLS.md",
      "REMARKS_ON_THE_CONDITION_AND_ANOMALIES_OF_THE_JAWS_OF_THE_LACHISH_SKULLS.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "congenitally absent",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"agenesis\"\n}",
      "model_answer": "agenesis",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3098",
    "folder": "",
    "question": "In selection modeling, the joint analysis of both ordinal outcomes and their missingness can be expressed as f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK], where Ráµ¢ denotes the missingness indicators.",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). This term highlights the dependency of the missingness distribution on the observed and unobserved outcomes, distinguishing selection models from patternâ€“mixture approaches.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-816",
    "folder": "",
    "question": "The RAMSVM classifier uses a convex combination of two MSVM losses to form a new group of Fisher consistent hinge loss functions for multicategory problems. The convex combination parameter is denoted by [BLANK].",
    "gold_answer": "Î³ (gamma). This parameter balances the contribution of the two MSVM losses in the convex combination, allowing for a flexible and potentially more robust classification approach.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_25\\Issue_3\\Reinforced_Angle-Based_Multicategory_Support_Vector_Machines__Reinforced_Angle-Based_Multicategory_Support_Vector_Machines\\Reinforced_Angle-Based_Multicategory_Support_Vector_Machines__Reinforced_Angle-Based_Multicategory_Support_Vector_Machines.md",
      "Reinforced_Angle-Based_Multicategory_Support_Vector_Machines__Reinforced_Angle-Based_Multicategory_Support_Vector_Machines.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î³ (gamma)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»\"\n}",
      "model_answer": "Î»",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3244",
    "folder": "",
    "question": "In the context of hypothesis testing for a bivariate normal distribution with missing observations, the test statistic that discards additional X observations and uses only the pairs (Xáµ¢, Yáµ¢) for i=1,2,...,n is known as [BLANK]. This test is proven to be admissible for testing Hâ‚€: Î¼=0 vs. Hâ‚: Î¼â‰ 0.",
    "gold_answer": "Hotelling's TÂ² test. The missing element is highlighted to emphasize the specific test discussed in the paper, which is admissible under the given conditions.",
    "source": [
      "A-result-on-hypothesis-testing-for-a-multivariate-.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1977\\ScienceDirect_articles_02Mar2025_09-13-41.951\\A-result-on-hypothesis-testing-for-a-multivariate-\\A-result-on-hypothesis-testing-for-a-multivariate-.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Hotelling's TÂ² test",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"paired t-test\"\n}",
      "model_answer": "paired t-test",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1476",
    "folder": "",
    "question": "The convergence of the test statistic towards its asymptotic distribution is relatively slow. Thus, [BLANK] methods based on random samples are suggested to determine the corresponding critical values.",
    "gold_answer": "Monte Carlo",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Monte Carlo",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Monte Carlo\"\n}",
      "model_answer": "Monte Carlo",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3403",
    "folder": "",
    "question": "In the construction of non-orthogonal unsaturated main effect plans for any $k^{n}$ factorial, when $k$ is even, the method consists of forming $k^{n}/2$ pairs of treatment combinations. What property must these pairs satisfy?",
    "gold_answer": "Differences within pairs are clear of 'even' effects and sums are clear of 'odd' effects. This property is crucial for the construction method to ensure that the main effect plans can estimate the desired effects without interference from the other type of effects.",
    "source": [
      "A Unified Approach for Constructing a Useful Class.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_30_Issue_2\\A Unified Approach for Constructing a Useful Class\\A Unified Approach for Constructing a Useful Class.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Differences within pairs are clear of 'even' effects and sums are clear of 'odd' effects",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"complementary\"\n}",
      "model_answer": "complementary",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-635",
    "folder": "",
    "question": "The penalized least squares approach with smoothly clipped absolute deviation penalty has been consistently demonstrated to be an attractive regression shrinkage and selection method. It not only automatically and consistently selects the important variables, but also produces estimators which are as efficient as the [BLANK] estimator.",
    "gold_answer": "oracle. The oracle estimator is a theoretical benchmark that assumes knowledge of the true model, and the smoothly clipped absolute deviation method's estimators achieve similar efficiency under certain conditions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_94_Issue_3\\Tuning_parameter_selectors_for_the_smoothly_clipped_absolute_deviation_method\\Tuning_parameter_selectors_for_the_smoothly_clipped_absolute_deviation_method.md",
      "Tuning_parameter_selectors_for_the_smoothly_clipped_absolute_deviation_method.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "oracle",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"oracle\"\n}",
      "model_answer": "oracle",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-467",
    "folder": "",
    "question": "In the context of analyzing experimental data with potential wild points, the $L_{1}$ approximation is theoretically justified over $L_{2}$ approximation because it minimizes the sum of the absolute deviations, which is represented by the formula: $\\sum_{i=1}^{N}\\mid y_{i}-L(A,x_{i})\\mid$. This approach is particularly effective when the data contains [BLANK], as it tends to ignore or lightly weight these points.",
    "gold_answer": "wild points. The $L_{1}$ approximation's superiority in handling wild points is due to its robustness against outliers, minimizing the impact of these extreme values on the overall approximation.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_17_Issue_1\\L1 Approximation and the Analysis of Data\\L1 Approximation and the Analysis of Data.md",
      "L1 Approximation and the Analysis of Data.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "wild points",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"wild points\"\n}",
      "model_answer": "wild points",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2113",
    "folder": "",
    "question": "In the context of biclustering analysis of functionals via penalized fusion, the objective function for estimation without clustering includes a lack-of-fit term and a penalty term. The penalty term is given by [BLANK], where Î³â‚ is a non-negative tuning parameter and D is a matrix representing the second order differential operator.",
    "gold_answer": "Â½Î³â‚Î²áµ¢â±¼áµ€DÎ²áµ¢â±¼. This penalty term controls the smoothness of the estimation by penalizing the second derivative of the functional estimates, encouraging smoother functions.",
    "source": [
      "Biclustering-analysis-of-functionals-via-pena_2022.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2022\\ScienceDirect_articles_28Feb2025_08-31-08.158\\Biclustering-analysis-of-functionals-via-pena_2022\\Biclustering-analysis-of-functionals-via-pena_2022.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Â½Î³â‚Î²áµ¢â±¼áµ€DÎ²áµ¢â±¼",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î³â‚||DÎ²||â‚\"\n}",
      "model_answer": "Î³â‚||DÎ²||â‚",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2593",
    "folder": "",
    "question": "The structural dimension, denoted as d, is defined as the dimension of the [BLANK] or the central mean subspace.",
    "gold_answer": "central subspace. The structural dimension is a key concept in sufficient dimension reduction, representing the dimension of the central subspace or the central mean subspace.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "central subspace",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"central subspace\"\n}",
      "model_answer": "central subspace",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3194",
    "folder": "",
    "question": "In the mixed model, the F-statistic F_2(Ë†T_B) is based on the joint null hypothesis that there is a unit root and that the coefficients of the time-trend and the lagged trend-break dummy are both equal to zero. The data generating process under the unit root null hypothesis includes a term Î³ DU_{t-1}^0, where DU_{t-1}^0 is a dummy variable defined using the true break-date T_B^0, and e_t ~ i.i.d. (0,Ïƒ^2). The initial condition is set as y_0 = [BLANK].",
    "gold_answer": "0. This initial condition is commonly assumed in the derivation of the limiting distributions of unit root test statistics.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0\"\n}",
      "model_answer": "0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1676",
    "folder": "",
    "question": "In the context of nonlinear mixed effects models for repeated measures data, the test statistic for Neyman's partial score test under the null hypothesis has asymptotically a [BLANK] distribution.",
    "gold_answer": "Ï‡Â². This is because, under the null hypothesis, the test statistic follows a chi-square distribution with degrees of freedom equal to the number of independent restrictions over the parameters.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1995\\ScienceDirect_articles_02Mar2025_02-17-48.876\\Score-Tests-for-Fixed-Effects-and-Overdispersion-C\\Score-Tests-for-Fixed-Effects-and-Overdispersion-C.md",
      "Score-Tests-for-Fixed-Effects-and-Overdispersion-C.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï‡Â²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"chi-square\"\n}",
      "model_answer": "chi-square",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-183",
    "folder": "",
    "question": "In the context of modified profile likelihoods for stratified data, the condition for the profile likelihood to have the usual asymptotic distribution is $1/m=o(q^{-1})$, while for the modified profile likelihood, it is $1/m=o([BLANK])$. What is the missing term that completes the condition for the modified profile likelihood?",
    "gold_answer": "q^{-1/3}. This term is crucial as it indicates that the modified profile likelihood can achieve the usual asymptotic distribution under a weaker condition compared to the profile likelihood, allowing for more flexibility in the relationship between the number of strata (q) and the sample size per stratum (m).",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_90_Issue_3\\Modified_profile_likelihoods_in_models_with_stratum_nuisance_parameters\\Modified_profile_likelihoods_in_models_with_stratum_nuisance_parameters.md",
      "Modified_profile_likelihoods_in_models_with_stratum_nuisance_parameters.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "q^{-1/3}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1906",
    "folder": "",
    "question": "In the Bayesian methodology for multiple testing that asymptotically guarantees type I error control, the proposed approach is more powerful than the method of [BLANK], which is commonly utilized in practice as a more powerful alternative to the ubiquitous Bonferroni correction.",
    "gold_answer": "Holm (1979). This is highlighted to emphasize the comparative advantage of the Bayesian approach in controlling type I error while maintaining higher power across various correlations between outcomes.",
    "source": [
      "Bayesian multivariate probability of success using.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_24_Issue_1\\Bayesian multivariate probability of success using\\Bayesian multivariate probability of success using.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Holm (1979)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Benjamini and Hochberg\"\n}",
      "model_answer": "Benjamini and Hochberg",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2364",
    "folder": "",
    "question": "The PC-algorithm starts from a complete, undirected graph and deletes recursively edges based on [BLANK] decisions. This yields an undirected graph which can then be partially directed and further extended to represent the underlying DAG.",
    "gold_answer": "conditional independence. This is omitted to highlight the fundamental operation of the PC-algorithm, which relies on testing conditional independence to iteratively remove edges from the complete graph.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_17\\Issue_4\\Robustification_of_the_PC-Algorithm_for_Directed_Acyclic_Graphs__Robustification_of_the_PC-Algorithm_for_Directed_Acyclic_Graphs\\Robustification_of_the_PC-Algorithm_for_Directed_Acyclic_Graphs__Robustification_of_the_PC-Algorithm_for_Directed_Acyclic_Graphs.md",
      "Robustification_of_the_PC-Algorithm_for_Directed_Acyclic_Graphs__Robustification_of_the_PC-Algorithm_for_Directed_Acyclic_Graphs.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "conditional independence",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"conditional independence\"\n}",
      "model_answer": "conditional independence",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-842",
    "folder": "",
    "question": "The concept of a Î¼-pure field is analogous to the compactness of a class but is weaker because the Î¼-pure field depends on [BLANK] in an essential manner.",
    "gold_answer": "Î¼",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¼",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the measure\"\n}",
      "model_answer": "the measure",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3493",
    "folder": "",
    "question": "In the context of constructing a confidence region with prescribed maximum width and coverage probability for linear regression parameters, the sequential procedure's sample size N depends on d, and as d approaches 0, N(d) approaches infinity almost surely. The goal is to find a region R in p-dimensional Euclidean space such that P{Î² âˆˆ R} = Î± and the maximum diameter of R â‰¤ 2d. The missing element in the equation representing this goal is [BLANK].",
    "gold_answer": "P{Î² âˆˆ R} = Î±. This equation is fundamental as it sets the coverage probability requirement for the confidence region R, ensuring that the true parameter vector Î² lies within R with probability Î±.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_29_Issue_1\\On Fixed-Width Confidence Bounds for Regression Pa\\On Fixed-Width Confidence Bounds for Regression Pa.md",
      "On Fixed-Width Confidence Bounds for Regression Pa.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "P{Î² âˆˆ R} = Î±",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î±\"\n}",
      "model_answer": "Î±",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1443",
    "folder": "",
    "question": "A key assumption in the IRT approach for factor analysis with ordinal data is that, conditional on the latent variables, the observed variables are [BLANK]. This assumption simplifies the model by allowing the joint probability of the observed variables to be expressed as the product of their individual conditional probabilities.",
    "gold_answer": "independent. This conditional independence assumption is fundamental to the IRT approach, enabling the factorization of the joint probability distribution.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "independent",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"independent\"\n}",
      "model_answer": "independent",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1866",
    "folder": "",
    "question": "In the heterogeneous mixing model of infectious diseases, the force of infection for class (x,u) is given by Î»(t|x,u) = âˆ«Î²(x,u;y,v)I(t|y,v)dF(y,v). For the case where the transmission parameter can be factorized as Î²(x,u;y,v) = Î²(x,u)Î²(y,v), the hazard rate h(t|x,u) reduces to Î²(x,u)hâ‚€(t), where hâ‚€(t) is known as the [BLANK].",
    "gold_answer": "baseline hazard function. This term is crucial as it represents the hazard rate for a hypothetical subgroup with a mixing factor equal to one, scaling up based on the subgroup's contact with others.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_82_Issue_1\\The_empirical_content_of_canonical_models_of_infectious_diseases_The_proportional_hazard_specification\\The_empirical_content_of_canonical_models_of_infectious_diseases_The_proportional_hazard_specification.md",
      "The_empirical_content_of_canonical_models_of_infectious_diseases_The_proportional_hazard_specification.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "baseline hazard function",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"baseline hazard\"\n}",
      "model_answer": "baseline hazard",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2964",
    "folder": "",
    "question": "In the context of nonparametric quantile regression for VaR prediction, the Double Kernel Local Linear (DKLL) estimator is chosen because it localizes the data in both the x- and y-direction, which leads to smoother estimates. The estimator is defined as the inverse of a conditional distribution function, and for notational convenience, observations are assumed to be drawn from an underlying bivariate distribution F(x,y) with density f(x,y). The extension to the multivariate case is straightforward but requires a more tedious notation. The estimator is defined as the inverse of a conditional distribution function as in (2.1). Throughout this section, quantiles of return distributions are discussed, so that VaR corresponds to the negative quantile. A generic nonparametric method of estimating a conditional distribution F(y|x) is given by [BLANK], where I(Â·) is an indicator function and the weights w_t(x) are positive and sum up to one.",
    "gold_answer": "tilde{F}(y|x) = sum_{t=1}^n w_t(x) I(Y_t â‰¤ y). This formula represents a generic nonparametric method for estimating a conditional distribution function, highlighting the flexibility of nonparametric approaches in statistical estimation.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "tilde{F}(y|x) = sum_{t=1}^n w_t(x) I(Y_t â‰¤ y)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"F(y|x) = Î£ w_t(x)I(Y_t â‰¤ y)\"\n}",
      "model_answer": "F(y|x) = Î£ w_t(x)I(Y_t â‰¤ y)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1995",
    "folder": "",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a patternâ€“mixture perspective, where we distinguish subpopulations according to their missingness patterns. Suppose we rely on the â€˜neighboring case missing valueâ€™ approach (NCMV) so that missing values in a partially observed sequence borrow information only from the next identified pattern. If we consider the subpopulation distribution f(Y | pattern), we multiply this by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern (f(pattern)). We omit it to underscore that each pattern has a distinct distribution of Y, and combining them in a patternâ€“mixture approach requires weighting by the relative frequency of each pattern.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the proportion of that missingness pattern (f(pattern))",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(pattern)\"\n}",
      "model_answer": "P(pattern)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2681",
    "folder": "",
    "question": "In the context of split-plot designs, the varianceâ€“covariance matrix for the response vector y is given by V = ÏƒÂ²ÎµI_N + ÏƒÂ²Î³ZZâ€² = ÏƒÂ²Îµ(I_N + Î·D), where Î· = ÏƒÂ²Î³/ÏƒÂ²Îµ. The matrix D is block-diagonal, implying that observations in the same whole plot are correlated, while those from different whole plots are not. The matrix D is constructed using vectors of ones and zero matrices, specifically D = [1_n1â€²_n 0_n ... 0_n; 0_n 1_n1â€²_n ... 0_n; ...; 0_n 0_n ... 1_n1â€²_n], where 1_n is an n-dimensional vector of ones and 0_n is an nÃ—n zero matrix. The term [BLANK] represents the ratio of the variance components in the model.",
    "gold_answer": "Î· = ÏƒÂ²Î³/ÏƒÂ²Îµ. This ratio quantifies the relative importance of the whole-plot variance component compared to the error variance component in the model.",
    "source": [
      "A-coordinate-exchange-two-phase-local-search-algor.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2014\\ScienceDirect_articles_04Mar2025_11-06-53.618\\A-coordinate-exchange-two-phase-local-search-algor\\A-coordinate-exchange-two-phase-local-search-algor.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î· = ÏƒÂ²Î³/ÏƒÂ²Îµ",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î·\"\n}",
      "model_answer": "Î·",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2857",
    "folder": "",
    "question": "A collection of random variables $(Y_{1},...,Y_{b})$ is said to have a Dirichlet distribution with parameters $(\\mathfrak{v}_{1},...,\\mathfrak{v}_{b};\\mathfrak{v}_{b+1})$ written as $D(\\mathfrak{v}_{1},...,\\mathfrak{v}_{b};\\mathfrak{v}_{b+1})$ if they have the joint density ${\\frac{I(v_{1}+\\cdots+\\nu_{b+1})}{I(v_{1})\\cdots I(v_{b+1})}}\\left(\\prod_{1}^{b}y_{i}^{v_{i}-1}\\right)(1-y_{1}\\cdots-y_{\\mathsf{b}})^{v_{b+1}-1}$ over the $\\pmb{b}$ dimensional simplex $S_{b}=\\{(y_{1},...,y_{b}){:}y_{i}\\geqslant0,\\quad i=1,...,b,$ $\\begin{array}{r}{\\sum_{1}^{b}y_{i}\\leqslant1\\}}\\end{array}$ and zero outside $\\pmb{S_{b}}$ . This is a $b$ variate generalization of the familiar beta density. For an elementary exposition on Dirichlet distributions and some properties, see Wilks [11] and for a more detailed discussion as well as tables, see Sobel et al. [9]. Incomplete Dirichlet integrals are strongly connected with the multinomial and negative multinomial probabilities and these relations are explored in Olkin and Sobel [7] and Khatri and Mitra [5]. The integral $J_{p}^{(b)}(1,n)$ is defined for $0<p<1/b$ as the probability of the event $\\{Y_{i}>p,i=1,...,b\\}$ and is given by $J_{p}^{(b)}(1,n)={\\frac{n!}{(n-b)!}}\\int_{p}^{1}\\cdot\\stackrel{\\cdot\\cdot\\cdot}{\\scriptscriptstyle\\downarrow^{b}y_{1}\\leqslant1\\atop1}\\int_{p}^{1}\\left(1-\\sum_{1}^{b}y_{i}\\right)^{n-b}\\prod_{1}^{b}d y_{i}$. For $b=0$, $J_{p}^{(0)}(1,n)$ is defined to be equal to 1 if $\\pmb{p}$ is positive and zero otherwise. A recurrence formula for $\\pmb{\\cal J}_{p}^{(b)}(1,n)$ is obtained by integrating $y_{b}$ from $p$ to $1-\\textstyle\\sum_{i}^{b-1}y_{i}$ and transforming $y_{i}$ to $\\big(y_{i}/(1-p)\\big)$. Thus, $J_{p}^{(b)}(1,n)=(1-p)^{n}J_{p/(1-p)}^{(b-1)}(1,n)$. Using this relation repeatedly gives $J_{p}^{(b)}(1,n)=\\langle1-b p\\rangle^{n}$. Which mathematical operation is used to derive the final expression for $J_{p}^{(b)}(1,n)$ from the recurrence relation?",
    "gold_answer": "Iteration. The final expression for $J_{p}^{(b)}(1,n)$ is derived by repeatedly applying the recurrence relation until the base case is reached, demonstrating how the integral simplifies through iterative substitution.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1980\\ScienceDirect_articles_02Mar2025_02-37-42.362\\Incomplete-Dirichlet-integrals-with-applications-t\\Incomplete-Dirichlet-integrals-with-applications-t.md",
      "Incomplete-Dirichlet-integrals-with-applications-t.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Iteration",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"recursion\"\n}",
      "model_answer": "recursion",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1795",
    "folder": "",
    "question": "In the context of EM-type algorithms for computing restricted MLEs in multivariate normal distributions, the key idea is to introduce a sequence of latent variables such that the complete-data model belongs to the [BLANK], resulting in a simple E-step and an explicit M-step.",
    "gold_answer": "exponential family. This is crucial because it simplifies the estimation process by leveraging the properties of the exponential family, which facilitates both the expectation (E-step) and maximization (M-step) steps in the EM algorithm.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2008\\ScienceDirect_articles_04Mar2025_14-41-21.444\\EM-type-algorithms-for-computing-restricted-MLEs-i\\EM-type-algorithms-for-computing-restricted-MLEs-i.md",
      "EM-type-algorithms-for-computing-restricted-MLEs-i.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "exponential family",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"exponential family\"\n}",
      "model_answer": "exponential family",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1472",
    "folder": "",
    "question": "In the heteroscedastic hierarchical model, the SURE estimates are shown to be superior to EBMLE and EBMOM in terms of the averaged squared loss under both parametric and semiparametric settings. This superiority is particularly evident when the data exhibit [BLANK], a scenario not uncommon in practical applications such as gene expression data from microarray studies.",
    "gold_answer": "heteroscedasticity and correlation between components. The SURE estimator's ability to account for unequal variances and dependencies among data components makes it particularly effective in complex data structures, outperforming other estimators that may not fully capture these aspects.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "heteroscedasticity and correlation between components",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"heteroscedasticity\"\n}",
      "model_answer": "heteroscedasticity",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2008",
    "folder": "",
    "question": "In the estimation of population parameters from capture-recapture data, the ratio method of maximizing the likelihood function involves equating L(Î¸) to [BLANK].",
    "gold_answer": "L(Î¸-1). This approach, used by Darroch (1958), involves setting the difference in log likelihoods to zero to find maximum likelihood estimates.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "L(Î¸-1)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"zero\"\n}",
      "model_answer": "zero",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-587",
    "folder": "",
    "question": "The (mean-zero) EG density for a point $\\pmb{x}\\in\\mathbb{R}^{q}$ is given by $$ p_{\\mathrm{eg}}(\\pmb{x};\\pmb{\\Sigma},a,b):=\\frac{\\Gamma(q/2)}{\\pi^{q/2}\\Gamma(a)b^{a}|\\pmb{\\Sigma}|^{1/2}}\\big(\\pmb{x}^{\\top}\\pmb{\\Sigma}^{-1}\\pmb{x}\\big)^{a-q/2}\\exp\\bigl(-b^{-1}\\pmb{x}^{\\top}\\pmb{\\Sigma}^{-1}\\pmb{x}\\bigr), $$ where $\\Sigma\\succ0$ is the scatter matrix, and $a,b>0$ are scale and shape parameters. The EG density generalizes the Gaussian density, which corresponds to $a=[BLANK]$. What value of $a$ makes the EG density equivalent to the Gaussian density?",
    "gold_answer": "$a=q/2$. This is the value at which the additional elliptical factor $(\\pmb{x}^{\\top}\\pmb{\\Sigma}^{-1}\\pmb{x})^{a-q/2}$ becomes 1, simplifying the EG density to the Gaussian density.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2016\\ScienceDirect_articles_03Mar2025_09-01-58.435\\Inference-and-mixture-modeling-with-the-Ellip_2016\\Inference-and-mixture-modeling-with-the-Ellip_2016.md",
      "Inference-and-mixture-modeling-with-the-Ellip_2016.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$a=q/2$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"q/2\"\n}",
      "model_answer": "q/2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1890",
    "folder": "",
    "question": "In the dependent BINAR(1) model, the conditional pgf is exponentially affine in Â±bX_{t-1}. Such a process is called [BLANK].",
    "gold_answer": "compound autoregressive (CaR). This term is used to describe processes where the conditional probability generating function (pgf) is exponentially affine in the past values of the process, highlighting the model's structure and properties.",
    "source": [
      "Bivariate-integer-autoregressive-process-with-an-a.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2019\\ScienceDirect_articles_28Feb2025_08-39-25.663\\Bivariate-integer-autoregressive-process-with-an-a\\Bivariate-integer-autoregressive-process-with-an-a.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "compound autoregressive (CaR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"self-exciting\"\n}",
      "model_answer": "self-exciting",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2246",
    "folder": "",
    "question": "In the context of analyzing cross-classified survey data, the adjusted Pearson XÂ² statistic is divided by [BLANK] to reduce the error in the level of tests, where v is the appropriate degrees of freedom. What is the term used to describe this adjustment?",
    "gold_answer": "E(XÂ²)/v. This term is crucial for the one moment adjustment of the XÂ² statistic, ensuring the test's level is more accurately aligned with the nominal level by accounting for the survey design's effect.",
    "source": [
      "Adjusted_chi-squared_tests_for_cross-classified_tables_of_survey_data.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_70_Issue_3\\Adjusted_chi-squared_tests_for_cross-classified_tables_of_survey_data\\Adjusted_chi-squared_tests_for_cross-classified_tables_of_survey_data.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "E(XÂ²)/v",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"v\"\n}",
      "model_answer": "v",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3074",
    "folder": "",
    "question": "The MADD dissimilarity index uses a scaling factor of [BLANK] to account for the increase in interpoint distances with dimensionality.",
    "gold_answer": "1/âˆšp. This scaling adjusts for the fact that distances in high-dimensional spaces grow at a rate proportional to the square root of the dimensionality.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1/âˆšp",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1/sqrt(p)\"\n}",
      "model_answer": "1/sqrt(p)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-293",
    "folder": "",
    "question": "In the context of nonparametric estimation of a periodic function, the convergence rate of the estimator of periods is given as [BLANK], where n denotes the number of observations made.",
    "gold_answer": "$O(n^{-3/2})$. This rate indicates that the estimator of periods converges at a parametric rate, which is faster than typical nonparametric rates, highlighting the efficiency of the method in estimating the period of a periodic function from noisy observations.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_87_Issue_3\\Nonparametric_estimation_of_a_periodic_function\\Nonparametric_estimation_of_a_periodic_function.md",
      "Nonparametric_estimation_of_a_periodic_function.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$O(n^{-3/2})$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"n^(-1)\"\n}",
      "model_answer": "n^(-1)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-868",
    "folder": "",
    "question": "The proof of $L^{2}$ consistency for the kth nearest neighbour distance estimator of the Shannon entropy for an arbitrary fixed $k\\geq1$ is provided. It is constructed the nonparametric test of goodness-of-fit for a class of introduced generalised multivariate Gaussian distributions based on a [BLANK] principle. The theoretical results are followed by numerical studies on simulated samples.",
    "gold_answer": "maximum entropy. This principle is crucial for constructing the test as it underpins the theoretical foundation for analyzing the goodness-of-fit for generalised multivariate Gaussian distributions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2022\\ScienceDirect_articles_03Mar2025_08-48-34.109\\Entropy-based-test-for-generalised-Gaussia_2022_Co\\Entropy-based-test-for-generalised-Gaussia_2022_Co.md",
      "Entropy-based-test-for-generalised-Gaussia_2022_Co.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "maximum entropy",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"likelihood ratio\"\n}",
      "model_answer": "likelihood ratio",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1116",
    "folder": "",
    "question": "The method is designed to answer questions arising in biophysical research on nanoclusters of Ras proteins. It takes into account the presence of disturbing metacluster structures as well as non-clustering objects, both common among Ras clusters. Its focus lies on estimating the proportion of points lying in clusters, the mean cluster size and the mean cluster radius without depending on prior knowledge of the [BLANK].",
    "gold_answer": "parameters. The method does not require prior knowledge of the parameters, making it versatile for various applications.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "parameters",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"metacluster structure\"\n}",
      "model_answer": "metacluster structure",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3607",
    "folder": "",
    "question": "In the evaluation of determinants for a class of patterned matrices, the determinant of a matrix $M = [D_{a_{i}} + \\alpha\\mathbf{b}\\mathbf{b}^{\\prime}]$ can be expressed as $\\Delta = \\left(1 + \\alpha\\sum_{i=1}^{n}\\frac{b_{i}^{2}}{a_{i}}\\right)\\prod_{i=1}^{n}a_{i}$. What critical element is missing from this formula?",
    "gold_answer": "The missing element is the condition that $a_{i} \\neq 0$ for all $i$. This condition is crucial because division by zero is undefined, and the formula assumes that all $a_{i}$ are non-zero to allow for the summation term.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The missing element is the condition that $a_{i} \\neq 0$ for all $i$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"D_{a_{i}} = diag(a_{i})\"\n}",
      "model_answer": "D_{a_{i}} = diag(a_{i})",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2954",
    "folder": "",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yáµ¢â±¼ can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where Î±áµ£ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "báµ¢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [
      "Composite_Likelihood_Inference_in_a_Discrete_Latent_Variable_Model_for_Two-Way_â€œClustering-by-Segmentationâ€_Problems__Composite_Likelihood_Inference_in_a_Discrete_Latent_Variable_Model_for_Two-Way__Clustering-by-Segmentation__Problems.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_26\\Issue_2\\Composite_Likelihood_Inference_in_a_Discrete_Latent_Variable_Model_for_Two-Way_â€œClustering-by-Segmentationâ€_Problems__Composite_Likelihood_Inference_in_a_Discrete_Latent_Variable_Model_for_Two-Way__Clustering-by-Segmentation__Problems\\Composite_Likelihood_Inference_in_a_Discrete_Latent_Variable_Model_for_Two-Way_â€œClustering-by-Segmentationâ€_Problems__Composite_Likelihood_Inference_in_a_Discrete_Latent_Variable_Model_for_Two-Way__Clustering-by-Segmentation__Problems.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-615",
    "folder": "",
    "question": "The pair correlation function of a log Gaussian Cox process is given by g(s) = exp(ÏƒÂ²r(s)), where r(s) is the [BLANK] function of the underlying Gaussian process.",
    "gold_answer": "correlation",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "correlation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"correlation\"\n}",
      "model_answer": "correlation",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-26",
    "folder": "",
    "question": "In the pseudolikelihood approach for nested case-control studies, the likelihood is factorized into a product of the outcome model and the missingness mechanism, expressed as f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK], where Ráµ¢ denotes the missingness indicators. What missingness-related term completes this equation?",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). This term is crucial as it represents the conditional probability of the missingness indicators given the outcomes, highlighting the dependency between missingness and the observed data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-162",
    "folder": "",
    "question": "In the context of biplots, the approximation of the data matrix Y by AB^T is given by Y â‰ƒ AB^T, where A and B are matrices of markers for the rows and columns of Y, respectively. The goodness of fit for this approximation is measured by the coefficient GF(Y, AB^T) = [BLANK]. What is the correct formula for GF(Y, AB^T)?",
    "gold_answer": "GF(Y, AB^T) = tr^2(Y^T AB^T) / {tr(Y^T Y) tr(B A^T A B^T)}. This formula measures the proportional goodness of fit of the biplot approximation to the data matrix Y, emphasizing the importance of the trace operations in assessing the fit.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_89_Issue_2\\Goodness_of_fit_of_biplots_and_correspondence_analysis\\Goodness_of_fit_of_biplots_and_correspondence_analysis.md",
      "Goodness_of_fit_of_biplots_and_correspondence_analysis.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "GF(Y, AB^T) = tr^2(Y^T AB^T) / {tr(Y^T Y) tr(B A^T A B^T)}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"tr(YB^TA^T)/(tr(YY^T)tr(BB^T)tr(AA^T))^(1/2)\"\n}",
      "model_answer": "tr(YB^TA^T)/(tr(YY^T)tr(BB^T)tr(AA^T))^(1/2)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-450",
    "folder": "",
    "question": "In the additive non-parametric logistic regression model described, the form is given as logit $[P(\\mathbf{x})]=\\alpha+$ $\\Sigma f_{j}(x_{j})$, where $P(\\mathbf{x})=P(y=1\\mid\\mathbf{x})$ for a 0-1 variable $y$, and $\\textbf{x}$ is a vector of $p$ covariates. The functions $f_{j}$ can be chosen to be linear, general non-linear, or step functions for discrete covariates. The functions are estimated simultaneously using the [BLANK] algorithm.",
    "gold_answer": "local scoring. This algorithm is a generalization of the iteratively reweighted least squares algorithm (IRLS) for estimating the parameters in generalized linear models, adapted for non-parametric function estimation.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_36_Issue_3\\Non-Parametric Logistic and Proportional Odds Regr\\Non-Parametric Logistic and Proportional Odds Regr.md",
      "Non-Parametric Logistic and Proportional Odds Regr.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "local scoring",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"backfitting\"\n}",
      "model_answer": "backfitting",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3601",
    "folder": "",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). We remove it from the question because it represents the core assumption that simplifies inference: once we condition on the observed responses, the missingness no longer depends on the unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1731",
    "folder": "",
    "question": "In the Levinson-Durbin algorithm for the pure autoregressive case, the coefficient Î±â‚š,â‚€(p) can be interpreted as minus the partial correlation of y(0) and y(-p) holding y(-1),...,y(-p+1) fixed. For the general autoregressive-moving average case, a similar representation of Î±â‚š,áµ©(p) and Î³â‚š,áµ©(p) is given, along with a simple relation between them which can replace the computationally expensive relation (2.7). This relation is given by Î³â‚š,áµ©(p) = [BLANK].",
    "gold_answer": "Î±â‚š,áµ©â‚‹â‚(p) (vâ‚šâ‚‹â‚,áµ© / Ïƒâ‚šâ‚‹â‚,áµ©) Ïƒâ‚šâ‚‹â‚,áµ©â‚‹â‚ vâ‚šâ‚‹â‚,áµ©â‚‹â‚ (Ïƒâ‚šâ‚‹â‚,áµ©â‚‹â‚Â² - ÏƒÂ²)â»Â¹. This relation simplifies the computation by relating Î³â‚š,áµ©(p) to previously computed values, avoiding the need for more complex calculations.",
    "source": [
      "A_Levinson-Durbin_recursion_for_autoregressive-moving_average_processes.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_72_Issue_3\\A_Levinson-Durbin_recursion_for_autoregressive-moving_average_processes\\A_Levinson-Durbin_recursion_for_autoregressive-moving_average_processes.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î±â‚š,áµ©â‚‹â‚(p) (vâ‚šâ‚‹â‚,áµ© / Ïƒâ‚šâ‚‹â‚,áµ©) Ïƒâ‚šâ‚‹â‚,áµ©â‚‹â‚ vâ‚šâ‚‹â‚,áµ©â‚‹â‚ (Ïƒâ‚šâ‚‹â‚,áµ©â‚‹â‚Â² - ÏƒÂ²)â»Â¹",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"-Î±â‚š,áµ©(p)\"\n}",
      "model_answer": "-Î±â‚š,áµ©(p)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1219",
    "folder": "",
    "question": "In the context of Data-Generating Experiments (DGEs), the Empirical Discrimination Index (EDI) is introduced to confirm almost surely discrimination of Î¸ from Î¸*, that is, FÎ¸ â‰  FÎ¸*, and to confirm identifiability of Î¸ âˆˆ Î˜ by repeating this for Î¸* in a fine sieve of Î˜. The EDI is based on properties of the Expected p-value for the [BLANK] test.",
    "gold_answer": "Kolmogorov-Smirnov. The EDI utilizes the Expected p-value from the Kolmogorov-Smirnov test to assess the discrimination between Î¸ and Î¸* by evaluating the distance between their respective cumulative distribution functions, FÎ¸ and FÎ¸*.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_33\\Issue_1\\EDI-Graphic__A_Tool_To_Study_Parameter_Discrimination_and_Confirm_Identifiability_in_Black-Box_Models__and_to_Select_Data-Generating_Machines\\EDI-Graphic__A_Tool_To_Study_Parameter_Discrimination_and_Confirm_Identifiability_in_Black-Box_Models__and_to_Select_Data-Generating_Machines.md",
      "EDI-Graphic__A_Tool_To_Study_Parameter_Discrimination_and_Confirm_Identifiability_in_Black-Box_Models__and_to_Select_Data-Generating_Machines.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Kolmogorov-Smirnov",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Kolmogorov-Smirnov\"\n}",
      "model_answer": "Kolmogorov-Smirnov",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1333",
    "folder": "",
    "question": "In the construction of the extensively corrected score, the first step involves [BLANK], which is crucial for generating independent replicates of the surrogate measurements.",
    "gold_answer": "duplicating. This step allows for the creation of multiple independent replicates of the surrogate measurements, enabling the subsequent steps of weighing, correcting, and averaging to construct an unbiased estimating function.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "duplicating",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"randomly splitting the data\"\n}",
      "model_answer": "randomly splitting the data",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-693",
    "folder": "",
    "question": "In the context of stochastic differential equations driven by fractional Brownian motion, the Skorokhod integral with respect to the fractional Brownian motion is not computable when the Hurst index H is not equal to [BLANK].",
    "gold_answer": "1/2. This is because the Skorokhod integral coincides with ItÃ´â€™s integral only when H = 1/2, making it computable in that specific case.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2025_Volume_52_Issue_1\\Scandinavian J Statistics - 2024 - Marie - On a co\\Scandinavian J Statistics - 2024 - Marie - On a co.md",
      "Scandinavian J Statistics - 2024 - Marie - On a co.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1/2",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1/2\"\n}",
      "model_answer": "1/2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2965",
    "folder": "",
    "question": "For estimating the parameters of the CAViaR models, an algorithm similar to the one proposed in the original paper is applied. A grid search is conducted by generating a large number of random vectors, the dimensions of which correspond to the number of model parameters. The five vectors which lead to the lowest values of the objective function (2.3) are selected and fed into a simplex optimization algorithm. The final parameter vector is chosen to be the one minimizing (2.3). Our new AR-TGARCH specification fits into this procedure. The objective function used in this context is [BLANK], where p denotes the probability level of the quantile being estimated, I(Â·) is the indicator function, and VaR_p^t(Î²) is the Value at Risk estimate at time t for probability level p.",
    "gold_answer": "min_Î² (1/n) sum_{t=1}^n [p - I(Y_t < -VaR_p^t(Î²))] (Y_t + VaR_p^t(Î²)). This objective function is crucial for estimating the parameters of CAViaR models, as it directly relates to the quantile regression framework, emphasizing the model's focus on accurately capturing the tail behavior of financial return distributions.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "min_Î² (1/n) sum_{t=1}^n [p - I(Y_t < -VaR_p^t(Î²))] (Y_t + VaR_p^t(Î²))",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"âˆ‘(t=1 to T)[p - I(r_t < -VaR_p^t(Î²))][-VaR_p^t(Î²)]\"\n}",
      "model_answer": "âˆ‘(t=1 to T)[p - I(r_t < -VaR_p^t(Î²))][-VaR_p^t(Î²)]",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1304",
    "folder": "",
    "question": "In the context of bias correction for estimators defined by an unbiased linear estimating equation, the new formula for the exact bias is expressed as a [BLANK]. What term describes the nature of this sequence?",
    "gold_answer": "convergent sequence. This term is used to describe the sequence because it approaches a specific limit as the number of terms increases, ensuring the formula's accuracy and computational feasibility.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_85_Issue_1\\From_unbiased_linear_estimating_equations_to_unbiased_estimators\\From_unbiased_linear_estimating_equations_to_unbiased_estimators.md",
      "From_unbiased_linear_estimating_equations_to_unbiased_estimators.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "convergent sequence",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"power series\"\n}",
      "model_answer": "power series",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-897",
    "folder": "",
    "question": "In the context of two-dimensional Functional Time Series, the prediction band for a future observation Y_{T+1} is defined as {y âˆˆ H: y(u, v) âˆˆ [g_{I_1}(u, v; X_{T+1}) Â± k^s s_{I_1}(u, v)] âˆ€(u, v) âˆˆ [c, d] Ã— [e, f]}, where g_{I_1} is a point predictor built from the training set I_1, and s_{I_1} is a [BLANK]. What term completes the definition of the prediction band?",
    "gold_answer": "modulation function. The modulation function s_{I_1} allows for prediction bands with non-constant width along the domain, adjusting the band's width based on the variability of the data in different parts of the domain.",
    "source": [
      "Conformal-prediction-bands-for-two-dimensiona_2023.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2023\\ScienceDirect_articles_03Mar2025_08-45-55.513\\Conformal-prediction-bands-for-two-dimensiona_2023\\Conformal-prediction-bands-for-two-dimensiona_2023.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "modulation function",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"standard deviation estimator\"\n}",
      "model_answer": "standard deviation estimator",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2833",
    "folder": "",
    "question": "The concept of substationarity is particularly useful in analyzing spatial point processes where the distribution is invariant under shifts in a subspace but may vary outside it, providing a bridge between [BLANK] and nonstationarity.",
    "gold_answer": "stationarity. This omission underscores substationarity's role in connecting the well-known concepts of stationarity and nonstationarity in spatial statistics.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "stationarity",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"stationarity\"\n}",
      "model_answer": "stationarity",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2892",
    "folder": "",
    "question": "In the model, the mean expression level Î¼_{g i k} is modeled using a log-linear regression that includes the library size, baseline expression, and the effect size, which is the log-fold change of expression between the two conditions, denoted by [BLANK].",
    "gold_answer": "Î²_{g k}. This parameter captures the effect size or log-fold change in expression for gene g in study k between conditions.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î²_{g k}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î²\"\n}",
      "model_answer": "Î²",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-207",
    "folder": "",
    "question": "The adaptive ABC-MCMC algorithm adjusts the tolerance parameter Î´ to achieve a target acceptance rate Î±âˆ—. The update rule for the log tolerance is given by logÎ´kâ†logÎ´kâˆ’1+Î³k(Î±âˆ—âˆ’Ak), where Ak is the acceptance indicator at iteration k, and [BLANK] is a sequence of decreasing step sizes.",
    "gold_answer": "Î³k. The sequence Î³k controls the rate at which the tolerance parameter Î´ is adjusted, ensuring convergence to the target acceptance rate Î±âˆ—.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î³k",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î³k\"\n}",
      "model_answer": "Î³k",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2852",
    "folder": "",
    "question": "In generalized linear mixed models (GLMMs), the variance of the pseudo-data Y_i* in the linear mixed model approximation is given by Var(Y_i*) â‰ˆ Î”_i Z_i D Z_i' Î”_i' + Î£_i, where Î”_i is [BLANK].",
    "gold_answer": "the diagonal matrix of derivatives âˆ‚Î¼_i/âˆ‚Î·_i evaluated at b_i = 0. This matrix plays a crucial role in the approximation by linking the mean and the linear predictor through the link function.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the diagonal matrix of derivatives âˆ‚Î¼_i/âˆ‚Î·_i evaluated at b_i = 0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the diagonal matrix of derivatives of the link function\"\n}",
      "model_answer": "the diagonal matrix of derivatives of the link function",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2920",
    "folder": "",
    "question": "In the context of polynomial histogram estimators, the first-order polynomial histogram estimator (Fophe) for a multivariate density f is given by gâ‚(x) = aâ‚€ + aáµ€x. The estimator satisfies two integral conditions over each bin Bâ„“. The first condition is âˆ«Bâ„“ gâ‚(x)dx = nâ„“/n. The second condition is âˆ«Bâ„“ x gâ‚(x)dx = [BLANK]. What is the missing term in the second condition?",
    "gold_answer": "nâ„“/n xÌ„â„“. This condition ensures that the estimator captures the local mean within each bin, aligning the polynomial's linear term with the data's average behavior in that region.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "nâ„“/n xÌ„â„“",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nâ„“xÌ„â„“/n\"\n}",
      "model_answer": "nâ„“xÌ„â„“/n",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3341",
    "folder": "",
    "question": "In the functional data analysis model, the observations can be modeled as Yâ‚œ(xâ‚œâ±¼) = Î·â‚œ(xâ‚œâ±¼) + Ïƒâ‚œ(xâ‚œâ±¼)Îµâ‚œâ±¼, where Îµâ‚œâ±¼ are measurement errors with EÎµâ‚œâ±¼ = 0 and EÎµâ‚œâ±¼Â² = 1. The noise variance function is denoted by [BLANK].",
    "gold_answer": "Ïƒâ‚œÂ²(x). This represents the variance function of the measurement error at point x for the t-th observation.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ïƒâ‚œÂ²(x)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ïƒâ‚œÂ²(xâ‚œâ±¼)\"\n}",
      "model_answer": "Ïƒâ‚œÂ²(xâ‚œâ±¼)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1993",
    "folder": "",
    "question": "In the method based on gamma distribution for constructing confidence intervals, the upper confidence limit is adjusted by a factor denoted as [BLANK], which can vary based on the approach taken.",
    "gold_answer": "w*. This factor is critical in determining the conservativeness of the confidence intervals constructed under the gamma distribution method.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "w*",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"k\"\n}",
      "model_answer": "k",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1821",
    "folder": "",
    "question": "An indirect estimation approach for elliptical stable distributions is presented. The auxiliary model is another elliptical distribution, the [BLANK] distribution. It has parameters that have a one-to-one relationship with those of the elliptical stable, making the proposed indirect approach particularly suitable.",
    "gold_answer": "multivariate Student-t. This choice is highlighted because the parameters of the multivariate Student-t distribution have a direct, one-to-one relationship with those of the elliptical stable distributions, facilitating the indirect estimation process.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2009\\ScienceDirect_articles_04Mar2025_14-36-07.278\\Indirect-estimation-of-elliptical-stable-_2009_Com\\Indirect-estimation-of-elliptical-stable-_2009_Com.md",
      "Indirect-estimation-of-elliptical-stable-_2009_Com.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "multivariate Student-t",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Student's t\"\n}",
      "model_answer": "Student's t",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1227",
    "folder": "",
    "question": "The Hidden Mixture Transition Distribution (HMTD) model integrates refinements of the mixture model and the hidden Markov model, allowing the observed heterogeneity to be induced by one or several [BLANK].",
    "gold_answer": "latent factors. This answer highlights the core aspect of the HMTD model, which is its ability to model observed heterogeneity through underlying, unobserved factors.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "latent factors",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"latent variables\"\n}",
      "model_answer": "latent variables",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1843",
    "folder": "",
    "question": "The total force of decrement in a multiple decrement table, denoted as Î¼â‚“â½áµ—â¾, is the sum of the forces of decrement for all causes, expressed as Î¼â‚“â½áµ—â¾ = [BLANK].",
    "gold_answer": "Î£ Î¼â‚“â½Ê²â¾(t) over all causes j. This summation aggregates the instantaneous rates of decrement from all causes to represent the total force of decrement acting on the population.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î£ Î¼â‚“â½Ê²â¾(t) over all causes j",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¼â‚“â‚â‚â‚Ž + Î¼â‚“â‚â‚‚â‚Ž + ... + Î¼â‚“â‚â‚–â‚Ž\"\n}",
      "model_answer": "Î¼â‚“â‚â‚â‚Ž + Î¼â‚“â‚â‚‚â‚Ž + ... + Î¼â‚“â‚â‚–â‚Ž",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2016",
    "folder": "",
    "question": "The null hypothesis H that Ï€_{ijkl}^{ABCD} = Ï€_{ik}^{AC}Ï€_{jl}^{BD} can be expressed in terms of two sub-hypotheses, H_a and H_b, where H_a states that Ï€_{ijk}^{ABC} = Ï€_{ik}^{AC}, and H_b states that Ï€_{ijkl}^{ABCD} = [BLANK].",
    "gold_answer": "Ï€_{jl}^{BD}. This decomposition simplifies the testing of the overall hypothesis H by breaking it down into more manageable parts.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï€_{jl}^{BD}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï€_{ijk}^{ABC}Ï€_{l}^{D}\"\n}",
      "model_answer": "Ï€_{ijk}^{ABC}Ï€_{l}^{D}",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2321",
    "folder": "",
    "question": "In the Gamma-frailty proportional hazards model for bivariate interval-censored data, the conditional cumulative hazard function for Tj, given the frailty Î·, is given by Aj(t|x,Î·) = A0j(t)exp(xâ€²Î²j)Î·, for j=1,2. The frailty is assumed to follow a gamma distribution with shape and rate parameters both equal to [BLANK].",
    "gold_answer": "Î½. The frailty parameter Î½ controls the dependence structure between the two failure times, with smaller values indicating stronger dependence.",
    "source": [
      "A-Gamma-frailty-proportional-hazards-model-for-_20.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2018\\ScienceDirect_articles_03Mar2025_08-57-32.179\\A-Gamma-frailty-proportional-hazards-model-for-_20\\A-Gamma-frailty-proportional-hazards-model-for-_20.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î½",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1/Î¸\"\n}",
      "model_answer": "1/Î¸",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3432",
    "folder": "",
    "question": "The basic idea behind testing goodness of fit for continuous distributions is that the distance should be '[BLANK]' when the null hypothesis is true, and '[BLANK]' when the hypothesis is false.",
    "gold_answer": "The basic idea behind testing goodness of fit for continuous distributions is that the distance should be 'small' when the null hypothesis is true, and 'large' when the hypothesis is false. This highlights the fundamental principle that the test statistic's value indicates the degree of agreement between the observed data and the null hypothesis.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_47_Issue_1\\Tailor-Made Tests of Goodness of Fit\\Tailor-Made Tests of Goodness of Fit.md",
      "Tailor-Made Tests of Goodness of Fit.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The basic idea behind testing goodness of fit for continuous distributions is that the distance should be 'small' when the null hypothesis is true, and 'large' when the hypothesis is false",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"small, large\"\n}",
      "model_answer": "small, large",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3576",
    "folder": "",
    "question": "An unbiased estimate of the total of a variate $y$ may then be obtained from formula (1) by putting $n$ equal to 2, and replacing $x_{i}$ by $\\nabla_{\\vec{p}}\\prime_{i}$ and $\\Sigma(x)$ by [BLANK].",
    "gold_answer": "1. This omission emphasizes the normalization step in obtaining unbiased estimates by adjusting the size measures.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0\"\n}",
      "model_answer": "0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1691",
    "folder": "",
    "question": "In the construction of a multivariate integer-valued trawl (MIVT) process, the cross-sectional dependence is entirely characterized through the [BLANK]. Which key element is this?",
    "gold_answer": "multivariate LÃ©vy measure Î½. This is because the cross-sectional dependence between the components of the MIVT process is determined by the joint distribution of jumps in the different components, which is specified by the multivariate LÃ©vy measure.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2019\\ScienceDirect_articles_28Feb2025_08-43-46.051\\Modeling--simulation-and-inference-for-multivariat\\Modeling--simulation-and-inference-for-multivariat.md",
      "Modeling--simulation-and-inference-for-multivariat.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "multivariate LÃ©vy measure Î½",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"trawl set\"\n}",
      "model_answer": "trawl set",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1181",
    "folder": "",
    "question": "The null distribution of the maximum likelihood ratio test statistic for two upper outliers in an exponential sample is derived. The test statistic for labelled slippage, introduced by Barnett and Lewis (1978, Ch. 3), identifies the k largest values as the only possible discordant observations. The maximum likelihood ratio test in this case is equivalent to using the test statistic Tâ‚– = (yâ‚™â‚‹â‚–â‚Šâ‚ + yâ‚™â‚‹â‚–â‚Šâ‚‚ + ... + yâ‚™) / Î£áµ¢â‚Œâ‚â¿ yáµ¢, a large value of which supplies evidence against Hâ‚€. For k=2, the null distribution of [BLANK] is obtained, critical values are tabulated and a simple inequality for the probability of wrongly rejecting Hâ‚€ is presented.",
    "gold_answer": "Tâ‚‚. This is the test statistic specifically for testing two upper outliers in an exponential sample, as detailed in the paper.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_30_Issue_2\\The Null Distribution of a Test for Two Upper Outl\\The Null Distribution of a Test for Two Upper Outl.md",
      "The Null Distribution of a Test for Two Upper Outl.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Tâ‚‚",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Tâ‚‚\"\n}",
      "model_answer": "Tâ‚‚",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-656",
    "folder": "",
    "question": "One of the sample allocation methods mentioned is the [BLANK] allocation, where each stratum sample size is the same.",
    "gold_answer": "equal",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "equal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"equal\"\n}",
      "model_answer": "equal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2601",
    "folder": "",
    "question": "The self-controlled case series model is derived from an underlying [BLANK] model.",
    "gold_answer": "Poisson cohort. This is the foundational model from which the self-controlled case series method is developed, assuming events arise as a non-homogeneous Poisson process.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Poisson cohort",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Poisson\"\n}",
      "model_answer": "Poisson",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1148",
    "folder": "",
    "question": "The controlled direct effect (CDE), the natural direct effect (NDE), and the natural indirect effect (NIE) are defined in the context of causal mediation analysis. For a treatment level x* and a control level x of treatment X, the natural direct effect is defined as E(Yx*Mx - YxMx). The key condition required to identify the natural direct and indirect effects, besides randomization of treatment X, is [BLANK].",
    "gold_answer": "Yx'm âŠ¥âŠ¥ Mx | (X=x, U) for all x, x', and m. This condition, known as the sequential ignorability assumption, ensures that the mediator's effect on the outcome is not confounded by unobserved variables conditional on the treatment and observed covariates.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Yx'm âŠ¥âŠ¥ Mx | (X=x, U) for all x, x', and m",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sequential ignorability\"\n}",
      "model_answer": "sequential ignorability",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1926",
    "folder": "",
    "question": "The marginal distributions in the proposed model are modeled through semiparametric transformation models using [BLANK], with the proportional hazards or odds model being a special case.",
    "gold_answer": "sieves. This emphasizes the use of sieves for approximating the infinite-dimensional nuisance parameters in the marginal models, allowing for flexible modeling beyond the proportional hazards or odds models.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "sieves",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"monotone splines\"\n}",
      "model_answer": "monotone splines",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-272",
    "folder": "",
    "question": "The incomplete beta function can be expressed as a contour integral, and its inverse can be represented by a quickly converging series. The equation for solving the incomplete beta function is given by $I_{x}(p,q)=\\frac{\\displaystyle{\\int_{0}^{x}t^{p-1}(1-t)^{q-1}d t}}{\\displaystyle{\\int_{0}^{1}t^{p-1}(1-t)^{q-1}d t}}=P$. To find either $\\pmb{\\mathcal{P}}$ or ${\\pmb x}$, the result is found in terms of percentage points of the [BLANK] distribution.",
    "gold_answer": "$x^{2}$ (chi-squared). This is omitted to highlight the distribution used to find the percentage points for solving the incomplete beta function equation.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_37_Issue_3-4\\THE_INCOMPLETE_BETA_FUNCTION_AS_A_CONTOUR_INTEGRAL_AND_A_QUICKLY_CONVERGING_SERIES_FOR_ITS_INVERSE\\THE_INCOMPLETE_BETA_FUNCTION_AS_A_CONTOUR_INTEGRAL_AND_A_QUICKLY_CONVERGING_SERIES_FOR_ITS_INVERSE.md",
      "THE_INCOMPLETE_BETA_FUNCTION_AS_A_CONTOUR_INTEGRAL_AND_A_QUICKLY_CONVERGING_SERIES_FOR_ITS_INVERSE.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$x^{2}$ (chi-squared)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"F\"\n}",
      "model_answer": "F",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-59",
    "folder": "",
    "question": "In the study of the inheritance of longevity, the correlation in the duration of life is greater between two brothers or two sisters than between brother and sister, highlighting that inheritance is stronger in members of the same sex. The daughter seems to be more closely related in duration of life to her parents than the son, which is somewhat opposed to the result obtained for [BLANK].",
    "gold_answer": "eye-colour. This opposition is explicable by noting how much more liable the male is to accidental death, thus intensifying the nonselective death-rate in his case.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_1_Issue_1\\ON_THE_INHERITANCE_OF_THE_DURATION_OF_LIFE,_AND_ON_THE_INTENSITY_OF_NATURAL_SELECTION_IN_MAN%2E\\ON_THE_INHERITANCE_OF_THE_DURATION_OF_LIFE,_AND_ON_THE_INTENSITY_OF_NATURAL_SELECTION_IN_MAN..md",
      "ON_THE_INHERITANCE_OF_THE_DURATION_OF_LIFE,_AND_ON_THE_INTENSITY_OF_NATURAL_SELECTION_IN_MAN..md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "eye-colour",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"brothers and sisters\"\n}",
      "model_answer": "brothers and sisters",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2802",
    "folder": "",
    "question": "In the analysis of factorial experiments where the effects of one factor are assumed to be proportional at different levels of another factor, the expected effect of the combination of level i of factor A with level j of factor B can be expressed in the form [BLANK]. Which formula correctly represents this expected effect?",
    "gold_answer": "a_i c_j + b_j. This formula captures the proportional effect of factor A at different levels of factor B, where a_i represents the effect of level i of factor A, c_j are the weights for factor B levels, and b_j represents the effect of level j of factor B.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_39_Issue_1-2\\THE_INTERPRETATION_OF_INTERACTIONS_IN_FACTORIAL_EXPERIMENTS\\THE_INTERPRETATION_OF_INTERACTIONS_IN_FACTORIAL_EXPERIMENTS.md",
      "THE_INTERPRETATION_OF_INTERACTIONS_IN_FACTORIAL_EXPERIMENTS.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "a_i c_j + b_j",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¼ + Î±áµ¢ + Î²â±¼ + Î³Î±áµ¢Î²â±¼\"\n}",
      "model_answer": "Î¼ + Î±áµ¢ + Î²â±¼ + Î³Î±áµ¢Î²â±¼",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2966",
    "folder": "",
    "question": "In the application of nonparametric quantile regression with refinements from extreme value theory for VaR prediction, the peaks over threshold (POT) method is incorporated and applied to the standardized nonparametric quantile residuals. This results in an estimator that combines nonparametric quantile regression and extreme value theory (EVT). The POT method approximates large observations that exceed a high threshold reasonably well by the Generalized Pareto Distribution (GPD) with distribution function G_Î¾,Î²(x). The shape parameter Î¾ and scale parameter Î² > 0 of the GPD can be consistently estimated if the threshold exceedances are independent, regardless of the true underlying distribution. The support of the GPD is x â‰¥ 0 when Î¾ â‰¥ 0 and 0 â‰¤ x â‰¤ -Î²/Î¾ if Î¾ < 0. The GPD is used to model the tail behavior of the distribution beyond a certain threshold, u, and the probability of a random variable Y exceeding u at most by x is given by [BLANK], where F is the distribution function of Y.",
    "gold_answer": "F_u(x) = P[Y - u â‰¤ x | Y > u] = [F(x + u) - F(u)] / [1 - F(u)]. This equation is fundamental in extreme value theory for modeling exceedances over a threshold, allowing for the estimation of tail behavior and the calculation of extreme quantiles, which are essential for accurate VaR prediction.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "F_u(x) = P[Y - u â‰¤ x | Y > u] = [F(x + u) - F(u)] / [1 - F(u)]",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(Y â‰¤ u + x|Y > u) = G_Î¾,Î²(x)\"\n}",
      "model_answer": "P(Y â‰¤ u + x|Y > u) = G_Î¾,Î²(x)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3261",
    "folder": "",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the validity of likelihood-based or multiple-imputation methods without explicitly modeling the dropout process.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-133",
    "folder": "",
    "question": "In the context of the Johnson system of probability distributions, the variable x has an S_B distribution if z = Î· + Î´ sinhâ»Â¹((x - Î¾)/Î»), where z is a unit normal variable. The parameters Î·, Î´, Î¾, and Î» are to be determined from the first four moments of an observed distribution. For distributions not too far from normality, the problem reduces to determining Ï‰ and Î© from given values of Î²â‚ and Î³â‚‚, where Ï‰ = e^(1/Î´Â²) and Î© = Î·/Î´. If the distribution is symmetrical about the origin, then Î²â‚ = 0, implying Î© = 0, and Î³â‚‚ can be expressed in terms of Ï‰ as Î³â‚‚ = (1/8)(Ï‰â´ - 1)(Ï‰â´ + 3). Solving for Ï‰ gives Ï‰ = {âˆš(4 + 2Î³â‚‚) - 1}^(1/2) = {âˆš(2Î²â‚‚ - 2) - 1}^(1/2). What is the value of Ï‰ when Î³â‚‚ = 0?",
    "gold_answer": "1. When Î³â‚‚ = 0, Ï‰ = {âˆš(4 + 2*0) - 1}^(1/2) = {âˆš4 - 1}^(1/2) = {2 - 1}^(1/2) = 1^(1/2) = 1. This indicates that the distribution is normal when Î³â‚‚ = 0, as Ï‰ = 1 corresponds to Î´ approaching infinity, making the transformation linear and thus the distribution normal.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_46_Issue_1-2\\The_generalized_mean_differences_of_the_binomial_and_Poisson_distributions\\The_generalized_mean_differences_of_the_binomial_and_Poisson_distributions.md",
      "The_generalized_mean_differences_of_the_binomial_and_Poisson_distributions.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2454",
    "folder": "",
    "question": "In the context of nonlinear prediction theory, the functional $F(f) = N_{\\phi}(f_0 - f)$ assumes its minimum exactly once on a set $C$ whenever $C$ is sequentially complete in the topology of $\\sigma(L^{\\phi}(\\mathcal{X}), \\mathcal{M}^{\\psi}(\\mathcal{X}^{*}))$. This uniqueness is guaranteed by the property of $L^{\\Phi}(\\Sigma, \\mathcal{X})$ being [BLANK].",
    "gold_answer": "rotund. This property ensures that the functional $F(\\cdot)$ on $C$ has a unique minimum, highlighting the importance of the space's strict convexity in guaranteeing uniqueness in optimization problems.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "rotund",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"strictly convex\"\n}",
      "model_answer": "strictly convex",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-373",
    "folder": "",
    "question": "In the model where the probability differential of a service completion is Î¼Ïƒâ‚™ dt when the queue contains n, and arrivals occur in a Poisson stream with parameter Î», the equivalent traffic intensity for the system Ïƒâ‚™ = n + 1 is given by [BLANK].",
    "gold_answer": "1 - e^(-Ï). This is derived from the mean length of a steady-state service interval being Î»â»Â¹(1 - e^(-Ï)), where Ï = Î»/Î¼.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1 - e^(-Ï)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï/(n + 1)\"\n}",
      "model_answer": "Ï/(n + 1)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2034",
    "folder": "",
    "question": "The practice of interring artifacts with the body had died out by the [BLANK] century, making graveyards of that period of little interest to archaeologists.",
    "gold_answer": "10th and 11th",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "10th and 11th",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nineteenth\"\n}",
      "model_answer": "nineteenth",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1696",
    "folder": "",
    "question": "The proposed Bayesian model stands on a two-level hierarchy where at the instance level, latent indicator variables are assigned to individual instances, each indicating whether the corresponding instance is responsible for the response of the bag it belongs to. These latent indicators are modeled through a [BLANK] regression model.",
    "gold_answer": "logistic. This model is used to explain the relationship between the explanatory variables of instances and their binary latent variables, indicating the probability of an instance being responsible for the bag's response.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "logistic",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"probit\"\n}",
      "model_answer": "probit",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1297",
    "folder": "",
    "question": "In the context of testing for equality of mean ranks between two groups, the proposed statistic is defined as [BLANK]. What is the correct term to fill in the blank?",
    "gold_answer": "â„“=Î£(kâ‚âˆ’lâ‚)Â². This statistic is used to compare the mean ranks between two groups, highlighting the differences in their rankings.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "â„“=Î£(kâ‚âˆ’lâ‚)Â²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"G\"\n}",
      "model_answer": "G",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2848",
    "folder": "",
    "question": "In additive fuzzy clustering, the $n\\times K$ fuzzy memberships matrix $\\mathbf{P}$ is found by least-squares approximation of the off-diagonal elements of $\\mathbf{\\deltaQ}$ by inner products of rows of P. By contrast, kernelized fuzzy c-means is not least-squares and requires an additional [BLANK]. What is the additional requirement for kernelized fuzzy c-means?",
    "gold_answer": "fuzziness parameter. This parameter governs the degree of fuzziness in the clustering, distinguishing it from the least-squares approach of additive fuzzy clustering.",
    "source": [
      "Approximating-a-similarity-matrix-by-a-latent-clas.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2009\\ScienceDirect_articles_04Mar2025_14-35-09.749\\Approximating-a-similarity-matrix-by-a-latent-clas\\Approximating-a-similarity-matrix-by-a-latent-clas.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "fuzziness parameter",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"normalization constraint\"\n}",
      "model_answer": "normalization constraint",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2584",
    "folder": "",
    "question": "In the context of functional data analysis, the problem of feature selection is addressed by identifying a small subset of functions that can 'better explain' the model. The aim is to highlight the most important features by focusing on a statistical method such as classification, regression, or [BLANK].",
    "gold_answer": "principal components. This is omitted to emphasize the variety of statistical methods that can be applied to functional data analysis, with principal components being a key method for dimensionality reduction and feature extraction.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2016\\ScienceDirect_articles_28Feb2025_08-54-00.030\\Feature-selection-for-functional-data_2016_Journal\\Feature-selection-for-functional-data_2016_Journal.md",
      "Feature-selection-for-functional-data_2016_Journal.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "principal components",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"clustering\"\n}",
      "model_answer": "clustering",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2318",
    "folder": "",
    "question": "A key assumption in the smooth function model is that the parameter of interest $\\theta$ and its estimator $\\hat{\\theta}$ can be expressed as $\\theta = g(\\mu)$ and $\\hat{\\theta} = g(\\overline{X})$, where $\\mu$ is the mean of the distribution $F$ and $\\overline{X}$ is the sample mean. The function $g$ is assumed to be [BLANK] in an open neighbourhood of $\\mu$.",
    "gold_answer": "continuously differentiable up to a sufficiently high order. This ensures the applicability of the smooth function model by guaranteeing the necessary smoothness conditions for the function $g$.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "continuously differentiable up to a sufficiently high order",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"differentiable\"\n}",
      "model_answer": "differentiable",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1886",
    "folder": "",
    "question": "The algorithm computes a distribution-free confidence interval for the median in a one-sample problem, the median difference in a paired sample problem, the difference in the location parameters (shift parameter) in a two-sample problem, and the ratio of the [BLANK] in a two-sample problem.",
    "gold_answer": "scale parameters. This is omitted to highlight the algorithm's capability to handle not just location but also scale differences between two samples, broadening its applicability in statistical analysis.",
    "source": [
      "Distribution-Free Confidence Intervals.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_25_Issue_3\\Distribution-Free Confidence Intervals\\Distribution-Free Confidence Intervals.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "scale parameters",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"scale parameters\"\n}",
      "model_answer": "scale parameters",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1058",
    "folder": "",
    "question": "In the context of outlier detection in networks with missing links, the proposed algorithm is designed to detect outliers and simultaneously predict missing links under the assumption that the matrix of connection probabilities can be decomposed into a low-rank component and a column-wise sparse component. The low-rank component represents the connectivity pattern of inliers, while the column-wise sparse component corresponds to outliers. The key assumption regarding the outliers is that their number is small compared to the size of the network, which is formalized by stating that the matrix representing the outliers is [BLANK]. What term describes the sparsity condition of the outlier matrix?",
    "gold_answer": "column-wise sparse. This term is used to highlight that the matrix representing the outliers has a small number of non-zero columns, indicating that only a few nodes (the outliers) have anomalous connection patterns compared to the majority of nodes (the inliers).",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2021\\ScienceDirect_articles_03Mar2025_08-50-05.737\\Outlier-detection-in-networks-with-miss_2021_Compu\\Outlier-detection-in-networks-with-miss_2021_Compu.md",
      "Outlier-detection-in-networks-with-miss_2021_Compu.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "column-wise sparse",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"column-wise sparse\"\n}",
      "model_answer": "column-wise sparse",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2142",
    "folder": "",
    "question": "The singular value decomposition (SVD) of the data matrix Y is used in factor analysis to obtain estimates of the factors and loadings by minimizing the [BLANK].",
    "gold_answer": "reconstruction error. The SVD decomposes Y into components that capture the most significant patterns or variations in the data, providing a low-rank approximation that minimizes the difference between the original data and the model's reconstruction.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "reconstruction error",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sum of squared residuals\"\n}",
      "model_answer": "sum of squared residuals",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1916",
    "folder": "",
    "question": "In the Gaussian process accelerated failure time model, the log-survival time is modeled as T = ZÎ² + G + Îµ, where G ~ Nn{0, K(X, ÏƒÂ²)} and Îµ ~ Nn{0, ÏƒÎµÂ²In}. The term [BLANK] represents the covariance function based on genome-wide gene expression data.",
    "gold_answer": "K(X, ÏƒÂ²). This term is crucial as it models the covariance structure of the log-survival times based on the similarity of genome-wide gene expression data among patients.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "K(X, ÏƒÂ²)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"K(X, ÏƒÂ²)\"\n}",
      "model_answer": "K(X, ÏƒÂ²)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3516",
    "folder": "",
    "question": "In the context of comparing alternative nested linear models, the global Bayes factor is defined as Bâ‚€â‚ = p(y | Mâ‚€) / p(y | Mâ‚), where p(y | Máµ¢) is the marginal likelihood under model Máµ¢. The global Bayes factor is closely related to the [BLANK] model choice criterion.",
    "gold_answer": "Schwarz. The global Bayes factor is shown to lead, essentially, to the Schwarz-type of criterion, exemplifying its role as a model choice criterion based on posterior probabilities.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Schwarz",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Schwarz\"\n}",
      "model_answer": "Schwarz",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-208",
    "folder": "",
    "question": "In the context of off-policy evaluation in reinforcement learning, the efficiency bound for evaluating natural stochastic policies, such as tilting policies, is inflated compared to the case of a prespecified evaluation policy. This inflation is due to the fact that the evaluation policy itself is [BLANK].",
    "gold_answer": "unknown. This is because natural stochastic policies are defined in terms of deviations from the unknown behaviour policy, making the evaluation policy not prespecified and thus introducing additional uncertainty into the estimation process.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_111_Issue_1\\Efficient_evaluation_of_natural_stochastic_policies_in_off-line_reinforcement_learning\\Efficient_evaluation_of_natural_stochastic_policies_in_off-line_reinforcement_learning.md",
      "Efficient_evaluation_of_natural_stochastic_policies_in_off-line_reinforcement_learning.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "unknown",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"random\"\n}",
      "model_answer": "random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-532",
    "folder": "",
    "question": "The MMC plot can be used with unbalanced, multifactor designs with [BLANK].",
    "gold_answer": "covariates. This is omitted to highlight the versatility of MMC plots in handling complex designs that include covariates, which is a key feature distinguishing them from simpler graphical methods.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_15\\Issue_4\\Meanâ€“Mean_Multiple_Comparison_Displays_for_Families_of_Linear_Contrasts__Mean_Mean_Multiple_Comparison_Displays_for_Families_of_Linear_Contrasts\\Meanâ€“Mean_Multiple_Comparison_Displays_for_Families_of_Linear_Contrasts__Mean_Mean_Multiple_Comparison_Displays_for_Families_of_Linear_Contrasts.md",
      "Meanâ€“Mean_Multiple_Comparison_Displays_for_Families_of_Linear_Contrasts__Mean_Mean_Multiple_Comparison_Displays_for_Families_of_Linear_Contrasts.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "covariates",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"random effects\"\n}",
      "model_answer": "random effects",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-889",
    "folder": "",
    "question": "In the context of tensor regression, the Frobenius norm of a tensor B is defined as [BLANK], which is the square root of the sum of the squares of all its elements.",
    "gold_answer": "âˆš(âˆ‘_{i1,...,id}b_{i1...id}^2). This definition is fundamental for measuring the magnitude of tensors in regression problems, analogous to the Euclidean norm for vectors.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "âˆš(âˆ‘_{i1,",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"||B||_F\"\n}",
      "model_answer": "||B||_F",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-226",
    "folder": "",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK].",
    "gold_answer": "Missing at random (MAR)",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2150",
    "folder": "",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a patternâ€“mixture perspective, where we distinguish subpopulations according to their missingness patterns. If we consider the subpopulation distribution f(Y | pattern), we multiply this by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern (f(pattern))",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the proportion of that missingness pattern (f(pattern))",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(pattern)\"\n}",
      "model_answer": "P(pattern)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1267",
    "folder": "",
    "question": "In probit analysis, the relationship between the level of stimulant and the effect is completely specified by the mean and variance of the [BLANK] distribution of critical levels.",
    "gold_answer": "normal. This is omitted to emphasize the foundational assumption in probit analysis that the critical levels of stimulant among objects follow a normal distribution.",
    "source": [
      "A_NOTE_ON_THE_ANALYSIS_OF_GROUPED_PROBIT_DATA.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_36_Issue_1-2\\A_NOTE_ON_THE_ANALYSIS_OF_GROUPED_PROBIT_DATA\\A_NOTE_ON_THE_ANALYSIS_OF_GROUPED_PROBIT_DATA.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "normal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"normal\"\n}",
      "model_answer": "normal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1748",
    "folder": "",
    "question": "In the simulation study comparing different methods for testing the effect of $X$ conditional on $Z$, the proposed conditional adaptive resampling test is shown to control the sizes reasonably well, except in cases with large $d$ and small $n$. The test based on direct estimation of the asymptotic critical value of the maximum-type statistic $T_{n}$, assuming independence of the noise and the covariates, gives inflated Type I error for the small sample size of $n=100$. This highlights the importance of the [BLANK] approach in small sample settings.",
    "gold_answer": "bootstrap. The bootstrap approach is crucial for accurately estimating the distribution of the test statistic in small samples, where asymptotic approximations may not hold.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "bootstrap",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"resampling\"\n}",
      "model_answer": "resampling",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2499",
    "folder": "",
    "question": "When the pdf $f(\\mathbf{x})$ is non-increasing in $\\left|x_{i}\\right|$ for $i=1,2,...,k$, the sphere of diameter $^d$ centred at the origin has the largest probability content compared to any other region of diameter at most $d$. This implies that a sphere of diameter $^d$ has the largest [BLANK] among the regions of diameter at most $d$.",
    "gold_answer": "volume. This is because the probability content is maximized for the sphere under the given conditions, and when considering the uniform distribution (where the pdf is constant), the probability content directly relates to the volume of the region.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1990\\ScienceDirect_articles_02Mar2025_02-23-45.339\\Region-of-maximum-probability-content-of-fixe_1990\\Region-of-maximum-probability-content-of-fixe_1990.md",
      "Region-of-maximum-probability-content-of-fixe_1990.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "volume",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"concentration probability\"\n}",
      "model_answer": "concentration probability",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3158",
    "folder": "",
    "question": "The algorithm described in the text is designed to compute the exact likelihood function of a stationary autoregressive-moving average (ARMA) process of order $(p,q)$. The equation defining the ARMA $(p,q)$ process is given by $w_{t}=\\phi_{1}w_{t-1}+...+\\phi_{p}w_{t-p}+a_{t}-\\theta_{1}a_{t-1}-...-\\theta_{q}a_{t-q}$, where $a_{t}$ are normally and independently distributed with zero mean and constant variance $\\sigma^{2}$. The likelihood is then given by the expression $(2\\pi)^{-n/2}\\left(\\prod_{\\scriptstyle t=1}^{n}\\sigma_{t}\\right)^{-1}\\exp\\left\\{-\\frac{1}{2}\\sum_{\\scriptstyle t=1}^{n}(\\hat{a}_{t}/\\sigma_{t})^{2}\\right\\}$, where $\\sigma_{t}=h_{t}\\sigma$ is the standard deviation of $\\widehat{\\pmb{a}}_{t}$. Maximizing this likelihood with respect to the parameters included in $\\phi$ and $\\pmb\\theta$ is equivalent to minimizing the sum of squares $\\left(\\prod_{t=1}^{n}h_{t}^{2}\\right)^{1/n}\\sum_{t=1}^{n}\\left(\\frac{\\hat{a}_{t}}{h_{t}}\\right)^{2}$. The maximum likelihood estimate of $\\sigma^{2}$ is then given by [BLANK], evaluated at the optimal parameter point.",
    "gold_answer": "$n^{-1}\\Sigma(\\widehat{a}_{t}/h_{t})^{2}$. This is the formula for the maximum likelihood estimate of the variance $\\sigma^{2}$ of the innovations $a_{t}$, evaluated at the parameter values that minimize the sum of squares.",
    "source": [
      "A Fast Algorithm for the Exact Likelihood of Autor.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_33_Issue_1\\A Fast Algorithm for the Exact Likelihood of Autor\\A Fast Algorithm for the Exact Likelihood of Autor.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$n^{-1}\\Sigma(\\widehat{a}_{t}/h_{t})^{2}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"$\\frac{1}{n}\\left(\\prod_{t=1}^{n}h_{t}^{2}\\right)^{1/n}\\sum_{t=1}^{n}\\left(\\frac{\\hat{a}_{t}}{h_{t}}\\right)^{2}$\"\n}",
      "model_answer": "$\\frac{1}{n}\\left(\\prod_{t=1}^{n}h_{t}^{2}\right)^{1/n}\\sum_{t=1}^{n}\\left(\\frac{\\hat{a}_{t}}{h_{t}}\right)^{2}$",
      "error": "è­¦å‘Š: åŽŸå§‹JSONæ— æ•ˆï¼Œå·²é€šè¿‡json_repairä¿®å¤ã€‚"
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3071",
    "folder": "",
    "question": "The parametric bootstrap is a distribution-free method of assessing sampling variability based on resampling from the empirical distribution; the parametric bootstrap resamples from a fitted [BLANK] model.",
    "gold_answer": "parametric. The blank is filled with 'parametric' to specify that the parametric bootstrap involves resampling from a model that has been fitted to the data, distinguishing it from non-parametric methods that resample directly from the empirical distribution.",
    "source": [
      "Application of the Parametric Bootstrap to Models.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_44_Issue_1\\Application of the Parametric Bootstrap to Models\\Application of the Parametric Bootstrap to Models.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "parametric",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"parametric\"\n}",
      "model_answer": "parametric",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2060",
    "folder": "",
    "question": "In the context of mixing random variables, the empirical distribution function $T_n(t)$ is defined as $T_n(t) = n^{-1}\\sum_{i=1}^{n}u(t-\\xi_i)$, where $u(t) = 1$ if $t \\geq 0$ and $0$ otherwise. The sequence $\\{\\xi_i\\}$ is said to be strong mixing if for all $A \\in M_1^k$ and $B \\in M_{k+n}^\\infty$, $|P(A \\cap B) - P(A)P(B)| \\leq [BLANK]$. What is the term that fills in the blank?",
    "gold_answer": "\\alpha(n). This term represents the strong mixing coefficient, which quantifies the dependence between events separated by n steps in the sequence.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "\\alpha(n)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î±(n)\"\n}",
      "model_answer": "Î±(n)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2797",
    "folder": "",
    "question": "A univariate spline $S(x)$ of degree $\\mathbf{\\nabla}m$ with knots $\\{x^{i}\\},i=0,...,n$ is a function S $\\because R\\rightarrow R$ which is globally of continuity class $C^{m-1}$ , and on every interval between knots $(-\\infty,x^{0})$, $(x^{0},x^{1}),...,(x^{n-1},x^{n}),(x^{n},\\infty)$ is a polynomial of degree [BLANK].",
    "gold_answer": "m. The degree of the polynomial pieces between the knots is equal to the degree of the spline, which is m.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1986\\ScienceDirect_articles_02Mar2025_02-27-40.843\\Multivariate-splines--A-probabilistic-persp_1986_J\\Multivariate-splines--A-probabilistic-persp_1986_J.md",
      "Multivariate-splines--A-probabilistic-persp_1986_J.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "m",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"m\"\n}",
      "model_answer": "m",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1497",
    "folder": "",
    "question": "In the context of the random-scale model, the peak-to-sum ratio P is modeled given M > u and P < 1 using a [BLANK] distribution.",
    "gold_answer": "scaled beta. This distribution is selected for its ability to model variables bounded within a specific range, fitting the constraints of the peak-to-sum ratio.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "scaled beta",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"beta\"\n}",
      "model_answer": "beta",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-836",
    "folder": "",
    "question": "In the model for aligning time series fragments, the equation Y_t = Î² + X_{t+J} + Îµ_t is used, where Îµ_t are independent and identically distributed with zero mean and finite variance ÏƒÂ². The term [BLANK] represents the unknown lag between the master series and the fragment to be aligned.",
    "gold_answer": "J. This term is crucial for determining the time shift needed to align the fragment with the master series, capturing the temporal discrepancy between them.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_94_Issue_2\\On_the_alignment_of_multiple_time_series_fragments\\On_the_alignment_of_multiple_time_series_fragments.md",
      "On_the_alignment_of_multiple_time_series_fragments.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "J",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"J\"\n}",
      "model_answer": "J",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1535",
    "folder": "",
    "question": "Theorem 3 suggests that the distance between estimates $\\hat{\\mathcal{C}}^{(t)}$ and the true coefficient tensor $\\mathcal{C}$ is bounded by a term that decays geometrically plus a statistical error term, under the condition that the initialization error $\\mu$ is not too large and the restricted isometry property holds with a small enough constant $\\delta$. The statistical error term is proportional to $\\sqrt{(1/n)\\log n}$, indicating the convergence rate is [BLANK].",
    "gold_answer": "$\\sqrt{(1/n)\\log n}$. This rate demonstrates the statistical efficiency of the deep Kronecker network in estimating the true coefficient tensor from observed data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\sqrt{(1/n)\\log n}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sublinear\"\n}",
      "model_answer": "sublinear",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2101",
    "folder": "",
    "question": "In addition to the asymptotic variance and covariance, some asymptotic moments of $r_{a b}$ , $(a\\ne b)$ ) are available with or without normality. Hotelling (1953, p. 212) gave the asymptotic central moments of $r_{a b}$ up to the sixth order under normality. Olkin and Pratt (1958, Eq. (2.7)) derived the asymptotically unbiased estimator of the population correlation coefficient up to order $n^{-1}$ in normal samples. Konishi (1978, Lemma; 1979a, Theorems 2.1 and 2.2; 1979b, Theorem 6.2) provided the Edgeworth expansions of the distribution of the function of the sample correlation matrix up to order $n^{-1}$ under normality. The normality assumption has been relaxed by some authors. Boik (1998, Eq. (19)) derived the matrix expression of the asymptotic biases of order $n^{-1}$ for the vectorized sample correlation matrix under nonnormality while Ogasawara (2004a, Eq. (A11)) gave the corresponding elementwise result which is convenient for actual computation. Kollo and Ruul (2003, Theorem 4) provided the Edgeworth expansion of the vectorized sample correlation matrix up to order $\\bar{n}^{-1/2}$ with the matrix expression of the associated cumulants up to the third order under nonnormality. The purpose of this paper is to have the Edgeworth expansion of $r_{a b}$ under nonnormality up to order $n^{-1}$ and to illustrate their results with comparison to the corresponding simulated distributions. It will be shown that the asymptotic expansion will improve the approximation to the true distribution with moderate sample sizes. The key to this improvement is the calculation of the [BLANK].",
    "gold_answer": "fourth cumulant. This is essential for accurately approximating the distribution of the sample correlation coefficient under nonnormality with the Edgeworth expansion.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "fourth cumulant",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"asymptotic cumulants\"\n}",
      "model_answer": "asymptotic cumulants",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2597",
    "folder": "",
    "question": "The kernel estimate of a probability density function is defined by fâ‚™(x) = nâ»Â¹hâ»Â¹âˆ‘â±¼â‚Œâ‚â¿K{hâ»Â¹(x - Xâ±¼)}, where K is the [BLANK] and h is the smoothing parameter or window width.",
    "gold_answer": "kernel function. This is omitted to highlight the role of K in determining the shape of the estimate, while h controls the smoothness.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_31_Issue_1\\Kernel Density Estimation Using the Fast Fourier T\\Kernel Density Estimation Using the Fast Fourier T.md",
      "Kernel Density Estimation Using the Fast Fourier T.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "kernel function",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"kernel function\"\n}",
      "model_answer": "kernel function",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3187",
    "folder": "",
    "question": "In the context of linear state space models with known parameters, the Kalman filter (KF) generates best linear unbiased predictions of the underlying states together with their corresponding [BLANK].",
    "gold_answer": "Prediction Mean Square Errors (PMSE). This term is critical as it measures the uncertainty associated with the estimated states.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Prediction Mean Square Errors (PMSE)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"mean squared errors\"\n}",
      "model_answer": "mean squared errors",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-784",
    "folder": "",
    "question": "In the partially linear regression model with responses missing at random, the conditional probability of observing the response given the covariates is denoted by [BLANK]. This assumption is crucial for the validity of the complete case analysis.",
    "gold_answer": "Ï€(U,X). This term represents the probability that the response Y is observed given the covariates (U,X), which is essential for understanding the missingness mechanism in the model.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï€(U,X)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï€(X,Z)\"\n}",
      "model_answer": "Ï€(X,Z)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2061",
    "folder": "",
    "question": "For a stationary sequence of uniform [0, 1] random variables $\\{\\xi_i\\}$, the empirical distribution function $T_n(t)$ is used to study asymptotic properties. Under $\\varphi$-mixing conditions, given $\\epsilon > 0$, there exists a subset $S_{n,\\epsilon}$ of $\\Omega$ with $P(S_{n,\\epsilon}) > 1 - \\epsilon$ on which $1 - (1 - t)/\\beta \\leq T_n(t) \\leq t/\\beta$ for $0 \\leq t \\leq 1$. Here, $\\beta$ depends on [BLANK]. What fills in the blank?",
    "gold_answer": "\\epsilon. The parameter $\\beta$ is chosen based on the given $\\epsilon$ to ensure the probability condition is satisfied.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "\\epsilon",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Îµ\"\n}",
      "model_answer": "Îµ",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1244",
    "folder": "",
    "question": "For the risk ratio (RR) in a three-arm NI trial, under Margin 1, the NI hypothesis can be written as Hâ‚€: Ï€E/Ï€R â‰¤ 1 + f(1 âˆ’ Ï€P/Ï€R) vs. Hâ‚: Ï€E/Ï€R > 1 + f(1 âˆ’ Ï€P/Ï€R), where [BLANK] is the pre-specified negative fraction.",
    "gold_answer": "f. This element is crucial as it defines the fraction of the effect size of the reference treatment over placebo used to determine the NI margin.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f\"\n}",
      "model_answer": "f",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-692",
    "folder": "",
    "question": "In the context of model selection strategies for identifying most relevant covariates in homoscedastic linear models, the proposed method is based on an interpretable scaled quantity that measures a maximal relative error one makes by selecting covariates from a given set of all available covariates. This quantity is denoted as [BLANK].",
    "gold_answer": "D or D_alpha,n. The quantity measures the maximal relative error when selecting covariates, providing a basis for the proposed model selection procedures.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2010\\ScienceDirect_articles_04Mar2025_11-16-58.341\\Model-selection-strategies-for-identifying-most-re\\Model-selection-strategies-for-identifying-most-re.md",
      "Model-selection-strategies-for-identifying-most-re.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "D or D_alpha,n",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"G\"\n}",
      "model_answer": "G",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2793",
    "folder": "",
    "question": "The method was originally proposed for cases where the probability models have [BLANK] support.",
    "gold_answer": "overlapping. The original proposal of bridge sampling was for probability models that have overlapping support, facilitating the computation of ratios of normalizing constants.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "overlapping",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"compact\"\n}",
      "model_answer": "compact",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1395",
    "folder": "",
    "question": "The BHEP test statistic for multivariate normality is given by $T_{n,\\beta}:=n(4\\mathrm{\\boldmath~1\\{~}}S_{n}\\mathrm{is~singular\\}+W_{n,\\beta}\\mathrm{\\boldmath~1\\{~}}S_{n}\\mathrm{is~nonsingular\\}})$. Here, $W_{n,\\beta}$ is the weighted $L^{2}$ -distance between the empirical characteristic function of the scaled residuals and the characteristic function of the standard $d$ -variate normal distribution, weighted by $\\varphi_{\\beta}(t):=(2\\pi\\beta^{2})^{-d/2}\\exp{\\biggl(-\\frac{\\|t\\|^{2}}{2\\beta^{2}}\\biggr)}$. The weight function $\\varphi_{\\beta}$ is chosen because it allows $W_{n,\\beta}$ to take the simple form involving $\\exp\\left(-\\frac{\\beta^{2}}{2}\\parallel Y_{j}-Y_{k}\\parallel^{2}\\right)$. What is the key property of $\\varphi_{\\beta}$ that enables this simplification?",
    "gold_answer": "The weight function $\\varphi_{\\beta}$ is the Fourier transform of a Gaussian kernel, which simplifies the integral expression for $W_{n,\\beta}$ into a sum of exponentials. This property is crucial for the computational tractability of the BHEP test statistic.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The weight function $\\varphi_{\\beta}$ is the Fourier transform of a Gaussian kernel, which simplifies the integral expression for $W_{n,\\beta}$ into a sum of exponentials",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"It is the characteristic function of a normal distribution\"\n}",
      "model_answer": "It is the characteristic function of a normal distribution",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3328",
    "folder": "",
    "question": "In the context of Approximate Bayesian Computation (ABC), the true posterior is approximated by $p(\\theta|y)\\approx p(\\theta|s)$, where $s=s(y)=(s_{1},\\ldots,s_{d})^{\\top}$ is a low-dimensional vector of summary statistics. The approximate posterior itself is constructed as $\\begin{array}{r}{p(\\theta|s)\\approx\\int p(\\theta,s^{*}|s)d s^{*}}\\end{array}$, following standard kernel density estimation arguments. The form of this allows sampler-based ABC algorithms to sample from $p(\\theta,s^{*}|s)$ without direct evaluation of the likelihood. What term is used to describe the scale parameter in the standard smoothing kernel $K_{\\epsilon}(\\|u\\|)=K(\\|u\\|/\\epsilon)/\\epsilon$?",
    "gold_answer": "epsilon. This term controls the bandwidth of the kernel, influencing the degree of smoothing applied in the approximation of the posterior distribution.",
    "source": [
      "Approximate_Bayesian_Computation_and_Bayesâ€™_Linear_Analysis_Toward_High-Dimensional_ABC__Approximate_Bayesian_Computation_and_Bayes__Linear_Analysis__Toward_High-Dimensional_ABC.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_23\\Issue_1\\Approximate_Bayesian_Computation_and_Bayesâ€™_Linear_Analysis_Toward_High-Dimensional_ABC__Approximate_Bayesian_Computation_and_Bayes__Linear_Analysis__Toward_High-Dimensional_ABC\\Approximate_Bayesian_Computation_and_Bayesâ€™_Linear_Analysis_Toward_High-Dimensional_ABC__Approximate_Bayesian_Computation_and_Bayes__Linear_Analysis__Toward_High-Dimensional_ABC.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "epsilon",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"bandwidth\"\n}",
      "model_answer": "bandwidth",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2130",
    "folder": "",
    "question": "In the probabilistic principal component analysis (PPCA) model, the random vector \\(\\mathbf{y}_{i}\\) is expressed as \\(\\mathbf{y}_{i} = \\pmb{\\mu} + W\\mathbf{u}_{i} + \\epsilon_{i}\\), where \\(\\mathbf{u}_{i}\\) is a vector of latent principal components and \\(\\epsilon_{i}\\) is the error term. The distribution assumed for \\(\\mathbf{u}_{i}\\) is [BLANK].",
    "gold_answer": "\\(\\mathbf{u}_{i} \\sim \\mathcal{N}(\\mathbf{0}, I_{q})\\). This distribution is chosen because it simplifies the model by assuming that the latent principal components are independently and identically distributed with zero mean and unit variance, facilitating the estimation of the model parameters.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_65_Issue_1\\Probabilistic Principal Component Analysis to Iden\\Probabilistic Principal Component Analysis to Iden.md",
      "Probabilistic Principal Component Analysis to Iden.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "\\(\\mathbf{u}_{i} \\sim \\mathcal{N}(\\mathbf{0}, I_{q})\\)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"N(0,I)\"\n}",
      "model_answer": "N(0,I)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2705",
    "folder": "",
    "question": "In the context of geological studies, the term 'target population' refers to the entire group of interest about which inferences are to be made, whereas the 'sampled population' consists of the parts of the target population that are actually accessible for sampling. A key concept that bridges these two is the [BLANK], which represents the part of the original rock body still extant and available for sampling.",
    "gold_answer": "existent population. This term is crucial for understanding the limitations and possibilities in geological sampling, highlighting the difference between what was originally present and what remains accessible for study.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_9_Issue_2\\Some Problems in Applying Statistics to Geology\\Some Problems in Applying Statistics to Geology.md",
      "Some Problems in Applying Statistics to Geology.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "existent population",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sampling population\"\n}",
      "model_answer": "sampling population",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-98",
    "folder": "",
    "question": "In the context of dependent competing risks, the joint density of survival time T and censoring time C is denoted by f(t, s). The assumption that the conditional death hazard at instant t differs by a known factor Ï(t) depending on whether an individual is censored before or after t is expressed as lim_(Î´â†’0) [pr(t < T < t + Î´ | T > t, C â‰¤ t) / pr(t < T < t + Î´ | T > t, C > t)] = [BLANK].",
    "gold_answer": "Ï(t). This equation highlights the assumption that the ratio of conditional hazards for individuals censored before time t versus those censored after time t is a known function Ï(t), which is central to modeling dependent censoring.",
    "source": [
      "Dependent_competing_risks_and_summary_survival_curves.md",
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_70_Issue_3\\Dependent_competing_risks_and_summary_survival_curves\\Dependent_competing_risks_and_summary_survival_curves.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï(t)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï(t)\"\n}",
      "model_answer": "Ï(t)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2923",
    "folder": "",
    "question": "In the comparison of polynomial histogram estimators with kernel estimators, one notable advantage of the second-order polynomial histogram estimator (Sophe) is its larger optimal binwidth. This larger binwidth leads to [BLANK], making the Sophe computationally more efficient than kernel estimators in higher dimensions.",
    "gold_answer": "more efficient computations. The larger binwidth reduces the number of bins needed, significantly lowering the computational effort required for density estimation in multivariate settings.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "more efficient computations",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"fewer bins\"\n}",
      "model_answer": "fewer bins",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3119",
    "folder": "",
    "question": "The POT stability of a univariate GPD is characterized by the property that for a random variable $U$ following a GPD $W$, the conditional probability $P(U>t x_{0} \\mid U>x_{0})$ is invariant to the choice of $x_{0}$. For a polynomial GPD, this probability equals $t^{\\alpha}$ for $t\\in[0,1]$. For a Pareto GPD, it equals $t^{-\\alpha}$ for $t\\geqslant1$, and for the exponential GPD, it equals $\\exp(-t)$ for $t\\geqslant0$. The key property that makes these distributions POT stable is the [BLANK] of the exceedance distributions to the threshold $x_{0}$.",
    "gold_answer": "invariance. This property is crucial for understanding the behavior of exceedances over thresholds in the context of generalized Pareto distributions.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "invariance",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"invariance\"\n}",
      "model_answer": "invariance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3622",
    "folder": "",
    "question": "In the context of testing hypotheses about changes in the center of location for truncated data, the test function proposed by David and Johnson for the one-sample case is denoted as [BLANK]. What is the correct symbol for this test function?",
    "gold_answer": "T_a. This symbol is used to represent the test function based on the difference of sample quantiles in the one-sample case, highlighting its distinction from other test functions discussed in the paper.",
    "source": [
      "A Comparison of Two Sorts of Test for a Change of.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_19_Issue_1\\A Comparison of Two Sorts of Test for a Change of\\A Comparison of Two Sorts of Test for a Change of.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "T_a",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Tâ‚\"\n}",
      "model_answer": "Tâ‚",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-580",
    "folder": "",
    "question": "In the context of row-column designs, the average efficiency factor is given by the harmonic mean of the [BLANK], which are (1/r) times the nonzero eigenvalues of its information matrix.",
    "gold_answer": "canonical efficiency factors. This highlights the mathematical foundation used to evaluate the performance of row-column designs by focusing on the eigenvalues of the information matrix.",
    "source": [
      "Bounds_for_the_efficiency_factor_of_row-column_designs.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_79_Issue_3\\Bounds_for_the_efficiency_factor_of_row-column_designs\\Bounds_for_the_efficiency_factor_of_row-column_designs.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "canonical efficiency factors",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"canonical efficiency factors\"\n}",
      "model_answer": "canonical efficiency factors",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1572",
    "folder": "",
    "question": "In the setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR)",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2200",
    "folder": "",
    "question": "In the context of high-dimensional data analysis for causal effect estimation with multivariate treatments, the proposed Double Screening Prior Adaptive Lasso (DSPAL) method combines the adaptive lasso method with the marginal conditional (in)dependence prior information to select target covariates. The distinctive feature of DSPAL is that it can be applied to [BLANK] dimensional covariates for multivariate treatments, and can deal with both parametric and nonparametric outcome models.",
    "gold_answer": "high-dimensional or even ultra-high. This highlights DSPAL's capability to handle datasets where the number of covariates is very large, possibly exceeding the sample size, making it versatile for various types of data analysis scenarios.",
    "source": [
      "A-new-covariate-selection-strategy-for-high-dimens.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2023\\ScienceDirect_articles_28Feb2025_08-28-26.958\\A-new-covariate-selection-strategy-for-high-dimens\\A-new-covariate-selection-strategy-for-high-dimens.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "high-dimensional or even ultra-high",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"high\"\n}",
      "model_answer": "high",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1072",
    "folder": "",
    "question": "The proposed method for subgroup identification is robust against heavy-tailed errors or outliers due to the use of [BLANK] regression.",
    "gold_answer": "median",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "median",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"quantile\"\n}",
      "model_answer": "quantile",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2806",
    "folder": "",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yáµ¢â±¼ can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where Î±áµ£ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "báµ¢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [
      "Detection-and-localization-of-changes-in-a-pan_202.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2025\\ScienceDirect_articles_28Feb2025_08-24-54.169\\Detection-and-localization-of-changes-in-a-pan_202\\Detection-and-localization-of-changes-in-a-pan_202.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1427",
    "folder": "",
    "question": "In the context of seasonal cointegration analysis, the new iterative reduced-rank regression procedures are motivated by the idea that modelling the cointegration restrictions jointly at different frequencies may increase [BLANK] in finite samples.",
    "gold_answer": "efficiency. This highlights the advantage of considering multiple frequencies together to improve the accuracy and reliability of statistical analyses in small samples.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2005\\ScienceDirect_articles_04Mar2025_14-57-17.520\\Small-sample-improvements-in-the-statistical-anal_\\Small-sample-improvements-in-the-statistical-anal_.md",
      "Small-sample-improvements-in-the-statistical-anal_.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "efficiency",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"efficiency\"\n}",
      "model_answer": "efficiency",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3458",
    "folder": "",
    "question": "In the context of rounding error adjustments in regression, Sheppard's corrections involve subtracting a term of the form [BLANK] from the diagonal elements of the sample covariance matrix calculated using rounded data, where Î´ denotes the width of the rounding interval.",
    "gold_answer": "Î´Â²/12. This term is subtracted to adjust for the bias introduced by rounding errors in the data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î´Â²/12",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î´Â²/12\"\n}",
      "model_answer": "Î´Â²/12",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-802",
    "folder": "",
    "question": "A necessary, though not sufficient, condition for a multivariate distribution to be normal is that all the marginal distributions should be [BLANK].",
    "gold_answer": "univariate normal. This is removed to emphasize the foundational requirement for testing multivariate normality through the examination of its marginal distributions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_29_Issue_1\\Marginal Skewness and Kurtosis in Testing Multivar\\Marginal Skewness and Kurtosis in Testing Multivar.md",
      "Marginal Skewness and Kurtosis in Testing Multivar.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "univariate normal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"normal\"\n}",
      "model_answer": "normal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1342",
    "folder": "",
    "question": "The Coordinate-Exchange Algorithm is used to construct the additional runs Xâ‚‚ to optimize the Bayesian D-optimality criterion |Xâ‚â€²Xâ‚ + Xâ‚‚â€²Xâ‚‚ + R|. This algorithm iterates through each entry in the design matrix, replacing the current value with the entry from {-1, +1} that results in the largest value of the objective function. Because the resulting design is likely only locally optimal, the algorithm is repeated many times with different random starting values for the entries. After many random starts, e.g., 100, the design with the largest determinant is approximately the Bayesian D-optimal design. The number of random starts suggested by Jones et al. (2008) to ensure the design is approximately optimal is [BLANK].",
    "gold_answer": "100. This number of random starts is suggested to ensure that the algorithm explores a wide range of possible designs and converges to one that is approximately optimal.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "100",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"100\"\n}",
      "model_answer": "100",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-36",
    "folder": "",
    "question": "In the analysis of correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yáµ¢â±¼ can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where Î±áµ£ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "báµ¢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2378",
    "folder": "",
    "question": "The measurement equation for continuous variables in the GLVM is specified using an identity link function, where the expected value of the response variable is related to the latent variables through the equation: gâ±¼(Ï‘áµ¢â±¼,â‚–) = Ï‘áµ¢â±¼,â‚– = Î¼â±¼,â‚– + [BLANK]'Ï‰áµ¢. What term completes this equation to represent the linear predictor?",
    "gold_answer": "Î›â±¼,â‚–. This term represents the vector of factor loadings for the jth observed variable in the kth component, linking the latent variables to the observed variables.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î›â±¼,â‚–",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»â±¼,â‚–\"\n}",
      "model_answer": "Î»â±¼,â‚–",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2799",
    "folder": "",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK]. This assumption is essential for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by ensuring that missingness does not depend on unobserved data once conditioned on observed responses.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-318",
    "folder": "",
    "question": "In the study of Shirley poppies, the mean number of stigmatic bands per capsule was found to be [BLANK] for the original Hampden crop.",
    "gold_answer": "12.51. This value represents the average number of stigmatic bands observed in the capsules of the original Hampden crop, serving as a baseline for comparison with other crops.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "12",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"12.6\"\n}",
      "model_answer": "12.6",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2137",
    "folder": "",
    "question": "In the context of testing the conditional mean and conditional variance for nonstationary data, the hypothesis can be interpreted as testing both the mean and the variance, or testing the mean under knowledge of an upper bound on the variance. The paper mainly uses interpretation (A), which is relevant when the tester is interested in whether a time series has switched away from a given regime with specified mean and variance bounds. The key challenge in this setting is that the data points are not [BLANK], and hence we cannot make inference of the distributions themselves.",
    "gold_answer": "independent and identically distributed. This is excluded to highlight the complexity of the problem where traditional inference methods cannot be directly applied due to the lack of i.i.d. assumptions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_112_Issue_1\\Testing_the_mean_and_variance_by_e-processes\\Testing_the_mean_and_variance_by_e-processes.md",
      "Testing_the_mean_and_variance_by_e-processes.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "independent and identically distributed",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"independent\"\n}",
      "model_answer": "independent",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-428",
    "folder": "",
    "question": "In the algorithm for generating population correlation matrices with specified eigenvalues, the initial step involves generating a random orthogonal matrix A from the invariant Haar measure on the group of orthogonal matrices. The resulting matrix Câ‚€ = A D Aâ€² is a random covariance matrix with eigenvalues given by D. What is the next step in the algorithm after obtaining Câ‚€?",
    "gold_answer": "The algorithm successively obtains n-1 orthogonal matrices Páµ¢ so that C = Pâ‚™â‚‹â‚Pâ‚™â‚‹â‚‚...Pâ‚‚Pâ‚Câ‚€Pâ‚â€²Pâ‚‚â€²...Pâ‚™â‚‹â‚‚â€²Pâ‚™â‚‹â‚â€² is a correlation matrix having the same eigenvalues as Câ‚€. This step is crucial for transforming the covariance matrix into a correlation matrix while preserving the specified eigenvalues.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_34_Issue_2\\Generation of Population Correlation Matrices with\\Generation of Population Correlation Matrices with.md",
      "Generation of Population Correlation Matrices with.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The algorithm successively obtains n-1 orthogonal matrices Páµ¢ so that C = Pâ‚™â‚‹â‚Pâ‚™â‚‹â‚‚",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Standardize Câ‚€ to obtain a correlation matrix\"\n}",
      "model_answer": "Standardize Câ‚€ to obtain a correlation matrix",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1100",
    "folder": "",
    "question": "In the context of product return data with two-layer censoring, the first layer of censoring is called [BLANK], which applies to the product lifetime due to a fixed warranty limit.",
    "gold_answer": "warranty censoring. This term is used to describe the censoring that occurs because the product's lifetime is only observed up to the warranty limit.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_72_Issue_5\\Phase-type distributions for product return data w\\Phase-type distributions for product return data w.md",
      "Phase-type distributions for product return data w.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "warranty censoring",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Type I censoring\"\n}",
      "model_answer": "Type I censoring",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1526",
    "folder": "",
    "question": "The usual measures of dispersion such as the sample variance, the sample mean deviation, the sample range, etc. cannot be used when the mean of the population is undergoing a trend, since they are likely to be seriously affected by the trend. Under these circumstances and especially if the trend is a slow-moving one, the following four measures of dispersion based on successive differences have been proposed: [BLANK], d, Î´â‚Â³, and dâ‚ƒ.",
    "gold_answer": "Î´Â². This is the first of the four measures of dispersion based on successive differences proposed for use when the population mean is undergoing a trend, highlighting its importance in such scenarios.",
    "source": [
      "APPROXIMATIONS_TO_THE_DISTRIBUTIONS_OF_SOME_MEASURES_OF_DISPERSION_BASED_ON_SUCCESSIVE_DIFFERENCES.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_44_Issue_3-4\\APPROXIMATIONS_TO_THE_DISTRIBUTIONS_OF_SOME_MEASURES_OF_DISPERSION_BASED_ON_SUCCESSIVE_DIFFERENCES\\APPROXIMATIONS_TO_THE_DISTRIBUTIONS_OF_SOME_MEASURES_OF_DISPERSION_BASED_ON_SUCCESSIVE_DIFFERENCES.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î´Â²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î´â‚â‚‚\"\n}",
      "model_answer": "Î´â‚â‚‚",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3608",
    "folder": "",
    "question": "For a matrix $M = [D_{a_{i}} + \\alpha\\mathbf{b}\\mathbf{b}^{\\prime}]$ where all $a_{i} = a$ and $\\mathbf{b}$ is a unit vector, the characteristic equation reduces to $\\{(a - \\lambda) + \\alpha n\\}(a - \\lambda)^{n-1} = 0$. What are the $n$ characteristic roots in this case?",
    "gold_answer": "The $n$ characteristic roots are $n-1$ roots equal to $a$ and one root equal to $a + \\alpha n$. This result highlights the impact of the vector $\\mathbf{b}$ and scalar $\\alpha$ on the matrix's eigenvalues.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The $n$ characteristic roots are $n-1$ roots equal to $a$ and one root equal to $a + \\alpha n$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"one root equal to a + Î±n and n-1 roots equal to a\"\n}",
      "model_answer": "one root equal to a + Î±n and n-1 roots equal to a",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2845",
    "folder": "",
    "question": "The horizontal distance between the two lines turns out to be the ratio of the number of degrees of freedom attributable to regression to the total number of degrees of freedom. This indicates rather neatly the way in which the degree of indeterminacy in the bounds procedure depends on both the number of regressors and the [BLANK].",
    "gold_answer": "sample size. The ratio reflects how the test's sensitivity to serial correlation is influenced by the model's complexity and the amount of data available.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "sample size",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sample size\"\n}",
      "model_answer": "sample size",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1779",
    "folder": "",
    "question": "The asymptotic properties of the model averaging estimator are derived under [BLANK] and heteroskedastic errors.",
    "gold_answer": "homoskedastic",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "homoskedastic",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"fixed design\"\n}",
      "model_answer": "fixed design",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3552",
    "folder": "",
    "question": "In the context of robust estimation of power spectra, the term [BLANK] refers to the process of filtering the data to transform the original time series into a series whose spectrum is nearly flat.",
    "gold_answer": "prewhitening",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "prewhitening",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"prewhitening\"\n}",
      "model_answer": "prewhitening",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1177",
    "folder": "",
    "question": "In the context of multivariate scale mixtures, the transformation from $S$ to $Y = S^{\\delta/\\rho}$ is considered, where $\\delta = \\pm1$ and $\\rho$ is a positive number. The choice of $\\rho$ is typically $\\frac{1}{2}$ or $1$ depending on whether $Z_1$ is distributed as the standard normal distribution or a gamma distribution. The constant $\\delta$ is chosen so that the first few moments of $S_i^{\\delta/\\rho}, i=1,\\dots,p$ are computable or evaluated. The transformation in case (1.2) is expressed as $Y_i = S_i^{\\delta/\\rho}, i=1,\\dots,p$. What critical value is omitted in the transformation expression?",
    "gold_answer": "The critical value omitted in the transformation expression is the specific choice of $\\delta$ (which can be $1$ or $-1$) that ensures the first few moments of $S_i^{\\delta/\\rho}$ are computable or evaluated. This choice is crucial for the practical application of the transformation, as it influences the computability of the moments and the overall behavior of the scale mixture model.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2005\\ScienceDirect_articles_01Mar2025_10-57-00.799\\L1-norm-error-bounds-for-asymptotic-expansions-of-\\L1-norm-error-bounds-for-asymptotic-expansions-of-.md",
      "L1-norm-error-bounds-for-asymptotic-expansions-of-.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The critical value omitted in the transformation expression is the specific choice of $\\delta$ (which can be $1$ or $-1$) that ensures the first few moments of $S_i^{\\delta/\\rho}$ are computable or evaluated",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0\"\n}",
      "model_answer": "0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3219",
    "folder": "",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yáµ¢â±¼ can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where Î±áµ£ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "báµ¢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1648",
    "folder": "",
    "question": "In the nonparametric calibration method for age estimation, the posterior distribution of age given the indicator variables is derived using [BLANK], which combines the likelihood of the indicators given age and the prior distribution of age.",
    "gold_answer": "Bayesâ€™s theorem. This is the fundamental principle that allows the posterior distribution to be calculated from the likelihood and the prior, enabling the incorporation of prior knowledge into the estimation process.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_51_Issue_2\\Nonparametric Calibration for Age Estimation\\Nonparametric Calibration for Age Estimation.md",
      "Nonparametric Calibration for Age Estimation.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Bayesâ€™s theorem",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Bayes' theorem\"\n}",
      "model_answer": "Bayes' theorem",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1619",
    "folder": "",
    "question": "In the Gaussian channel model with feedback, the mutual information $I_{t}(\\xi,Y)$ between the message $\\xi(\\cdot)$ and the output $Y(\\cdot)$ is given by a causal functional of $Y(\\cdot)$ when the spectral measure of the Gaussian noise $X(\\cdot)$ is [BLANK].",
    "gold_answer": "continuous. This condition ensures that the mutual information can be expressed in terms of a causal functional of the output process, facilitating the analysis of information transmission in such channels.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1975\\ScienceDirect_articles_02Mar2025_09-14-47.268\\Gaussian-channels-and-the-optimal-codin_1975_Journ\\Gaussian-channels-and-the-optimal-codin_1975_Journ.md",
      "Gaussian-channels-and-the-optimal-codin_1975_Journ.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "continuous",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"absolutely continuous\"\n}",
      "model_answer": "absolutely continuous",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-15",
    "folder": "",
    "question": "When modeling correlated ordinal responses, a proportional odds mixed model may include random effects to account for individual heterogeneity. The model can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where the omitted term captures individual-specific deviations.",
    "gold_answer": "báµ¢ (the random intercept). This term is essential for modeling the correlation within each subject's repeated measurements, accounting for the variability not explained by the fixed effects alone.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2127",
    "folder": "",
    "question": "The assumption that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes is known as [BLANK]. This assumption is crucial for likelihood-based or multiple-imputation methods to yield valid inferences.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies inference by stating that once we condition on the observed responses, the missingness no longer depends on the unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3202",
    "folder": "",
    "question": "In the context of goodness-of-fit tests for a multivariate distribution using the empirical characteristic function approach, the null hypothesis can be expressed as $H_{0}\\colon C(t)=C_{0}(t)$ for $t\\in R^{d}$, where $C(t)$ is the characteristic function of the distribution function $F(\\cdot)$ and $C_{0}(t)$ is the characteristic function of the specified distribution function $F_{0}(\\cdot)$. The test statistic proposed to measure the discrepancy between the empirical characteristic function $C_{n}(\\cdot)$ and $C_{0}(\\cdot)$ is given by $T_{n}=[Z_{n}(\\bar{t}_{m})-Z_{0}(\\bar{t}_{m})]^{\\prime}\\varOmega_{0}^{-1/2}(\\bar{t}_{m})W(\\bar{t}_{m},\\lambda)\\varOmega_{0}^{-1/2}(\\bar{t}_{m})[Z_{n}(\\bar{t}_{m})-Z_{0}(\\bar{t}_{m})]$, where $Z_{n}(\\bar{t}_{m})$ and $Z_{0}(\\bar{t}_{m})$ are vectors containing the real and imaginary parts of $C_{n}(t)$ and $C_{0}(t)$ evaluated at points $t_{1},...,t_{m}\\in R^{d}$, and $\\varOmega_{0}(\\bar{t}_{m})$ is the covariance matrix of $Y_{j}(\\bar{t}_{m})$ under $H_{0}$. The weight matrix $W(\\bar{t}_{m},\\lambda)$ is used to direct the power of the test towards different frequencies. The term deliberately omitted in the description of $T_{n}$ that highlights the role of $\\varOmega_{0}^{-1/2}(\\bar{t}_{m})$ is [BLANK].",
    "gold_answer": "ensuring that the transformed vector $\\varOmega_{0}^{-1/2}(\\bar{t}_{m})[Z_{n}(\\bar{t}_{m})-Z_{0}(\\bar{t}_{m})]$ has an identity covariance matrix under $H_{0}$. This transformation standardizes the discrepancy measure, making the test statistic invariant to the scale of the original data and facilitating the comparison across different frequencies.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1997\\ScienceDirect_articles_01Mar2025_11-25-08.904\\Goodness-of-Fit-Tests-for-a-Multivariate-Distribut\\Goodness-of-Fit-Tests-for-a-Multivariate-Distribut.md",
      "Goodness-of-Fit-Tests-for-a-Multivariate-Distribut.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ensuring that the transformed vector $\\varOmega_{0}^{-1/2}(\\bar{t}_{m})[Z_{n}(\\bar{t}_{m})-Z_{0}(\\bar{t}_{m})]$ has an identity covariance matrix under $H_{0}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"standardization\"\n}",
      "model_answer": "standardization",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1088",
    "folder": "",
    "question": "The asymptotic null distribution of the proposed test statistic is shown to converge weakly to a function of the [BLANK], under the null hypothesis of no parameter change.",
    "gold_answer": "Brownian bridge. This convergence is crucial for determining the critical values of the test statistic under the null hypothesis, facilitating hypothesis testing.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Brownian bridge",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Brownian bridge\"\n}",
      "model_answer": "Brownian bridge",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1872",
    "folder": "",
    "question": "The dichotomy pointed out by Feller in the context of diffusion processes distinguishes between systems with microscopic fluctuations and those with macroscopic fluctuations. In the case of microscopic fluctuations, the limit process is of the Ornstein-Uhlenbeck (Gaussian) type, obtained by amplifying the fluctuations by an appropriate factor. For systems with macroscopic fluctuations, the diffusion process satisfies a stochastic differential equation with nonconstant coefficients and is a mass process in the sense that the state space is [BLANK]. What is the state space for systems with macroscopic fluctuations?",
    "gold_answer": "R+. This denotes the space of nonnegative real numbers, indicating that the process models quantities that are inherently nonnegative, such as mass.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "R+",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"[0,âˆž)\"\n}",
      "model_answer": "[0,âˆž)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1746",
    "folder": "",
    "question": "In the context of conditional marginal regression, the proposed maximum-type test statistic is designed to detect the effects of $X$ in the presence of $Z$ by considering conditional marginal regression, where the response variable is separately regressed on each component of $X$ conditional on $Z$. The test statistic is based on a scale-invariant $t$-statistic, which maximizes $(\\hat{\\theta}_{j}^{Z})^{2}\\hat{V}_{j|Z}$, where $\\hat{\\theta}_{j}^{Z}$ is the estimated coefficient of $X_{j}$ when regressing $Y$ on $Z$ and $X_{j}$ together, and $\\hat{V}_{j|Z}$ is the estimated [BLANK] of $X_{j}$ given $Z$.",
    "gold_answer": "conditional variance. This term is crucial for understanding the variability of $X_{j}$ after accounting for the effects of $Z$, which is essential for the scale-invariance property of the test statistic.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "conditional variance",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"variance\"\n}",
      "model_answer": "variance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1827",
    "folder": "",
    "question": "The optimal rate of convergence for estimators of the stable tail dependence function l is determined by the behavior of a function g, which is Ï-varying at 0. For a sequence tâ‚™ satisfying lim_{nâ†’âˆž} g(tâ‚™)(n tâ‚™)Â¹/Â² = 1, the optimal rate aâ‚™ must satisfy lim_{nâ†’âˆž} aâ‚™/(g(tâ‚™)) = [BLANK] if Ï > 0.",
    "gold_answer": "âˆž. This indicates that the rate of convergence aâ‚™ must be slower than g(tâ‚™) to ensure that the estimator achieves the optimal balance between bias and variance.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "âˆž",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-565",
    "folder": "",
    "question": "The bootstrap-based procedure proposed as a diagnostic tool involves generating new samples by resampling the pairs $(x_t, y_t)$ from the data, taking into account the stochastic properties of the variables if necessary, a method attributed to [BLANK].",
    "gold_answer": "KÃ¼nsch (1989), Politis and Romano (1994), and Hansen (2002). These authors contributed to the development of bootstrap methods that account for the time series properties of financial data, ensuring the robustness of the resampling procedure.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "KÃ¼nsch (1989), Politis and Romano (1994), and Hansen (2002)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Freedman\"\n}",
      "model_answer": "Freedman",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2024",
    "folder": "",
    "question": "In the WaveSpect0 software package, the step-interval unification is achieved by applying [BLANK] interpolation in resampling.",
    "gold_answer": "cubic spline. Cubic spline interpolation is used to unify the step intervals of discrete data, ensuring that the data can be correctly and efficiently processed by MATLAB wavelet functions.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "cubic spline",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"linear\"\n}",
      "model_answer": "linear",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3019",
    "folder": "",
    "question": "In the context of analyzing the divergence of sub-groups from a general population, the coefficient of mean square contingency is used to measure heterogeneity. The formula for the coefficient of divergence for a sub-group b is given by c_b = sqrt(phi_b^2 / (1 - n_b/N + phi_b^2)), where phi_b^2 is the contribution of the sub-group to the total mean square contingency, n_b is the size of the sub-group, and N is the total population size. If phi_b^2 = 0, this implies that the sub-group is a [BLANK] sample of the general population.",
    "gold_answer": "random. This is because a phi_b^2 value of 0 indicates no contribution to the mean square contingency, suggesting the sub-group does not diverge from the general population and thus is a random sample.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_5_Issue_1-2\\X._On_a_Coefficient_of_Class_Heterogeneity_or_Divergence\\X._On_a_Coefficient_of_Class_Heterogeneity_or_Divergence.md",
      "X._On_a_Coefficient_of_Class_Heterogeneity_or_Divergence.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "random",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"random\"\n}",
      "model_answer": "random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2824",
    "folder": "",
    "question": "The selection of the tuning parameter q in the TC-MLqE method is based on the empirical stability of the estimates, aiming to choose q closest to 1 such that the estimates are sufficiently [BLANK].",
    "gold_answer": "stable. This approach ensures that the method remains efficient in the absence of contamination while robust against outliers.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "stable",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"stable\"\n}",
      "model_answer": "stable",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2",
    "folder": "",
    "question": "In the analysis of ordinal data, the proportional odds mixed model for a single ordinal response Yáµ¢â±¼ can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where Î±áµ£ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "báµ¢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_12_Issue_1-2\\II._Sur_lea_moments_de_la_fonction_de_correlation_normale_de_n_variables\\II._Sur_lea_moments_de_la_fonction_de_correlation_normale_de_n_variables.md",
      "II._Sur_lea_moments_de_la_fonction_de_correlation_normale_de_n_variables.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1228",
    "folder": "",
    "question": "In the HMTD model, the time series is treated as a mixture where the relation between the components is governed by a [BLANK] latent transition process.",
    "gold_answer": "Markovian. This emphasizes the model's use of Markov processes to govern transitions between different states or components of the mixture.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Markovian",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Markov\"\n}",
      "model_answer": "Markov",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1812",
    "folder": "",
    "question": "In the context of quality control for skew distributed data, the logarithmic transformation is used to calculate control limits by reversing the transformation to fix the limits so that sample values can be plotted in their original scale of measurement. This approach is based on the properties of the [BLANK] distribution.",
    "gold_answer": "lognormal. The question removes 'lognormal' to emphasize the specific distribution that underpins the method for handling skew data in quality control, highlighting its importance in the transformation process.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_7_Issue_3\\The Lognormal Distribution in Quality Control\\The Lognormal Distribution in Quality Control.md",
      "The Lognormal Distribution in Quality Control.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "lognormal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"lognormal\"\n}",
      "model_answer": "lognormal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2026",
    "folder": "",
    "question": "The Gaussian state space form is given by y_t = Z_tÎ±_t + Îµ_t, Î±_t = T_tÎ±_{t-1} + Î·_t (t=1,â€¦,n), where Î±_0 ~ N(a_0, P_0), Îµ_t ~ N(0, H_t), Î·_t ~ N(0, Q_t), and the initial conditions a_0 and P_0 are known. The [BLANK] can be used to deliver the log likelihood which in turn means the score can be evaluated by numerical differentiation.",
    "gold_answer": "Kalman filter. This is omitted to highlight the tool's central role in evaluating the log likelihood and subsequently the score through numerical differentiation in Gaussian state space models.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_79_Issue_4\\Miscellanea_Exact_score_for_time_series_models_in_state_space_form\\Miscellanea_Exact_score_for_time_series_models_in_state_space_form.md",
      "Miscellanea_Exact_score_for_time_series_models_in_state_space_form.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Kalman filter",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Kalman filter\"\n}",
      "model_answer": "Kalman filter",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-724",
    "folder": "",
    "question": "Under appropriate conditions, the paper proves consistency and asymptotic normality of WC estimators. From a computational point of view, computing WC estimators involves solving a minimax continuous problem, which is quite a challenging task, and the use of efficient numerical methods is required. In particular, the paper uses the global optimization algorithm considered by [BLANK].",
    "gold_answer": "Zakovic and Rustem (2003). This specifies the algorithm used for solving the minimax problem, highlighting the practical approach to computation.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Zakovic and Rustem (2003)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Gaudioso and Monaco\"\n}",
      "model_answer": "Gaudioso and Monaco",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1144",
    "folder": "",
    "question": "In the semiparametric model proposed for the marginal mark distribution, the association between the mark and survival time is parameterised by [BLANK], while the marginals are left unspecified.",
    "gold_answer": "Ï (the correlation coefficient). This highlights the model's flexibility in specifying the dependence structure without imposing strict assumptions on the marginal distributions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_93_Issue_4\\Semiparametric_estimation_of_marginal_mark_distribution\\Semiparametric_estimation_of_marginal_mark_distribution.md",
      "Semiparametric_estimation_of_marginal_mark_distribution.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï (the correlation coefficient)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"a copula\"\n}",
      "model_answer": "a copula",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3109",
    "folder": "",
    "question": "Kernel density estimators for discrete multivariate data are investigated, using the notation framework of contingency tables. We derive large sample properties of kernel estimators and the least-squares cross-validation method for choosing the bandwidth, including the asymptotic bias, the mean summed squared error, the actual summed squared error, and the asymptotic distribution of the resulting nonparametric estimator. We show that the least-squares cross-validation procedure is superior to Kullback-Leibler cross-validation in terms of [BLANK], but that the least-squares cross-validation is still sub-optimal concerning actual summed squared error.",
    "gold_answer": "mean summed squared error. This highlights the comparative advantage of the least-squares cross-validation method over Kullback-Leibler cross-validation when evaluating the performance of kernel estimators based on mean summed squared error, despite its sub-optimality regarding actual summed squared error.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "mean summed squared error",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"mean summed squared error\"\n}",
      "model_answer": "mean summed squared error",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-624",
    "folder": "",
    "question": "In the context of Gaussian Process (GP) regression surrogates for Bayesian estimation, the universal approximation property ensures that the GP can approximate any continuous function arbitrarily well on a compact subset of the input space. This property is guaranteed if the kernel used is [BLANK]. Which type of kernel guarantees this property?",
    "gold_answer": "universal. A kernel is universal if it can approximate any continuous function to arbitrary precision on a compact subset of the input space, which is a critical property for Gaussian Process regression surrogates in Bayesian estimation frameworks.",
    "source": [
      "Bayesian-estimation-of-large-scale-simulation-mode.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2024\\ScienceDirect_articles_03Mar2025_08-44-23.862\\Bayesian-estimation-of-large-scale-simulation-mode\\Bayesian-estimation-of-large-scale-simulation-mode.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "universal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"universal\"\n}",
      "model_answer": "universal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-365",
    "folder": "",
    "question": "The target INR range for patients prescribed anticoagulants is typically between [BLANK] and 3, aiming to balance the risk of thrombosis and bleeding.",
    "gold_answer": "2. The blank is filled with '2' to specify the lower bound of the target INR range for patients on anticoagulants, ensuring a reduced risk of thrombosis without excessively increasing bleeding risk.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "2",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"2\"\n}",
      "model_answer": "2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-995",
    "folder": "",
    "question": "In the proportional hazards regression model for the subdistribution of a competing risk, the subdistribution hazard function is defined as [BLANK], where Fâ‚(t;Z) is the cumulative incidence function of cause 1 given covariates Z.",
    "gold_answer": "Î»â‚*(t;Z) = -d log{1 - Fâ‚(t;Z)} / dt. This formula is crucial as it directly relates the subdistribution hazard to the cumulative incidence function, allowing for the modeling of covariate effects on the subdistribution hazard.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2016_Volume_43_Issue_1\\Scandinavian J Statistics - 2015 - He - A Proporti\\Scandinavian J Statistics - 2015 - He - A Proporti.md",
      "Scandinavian J Statistics - 2015 - He - A Proporti.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î»â‚*(t;Z) = -d log{1 - Fâ‚(t;Z)} / dt",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»â‚(t;Z) = -d log{1-Fâ‚(t;Z)}/dt\"\n}",
      "model_answer": "Î»â‚(t;Z) = -d log{1-Fâ‚(t;Z)}/dt",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3026",
    "folder": "",
    "question": "In the eigen-adjusted FPCA model, the covariance function Î“(s,t,z) is assumed to vary with the covariates via its [BLANK] while the corresponding eigenfunctions remain independent of the covariates.",
    "gold_answer": "eigenvalues. This highlights the model's flexibility by allowing the eigenvalues to adjust based on covariate information, facilitating a more nuanced analysis of functional data.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_31\\Issue_4\\Eigen-Adjusted_Functional_Principal_Component_Analysis__Eigen-Adjusted_Functional_Principal_Component_Analysis\\Eigen-Adjusted_Functional_Principal_Component_Analysis__Eigen-Adjusted_Functional_Principal_Component_Analysis.md",
      "Eigen-Adjusted_Functional_Principal_Component_Analysis__Eigen-Adjusted_Functional_Principal_Component_Analysis.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "eigenvalues",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"eigenvalues\"\n}",
      "model_answer": "eigenvalues",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1233",
    "folder": "",
    "question": "In the hierarchical-likelihood approach to autoregressive stochastic volatility models, the h-likelihood is defined as h(b, Î±) = âˆ‘ from t=1 to n of log f(y_t | b_t) + log f_Î±(b_1, ..., b_n). The term [BLANK] is crucial for estimating the unobserved log of volatilities (random effects). What is the missing term in the h-likelihood definition?",
    "gold_answer": "log f_Î±(b_1, ..., b_n). This term represents the log-density of the random effects b under the parameters Î±, which is essential for capturing the autoregressive structure of the volatilities in the model.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2011\\ScienceDirect_articles_04Mar2025_11-15-39.841\\The-hierarchical-likelihood-approach-to-autoregr_2\\The-hierarchical-likelihood-approach-to-autoregr_2.md",
      "The-hierarchical-likelihood-approach-to-autoregr_2.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "log f_Î±(b_1,",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"log f_Î±(b_1, ..., b_n)\"\n}",
      "model_answer": "log f_Î±(b_1, ..., b_n)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1021",
    "folder": "",
    "question": "In statistical inference, one may choose between a population model or a permutation model. The population model, introduced by Neyman and Pearson in 1928, involves sampling from one or more defined populations and applying a test statistic to this randomized sampling. On the other hand, the permutation model was introduced by Fisher in [BLANK].",
    "gold_answer": "1925",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1925",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1935\"\n}",
      "model_answer": "1935",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3369",
    "folder": "",
    "question": "In the context of sequential t tests, the ordinate zâ‚™ is calculated as [BLANK] divided by the sum of the squares of the observations up to n. What is the numerator in this calculation?",
    "gold_answer": "the square of the sum of the observations up to n. This is excluded to emphasize the formula's structure, highlighting how zâ‚™ aggregates the observations' linear and quadratic forms.",
    "source": [
      "Boundaries_for_closed_(wedge)_sequential_t_test_plans.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_53_Issue_3-4\\Boundaries_for_closed_(wedge)_sequential_t_test_plans\\Boundaries_for_closed_(wedge)_sequential_t_test_plans.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the square of the sum of the observations up to n",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the sum of the observations\"\n}",
      "model_answer": "the sum of the observations",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2948",
    "folder": "",
    "question": "The proposed nonparametric estimator of the psf h assumes that h is a member of [BLANK], meaning âˆ«âˆ«_D hÂ²(x,y) dxdy < âˆž.",
    "gold_answer": "LÂ²(D). This assumption ensures that the psf h has finite energy over the domain D, which is a common requirement in image processing.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "LÂ²(D)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Lâ‚‚(D)\"\n}",
      "model_answer": "Lâ‚‚(D)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1308",
    "folder": "",
    "question": "The probability generating functional (PGF) of the point process Nâ‚™(Â·|(a,i)) is given by Gâ‚™(Ï†|(a,i)), where Ï† is a function from DÃ—{1,...,q} to â„, with 1âˆ’Ï†(Â·,i) âˆˆ C_c(D), and 0 â‰¤ Ï†(Â·,Â·) â‰¤ 1. The semigroup property of Gâ‚™ states that Gâ‚™(Gâ‚˜(Ï†|Â·,Â·)|(x,i)) = [BLANK].",
    "gold_answer": "Gâ‚™â‚Šâ‚˜(Ï†|(x,i)). This property reflects the Markovian nature of the branching random walk, allowing the composition of generating functionals over successive generations.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Gâ‚™â‚Šâ‚˜(Ï†|(x,i))",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Gâ‚™â‚Šâ‚˜(Ï†|(x,i))\"\n}",
      "model_answer": "Gâ‚™â‚Šâ‚˜(Ï†|(x,i))",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1937",
    "folder": "",
    "question": "The varianceâ€“covariance matrix for the random vectors u and Î½ is given by Î£ = Î“ âŠ— I_M, where Î“ is a matrix with elements Î¸_u^2, ÏÎ¸_uÎ¸_Î½, ÏÎ¸_uÎ¸_Î½, and [BLANK].",
    "gold_answer": "Î¸_Î½^2. The blank is filled with 'Î¸_Î½^2' to complete the specification of the varianceâ€“covariance matrix Î“, quantifying the heterogeneity in the unobserved random effects for the hazard rate of death.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¸_Î½^2",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¸_Î½^2\"\n}",
      "model_answer": "Î¸_Î½^2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2565",
    "folder": "",
    "question": "In the context of forensic science, the likelihood ratio (LR) is used to evaluate the strength of evidence under two mutually exclusive hypotheses: contact (C) and no contact (Â¬C). The general expression for LR, considering all possible partitions of evidence E into transferred (ETi) and background (EBi) material, is given by LR = [BLANK]. This formula accounts for the probabilities of transferred material under both hypotheses and the background material's distribution.",
    "gold_answer": "âˆ‘(i=1 to N) [p(ETi|C)p(yTi|ETiCx)pÏ(EBiyBi)] / âˆ‘(i=1 to N) [p(ETi|Â¬C)p(yTi|ETiÂ¬C)pÏ(EBiyBi)]. This expression is derived to comprehensively evaluate the evidence by considering all possible ways the evidence could be partitioned into transferred and background material, under both hypotheses of contact and no contact.",
    "source": [
      "A Quantitative Theory for Interpreting Transfer Ev.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_33_Issue_1\\A Quantitative Theory for Interpreting Transfer Ev\\A Quantitative Theory for Interpreting Transfer Ev.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "âˆ‘(i=1 to N) [p(ETi|C)p(yTi|ETiCx)pÏ(EBiyBi)] / âˆ‘(i=1 to N) [p(ETi|Â¬C)p(yTi|ETiÂ¬C)pÏ(EBiyBi)]",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"âˆ‘i P(ETi|C)P(EBi)/âˆ‘i P(ETi|Â¬C)P(EBi)\"\n}",
      "model_answer": "âˆ‘i P(ETi|C)P(EBi)/âˆ‘i P(ETi|Â¬C)P(EBi)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-762",
    "folder": "",
    "question": "Patterson and Thompson (1971) propose the [BLANK] estimation to estimate variance components in the context of an unbalanced incomplete-block design.",
    "gold_answer": "residual maximum likelihood (REML). REML is preferred for estimating covariance parameters in linear models due to its consideration of the loss of degrees of freedom in estimating the mean.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "residual maximum likelihood (REML)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"REML\"\n}",
      "model_answer": "REML",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2650",
    "folder": "",
    "question": "The paper proposes a new approach to evaluate the effect of the guidance strategy on the predictability of monetary policy, based on jump probabilities of Norwegian interest rates on announcement days of the Norges Bank before and after the introduction of [BLANK].",
    "gold_answer": "quantitative guidance. This is the key change in the Norges Bank's strategy that the paper investigates to assess its impact on monetary policy predictability.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_65_Issue_2\\Forward Guidance and the Predictability of Monetar\\Forward Guidance and the Predictability of Monetar.md",
      "Forward Guidance and the Predictability of Monetar.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "quantitative guidance",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"forward guidance\"\n}",
      "model_answer": "forward guidance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-191",
    "folder": "",
    "question": "In the study of human skull variation and correlation, the system of measurement used for most skulls was in accordance with the [BLANK], so far as the condition of the material allowed.",
    "gold_answer": "Frankfurter Verstandigung",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Frankfurter Verstandigung",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Frankfort convention\"\n}",
      "model_answer": "Frankfort convention",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-5",
    "folder": "",
    "question": "In the context of hereditary entropion and changes in the skin of the eyelids, the condition where the skin of the upper lids is very thin, has lost elasticity, and resembles crinkled cigarette paper is referred to as [BLANK].",
    "gold_answer": "blepharochalasis. This term is used to describe the specific condition of the eyelids where the skin becomes thin, loses elasticity, and forms fine wrinkles, resembling crinkled cigarette paper, as described by Fuchs in 1896.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_24_Issue_1-2\\HEREDITARY_ENTROPION_AND_HEREDITARY_CHANGES_IN_THE_SKIN_OF_THE_EYELIDS\\HEREDITARY_ENTROPION_AND_HEREDITARY_CHANGES_IN_THE_SKIN_OF_THE_EYELIDS.md",
      "HEREDITARY_ENTROPION_AND_HEREDITARY_CHANGES_IN_THE_SKIN_OF_THE_EYELIDS.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "blepharochalasis",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"blepharochalasis\"\n}",
      "model_answer": "blepharochalasis",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-996",
    "folder": "",
    "question": "In selection modeling, the likelihood can be factorized into a product of the outcome model and the missingness mechanism, expressed as f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK], where Ráµ¢ denotes the missingness indicators. Which missingness-related term is deliberately omitted in this equation?",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). This term is omitted to highlight that, in a selection framework, the distribution of the missingness (Ráµ¢) may depend on the observed and unobserved outcomes (Yáµ¢), distinguishing selection models from patternâ€“mixture approaches.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_11\\Issue_2\\Risk_Estimation_for_Classification_Trees__Risk_Estimation_for_Classification_Trees\\Risk_Estimation_for_Classification_Trees__Risk_Estimation_for_Classification_Trees.md",
      "Risk_Estimation_for_Classification_Trees__Risk_Estimation_for_Classification_Trees.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1925",
    "folder": "",
    "question": "In the proposed copula-based semiparametric transformation model for bivariate data under general interval censoring, the joint likelihood is modeled through a two-parameter [BLANK], which can flexibly characterize the dependence between the two margins in both tails.",
    "gold_answer": "Archimedean copula. This is specified to highlight the flexibility of the two-parameter Archimedean copula in modeling dependence structures in both upper and lower tails of the distribution.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Archimedean copula",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"copula\"\n}",
      "model_answer": "copula",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2109",
    "folder": "",
    "question": "The robust differential abundance test is designed to be simple, computationally efficient, robust to prevalent zero counts, account for the compositional nature of the data, and have a theoretical guarantee of controlling false discoveries in a general setting. One critical element omitted in this description is [BLANK].",
    "gold_answer": "the ability to work with covariate-balancing techniques to remove potential confounding effects. This element is crucial for drawing reliable conclusions in the presence of observed covariates.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_110_Issue_1\\Robust_differential_abundance_test_in_compositional_data\\Robust_differential_abundance_test_in_compositional_data.md",
      "Robust_differential_abundance_test_in_compositional_data.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the ability to work with covariate-balancing techniques to remove potential confounding effects",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the ability to handle unbalanced sample sizes\"\n}",
      "model_answer": "the ability to handle unbalanced sample sizes",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-907",
    "folder": "",
    "question": "In the context of Bayesian hierarchical models, the joint posterior for (x, Î¸) can have a complex dependence structure, especially when the scale of x|Î¸, y varies substantially as a function of Î¸ in high-density regions of p(Î¸|y), leading to a [BLANK]-shaped joint posterior.",
    "gold_answer": "funnel. This shape complicates the exploration of the full target distribution and necessitates careful tuning of the HMC algorithm.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "funnel",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"banana\"\n}",
      "model_answer": "banana",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-524",
    "folder": "",
    "question": "The iterative convex minorant (ICM) algorithm proposed by Groeneboom and Wellner is fast in computing the NPMLE of the distribution function for interval censored data without covariates. We reformulate the ICM as a [BLANK], which leads to a natural extension to the Cox model.",
    "gold_answer": "generalized gradient projection method (GGP). This reformulation allows the ICM to be extended to the Cox model by treating it as a special case of the GGP, facilitating its application to more complex models.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_8\\Issue_1\\Extending_the_Iterative_Convex_Minorant_Algorithm_to_the_Cox_Model_for_Interval-Censored_Data__Extending_the_Iterative_Convex_Minorant_Algorithm_to_the_Cox_Model_for_Interval-Censored_Data\\Extending_the_Iterative_Convex_Minorant_Algorithm_to_the_Cox_Model_for_Interval-Censored_Data__Extending_the_Iterative_Convex_Minorant_Algorithm_to_the_Cox_Model_for_Interval-Censored_Data.md",
      "Extending_the_Iterative_Convex_Minorant_Algorithm_to_the_Cox_Model_for_Interval-Censored_Data__Extending_the_Iterative_Convex_Minorant_Algorithm_to_the_Cox_Model_for_Interval-Censored_Data.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "generalized gradient projection method (GGP)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"gradient projection algorithm\"\n}",
      "model_answer": "gradient projection algorithm",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2842",
    "folder": "",
    "question": "A well-known procedure for testing for serial correlation is to plot out the sample path of the cumulated periodogram and to compare the resulting graph with the [BLANK] limits.",
    "gold_answer": "Kolmogorov-Smirnov. This is a standard method for assessing the goodness of fit between the empirical distribution of the sample and the expected distribution under the null hypothesis of serial independence.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Kolmogorov-Smirnov",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"confidence\"\n}",
      "model_answer": "confidence",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-140",
    "folder": "",
    "question": "Bivariate extreme value distributions arise as the limiting distributions of renormalized componentwise maxima. No natural parametric family exists for the dependence between the marginal distributions, but there are considerable restrictions on the dependence structure. We consider modelling the dependence function with parametric models, for which two new models are presented. Tests for independence, and discriminating between models, are also given. The estimation procedure, and the fexibility of the new models, are illustrated with an application to [BLANK] data.",
    "gold_answer": "sea level. This blank is filled to specify the type of data used to illustrate the estimation procedure and the flexibility of the new models in the context of bivariate extreme value theory.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "sea level",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"air pollution\"\n}",
      "model_answer": "air pollution",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2075",
    "folder": "",
    "question": "The Generalized Tukey Lambda (GTL) distribution is defined by its link function G given by Îµ = G(u; Î±, Î´) = (u^(Î±âˆ’Î´) âˆ’ 1)/(Î±âˆ’Î´) âˆ’ ((1âˆ’u)^(Î±+Î´) âˆ’ 1)/(Î±+Î´), where u âˆˆ [0,1]. When Î±âˆ’Î´ = 0, the first term is replaced with [BLANK] according to lâ€™HÃ´pitalâ€™s Rule.",
    "gold_answer": "ln u",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ln u",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ln(u)\"\n}",
      "model_answer": "ln(u)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1139",
    "folder": "",
    "question": "In the context of analyzing the range of samples from a normal population, the mean range for a sample size n is given by the integral from negative infinity to positive infinity of {1 - (1 - Î±)^n - Î±^n} dÎ±. For a sample size of n=10, the mean range is approximately [BLANK] in terms of the standard deviation of the original population.",
    "gold_answer": "3.07751. This value is derived from the integral expression provided, representing the expected range for samples of size 10 from a normal population with unit standard deviation.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_17_Issue_3-4\\ON_THE_EXTREME_INDIVIDUALS_AND_THE_RANGE_OF_SAMPLES_TAKEN_FROM_A_NORMAL_POPULATION\\ON_THE_EXTREME_INDIVIDUALS_AND_THE_RANGE_OF_SAMPLES_TAKEN_FROM_A_NORMAL_POPULATION.md",
      "ON_THE_EXTREME_INDIVIDUALS_AND_THE_RANGE_OF_SAMPLES_TAKEN_FROM_A_NORMAL_POPULATION.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "3",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"3.078\"\n}",
      "model_answer": "3.078",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2837",
    "folder": "",
    "question": "In the context of kernel density estimation for circular data, the von Mises distribution is often used as a kernel function. The estimator can be written as \\(\\hat{f}(\\theta;\\nu)=\\frac{1}{n(2\\pi)I_{0}(\\nu)}\\sum_{i=1}^{n}\\exp\\{\\nu\\cos(\\theta-\\theta_{i})\\},\\) where \\(I_{r}(\\nu)\\) is the modified Bessel function of order \\(r\\), and \\(\\nu\\) is the concentration parameter. The optimal choice of \\(\\nu\\) can be derived by minimizing the asymptotic mean integrated squared error (AMISE), leading to a plug-in rule that depends on the concentration parameter of the data \\((\\kappa)\\) and the sample size \\((n)\\). This plug-in rule is given by \\(\\nu=\\left[3n\\hat{\\kappa}^{2}I_{2}(2\\hat{\\kappa})\\{4\\pi^{1/2}I_{0}(\\hat{\\kappa})^{2}\\}^{-1}\\right]^{[BLANK]}.\\). What exponent completes the plug-in rule for the smoothing parameter \\(\\nu\\)?",
    "gold_answer": "2/5. This exponent is derived from the optimization of the asymptotic mean integrated squared error (AMISE), balancing the bias and variance of the kernel density estimator for circular data.",
    "source": [
      "Automatic-bandwidth-selection-for-circular-_2008_C.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2008\\ScienceDirect_articles_04Mar2025_14-42-02.830\\Automatic-bandwidth-selection-for-circular-_2008_C\\Automatic-bandwidth-selection-for-circular-_2008_C.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "2/5",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1/5\"\n}",
      "model_answer": "1/5",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1547",
    "folder": "",
    "question": "In the context of bivariate binomial autoregressive models, the bivariate binomial distribution of Type II is abbreviated as [BLANK].",
    "gold_answer": "BVBII. This abbreviation is used to succinctly refer to the bivariate binomial distribution of Type II, which is central to the development of the models discussed.",
    "source": [
      "Bivariate-binomial-autoregressive-model_2014_Journ.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2014\\ScienceDirect_articles_01Mar2025_03-29-34.824\\Bivariate-binomial-autoregressive-model_2014_Journ\\Bivariate-binomial-autoregressive-model_2014_Journ.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "BVBII",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"BVBII\"\n}",
      "model_answer": "BVBII",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-358",
    "folder": "",
    "question": "In the context of categorical judgment data, the Successive Intervals model postulates that subjects' opinions of each stimulus are normally distributed over some opinion scale T', which can be expressed as F_i(T') = Î¦{b'_i(T' - a'_i)} for i = 1, 2, ..., s, where Î¦ is the standard normal distribution function. The categories for this scale are given by arbitrary intervals. What is the standard deviation of the opinion distributions on the T' scale?",
    "gold_answer": "1/b'_i. This is excluded to highlight that the standard deviation of the opinion distributions is inversely related to the scale parameter b'_i, which is a key aspect of the model's structure.",
    "source": [
      "A Comparison of Gaussian and Logistic Categorical.md",
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_24_Issue_1\\A Comparison of Gaussian and Logistic Categorical\\A Comparison of Gaussian and Logistic Categorical.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1/b'_i",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1/b'_i\"\n}",
      "model_answer": "1/b'_i",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1268",
    "folder": "",
    "question": "The varying-coefficient single-index models (VCSIMs) form a class of very flexible and general dimension reduction models, which contain many important regression models such as partially linear models, pure single-index models, partially linear single-index models, varying-coefficient models and so on as special examples. However, the testing problems of the index parameter of the VCSIM have not been very well developed, due partially to the complexity of the models. To this end, based on the estimators obtained by the local linear method and the backfitting technique, we propose the generalized [BLANK] test method to deal with the testing problems of the index parameters of the VCSIM.",
    "gold_answer": "F-type. The generalized F-type test method is proposed to handle the testing problems of the index parameters in VCSIMs, leveraging estimators from the local linear method and backfitting technique.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2013\\ScienceDirect_articles_04Mar2025_11-09-57.547\\Testing-the-significance-of-index-parameters-in-_2\\Testing-the-significance-of-index-parameters-in-_2.md",
      "Testing-the-significance-of-index-parameters-in-_2.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "F-type",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"F\"\n}",
      "model_answer": "F",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1737",
    "folder": "",
    "question": "In the LSRE model, the data are modeled as $X_{i j}=\\mu_{i}+\\sigma_{i}\\epsilon_{i j}$, where $\\epsilon_{i j}$ are i.i.d. with mean 0 and variance 1. The key assumption that allows for the identification of the error distribution $F$ when $n\\geq4$ is that the characteristic functions of $\\log\\sigma_{i}$, $\\epsilon_{i1}$, and $\\log|\\epsilon_{i1}-\\epsilon_{i2}|$ have [BLANK]. What property must these characteristic functions satisfy?",
    "gold_answer": "countably many zeroes. This assumption is crucial for the identifiability of the error distribution $F$ in the LSRE model, ensuring that the distributions of the components can be distinguished based on the observed data.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_20\\Issue_2\\Nonparametric_Estimation_of_Distributions_in_Random_Effects_Models__Nonparametric_Estimation_of_Distributions_in_Random_Effects_Models\\Nonparametric_Estimation_of_Distributions_in_Random_Effects_Models__Nonparametric_Estimation_of_Distributions_in_Random_Effects_Models.md",
      "Nonparametric_Estimation_of_Distributions_in_Random_Effects_Models__Nonparametric_Estimation_of_Distributions_in_Random_Effects_Models.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "countably many zeroes",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"no real zeros\"\n}",
      "model_answer": "no real zeros",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2594",
    "folder": "",
    "question": "A method to jointly analyze both ordinal outcomes and their missingness is to factorize the likelihood into a product of the outcome model and the [BLANK].",
    "gold_answer": "missingness mechanism. This factorization is a fundamental approach in selection modeling to handle missing data in statistical analyses.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "missingness mechanism",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing data model\"\n}",
      "model_answer": "missing data model",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2470",
    "folder": "",
    "question": "In the context of functional data analysis, the covariance function Î³(s,t) can be expressed as a sum of eigenvalues Î»j and eigenfunctions Ï†j(s)Ï†j(t), where the eigenvalues are ordered as [BLANK].",
    "gold_answer": "Î»1 â‰¥ Î»2 â‰¥ ... â‰¥ 0. This ordering is crucial for identifying the principal modes of variation in the data, with Î»1 representing the largest variance explained by the first principal component.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î»1 â‰¥ Î»2 â‰¥",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»1 â‰¥ Î»2 â‰¥ ... â‰¥ 0\"\n}",
      "model_answer": "Î»1 â‰¥ Î»2 â‰¥ ... â‰¥ 0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-597",
    "folder": "",
    "question": "In the context of robust regression using iteratively reweighted least squares (IRLS), the weight function wt.bisquare is defined for a given residual u and tuning constant c as [BLANK]. What is the correct expression for the wt.bisquare function?",
    "gold_answer": "w(u) = (1 - (u/c)^2)^2 for 0 < |u/c| â‰¤ 1, and 0 otherwise. This expression is crucial for understanding how the bisquare weight function downweights outliers in robust regression.",
    "source": [
      "Design_of_an_S_Function_for_Robust_Regression_Using_Iteratively_Reweighted_Least_Squares__Design_of_an_S_Function_for_Robust_Regression_Using_Iteratively_Reweighted_Least_Squares.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_1\\Issue_3\\Design_of_an_S_Function_for_Robust_Regression_Using_Iteratively_Reweighted_Least_Squares__Design_of_an_S_Function_for_Robust_Regression_Using_Iteratively_Reweighted_Least_Squares\\Design_of_an_S_Function_for_Robust_Regression_Using_Iteratively_Reweighted_Least_Squares__Design_of_an_S_Function_for_Robust_Regression_Using_Iteratively_Reweighted_Least_Squares.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "w(u) = (1 - (u/c)^2)^2 for 0 < |u/c| â‰¤ 1, and 0 otherwise",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"(1-(u/c)^2)^2 if |u|<=c, 0 if |u|>c\"\n}",
      "model_answer": "(1-(u/c)^2)^2 if |u|<=c, 0 if |u|>c",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2683",
    "folder": "",
    "question": "In the trichotomous framework for analyzing high-dimensional data, the signal subset includes only strong signals that stand outside the range of noise, the noise subset includes only noise, and the third subset, where relatively weak signals mix indistinguishably with noise, is called the [BLANK] subset.",
    "gold_answer": "mixed/indistinguishable. This term is used to describe the subset where weak signals are not easily distinguishable from noise, highlighting the challenge in identifying these signals amidst high-dimensional data.",
    "source": [
      "Detecting-weak-signals-in-high-dimension_2016_Jour.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2016\\ScienceDirect_articles_28Feb2025_08-52-52.356\\Detecting-weak-signals-in-high-dimension_2016_Jour\\Detecting-weak-signals-in-high-dimension_2016_Jour.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "mixed/indistinguishable",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"gray\"\n}",
      "model_answer": "gray",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-563",
    "folder": "",
    "question": "A key assumption in likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process is known as [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption simplifies the analysis by allowing the missingness to depend only on observed data, not on unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1387",
    "folder": "",
    "question": "The de la VallÃ©e Poussin kernel Ïˆ_Îº^VP is a nonnegative kernel function on SO(3) defined for any Îº âˆˆ â„•âˆ–{0} by its finite Chebyshev expansion, and it yields the optimal convergence rate of [BLANK] for the class F_2,S^2.",
    "gold_answer": "N^(-4/7). The de la VallÃ©e Poussin kernel achieves this optimal rate, demonstrating its efficiency in kernel density estimation for functions with bounded Sobolev norm of order 2.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "N^(-4/7)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"O(Îº^{-2})\"\n}",
      "model_answer": "O(Îº^{-2})",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1706",
    "folder": "",
    "question": "In the variational Bayes algorithm for Ising model parameter estimation, the pseudo-likelihood is used instead of the true likelihood due to the intractable nature of the [BLANK] in the likelihood.",
    "gold_answer": "normalizing constant. The normalizing constant is intractable in the Ising model likelihood, making direct computation infeasible, hence the use of pseudo-likelihood for estimation.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_33\\Issue_1\\Statistically_Valid_Variational_Bayes_Algorithm_for_Ising_Model_Parameter_Estimation__Statistically_Valid_Variational_Bayes_Algorithm_for_Ising_Model_Parameter_Estimation\\Statistically_Valid_Variational_Bayes_Algorithm_for_Ising_Model_Parameter_Estimation__Statistically_Valid_Variational_Bayes_Algorithm_for_Ising_Model_Parameter_Estimation.md",
      "Statistically_Valid_Variational_Bayes_Algorithm_for_Ising_Model_Parameter_Estimation__Statistically_Valid_Variational_Bayes_Algorithm_for_Ising_Model_Parameter_Estimation.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "normalizing constant",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"partition function\"\n}",
      "model_answer": "partition function",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1809",
    "folder": "",
    "question": "In the algorithm for calculating the digamma function, if the argument Y is less than or equal to a certain threshold S, the function approximates DIGAMA as [BLANK]. What is the formula used in this approximation?",
    "gold_answer": "D1 - 1.0 / Y. This formula is used when the argument Y is less than or equal to the threshold S, providing a quick approximation for the digamma function under these conditions.",
    "source": [
      "Blus Residuals.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_25_Issue_3\\Blus Residuals\\Blus Residuals.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "D1 - 1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"-1/Y - GAMMA\"\n}",
      "model_answer": "-1/Y - GAMMA",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2228",
    "folder": "",
    "question": "The mean residual life (MRL) of a nonnegative random variable $X$ at age t is defined as $M(t)=E(X-t|X>t)=\\frac{\\int_{t}^{\\infty}S(x)d x}{S(t)}$, where $S(t)$ is the [BLANK] function.",
    "gold_answer": "survival. The survival function $S(t)=P(X>t)$ gives the probability that the variable exceeds a certain value t, which is crucial for calculating the mean residual life.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "survival",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"survival\"\n}",
      "model_answer": "survival",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-927",
    "folder": "",
    "question": "In the context of testing the equality of two survival distributions using the modified Savage statistic, the null hypothesis $H_{0}$ states that $F_{1}=F_{2}=F$, where $F$ is an unknown continuous cumulative distribution function. The test is against either the one-sided alternative $H_{1}: F_{1}>F_{2}$ or the two-sided alternative $H_{1}: F_{1}\\neq F_{2}$. The Savage statistic, $\\mathcal{S}_{N}$, for testing $H_{0}$ is defined as $\\mathcal{S}_{N}=\\sum_{i=1}^{m}b_{N}(\\mathcal{R}_{Ni})-m=\\sum_{i=1}^{N}d_{i}\\{b_{N}(i)-1\\}$, where $b_{N}(i)$ is the expected value of the ith order statistic in a random sample of size $N$ from the exponential distribution. Under $H_{0}$, the expected value of $\\mathcal{S}_{N}$ is [BLANK].",
    "gold_answer": "0. This is because, under the null hypothesis, the Savage statistic is centered around zero, reflecting no difference between the two survival distributions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_65_Issue_3\\Sequential_testing_of_the_equality_of_two_survival_distributions_using_the_modified_Savage_statistic\\Sequential_testing_of_the_equality_of_two_survival_distributions_using_the_modified_Savage_statistic.md",
      "Sequential_testing_of_the_equality_of_two_survival_distributions_using_the_modified_Savage_statistic.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0\"\n}",
      "model_answer": "0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3277",
    "folder": "",
    "question": "The unscented Kalman smoother algorithm first implements a forward unscented Kalman filter and then evokes a separate backward smoothing pass by only making Gaussian approximations in the state but not in the [BLANK] space.",
    "gold_answer": "observation. This highlights the algorithm's focus on maintaining accuracy in the state space while simplifying the observation space processing.",
    "source": [
      "An-unscented-Kalman-smoother-for-volatility-extrac.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2013\\ScienceDirect_articles_04Mar2025_11-09-09.990\\An-unscented-Kalman-smoother-for-volatility-extrac\\An-unscented-Kalman-smoother-for-volatility-extrac.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "observation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"measurement\"\n}",
      "model_answer": "measurement",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1869",
    "folder": "",
    "question": "The hug and hop Markov chain Monte Carlo algorithm alternates between two kernels, referred to as hug and hop. Hug is a nonreversible kernel that repeatedly applies the bounce mechanism from the recently proposed bouncy particle sampler to produce a proposal point that is far from the current position yet on almost the same contour of the target density, leading to a high acceptance probability. Hop complements hug by deliberately proposing jumps between contours and has an efficiency that degrades very slowly with increasing dimension. The reflection operator used in the hug kernel is given by [BLANK]. What is the correct formula for the reflection operator?",
    "gold_answer": "The reflection operator used in the hug kernel is given by R(Î½;g) = Î½ - 2(Î½áµ€Ä)Ä, where Ä = g/||g|| is the unit gradient vector. This formula is crucial for the hug kernel as it ensures the proposed moves remain on nearly the same contour of the target density, facilitating high acceptance probabilities.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_110_Issue_2\\Hug_and_hop_a_discrete-time,_nonreversible_Markov_chain_Monte_Carlo_algorithm\\Hug_and_hop_a_discrete-time,_nonreversible_Markov_chain_Monte_Carlo_algorithm.md",
      "Hug_and_hop_a_discrete-time,_nonreversible_Markov_chain_Monte_Carlo_algorithm.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The reflection operator used in the hug kernel is given by R(Î½;g) = Î½ - 2(Î½áµ€Ä)Ä, where Ä = g/||g|| is the unit gradient vector",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"R(x,v) = v - 2(v^T n(x))n(x)\"\n}",
      "model_answer": "R(x,v) = v - 2(v^T n(x))n(x)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1259",
    "folder": "",
    "question": "In a logistic random intercept model where no distributional assumption is made on the random intercept, the estimator developed using semiparametric methods is guaranteed to be [BLANK].",
    "gold_answer": "consistent. This highlights the robustness of the estimator against misspecification of the random intercept distribution.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2016_Volume_43_Issue_1\\Scandinavian J Statistics - 2015 - Garcia - Optima\\Scandinavian J Statistics - 2015 - Garcia - Optima.md",
      "Scandinavian J Statistics - 2015 - Garcia - Optima.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "consistent",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"consistent\"\n}",
      "model_answer": "consistent",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-364",
    "folder": "",
    "question": "In the context of anticoagulant control, the international normalized ratio (INR) is a standardized measure of blood clotting speed, where a healthy population averages an INR of [BLANK], but patients on anticoagulants aim for a higher INR to reduce thrombosis risk.",
    "gold_answer": "1. The blank is filled with '1' to indicate the average INR in a healthy population, which is the baseline against which anticoagulant effects are measured.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1.0\"\n}",
      "model_answer": "1.0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2864",
    "folder": "",
    "question": "The ROC surface is a generalization of the ROC curve which is intended to accommodate the problems of [BLANK] classification.",
    "gold_answer": "three-class. This is highlighted to emphasize the ROC surface's application in scenarios where diagnostic tests categorize subjects into three distinct groups.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "three-class",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"multi-class\"\n}",
      "model_answer": "multi-class",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-831",
    "folder": "",
    "question": "One method to analyze both ordinal outcomes and their missingness in longitudinal clinical studies is to factorize the likelihood into a product of the outcome model and the missingness mechanism, expressed as f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK].",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). This term is crucial in selection modeling as it accounts for the dependency of missingness on observed and unobserved outcomes.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-883",
    "folder": "",
    "question": "The N-parameter Wiener process on R_{+}^{N} is defined by several properties, including that for any points s and t in R_{+}^{N}, the expected value E[X(s)X(t)] is equal to [BLANK].",
    "gold_answer": "the product of the minima of their corresponding components (min(sâ‚, tâ‚) * ... * min(s_N, t_N). This is excluded to highlight the specific covariance structure that defines the multiparameter Wiener process, distinguishing it from other types of stochastic processes.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1973\\ScienceDirect_articles_02Mar2025_09-17-16.040\\Laws-of-iterated-logarithm-of-multiparameter-w_197\\Laws-of-iterated-logarithm-of-multiparameter-w_197.md",
      "Laws-of-iterated-logarithm-of-multiparameter-w_197.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the product of the minima of their corresponding components (min(sâ‚, tâ‚) *",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"min(s,t)\"\n}",
      "model_answer": "min(s,t)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-904",
    "folder": "",
    "question": "In the context of Brownian motion, Hincin's law of the iterated logarithm states that for a real-valued Brownian motion with continuous sample paths, the probability that the limit superior of B(t)/(2t log log t)^(1/2) as t approaches infinity equals 1 is [BLANK].",
    "gold_answer": "1. This is the core result of Hincin's law, indicating that the maximum fluctuation of Brownian motion paths is almost surely bounded by the function (2t log log t)^(1/2).",
    "source": [
      "A-note-on-some-laws-of-the-iterated-logar_1975_Jou.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1975\\ScienceDirect_articles_02Mar2025_09-14-36.069\\A-note-on-some-laws-of-the-iterated-logar_1975_Jou\\A-note-on-some-laws-of-the-iterated-logar_1975_Jou.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2784",
    "folder": "",
    "question": "Ferebeeâ€™s method for constructing an unbiased estimator of the drift $\\theta$ in a group sequential test results in an estimator that agrees with the truncation-adaptable unbiased estimator $\\hat{\\theta}^{*}$. Ferebeeâ€™s estimator is given by $\\widehat{\\theta}_{F}(k,x)=[BLANK]$.",
    "gold_answer": "$\\frac{\\partial}{\\partial u}\\log p_{0}(k,x|u)|_{u=0}$. This expression defines Ferebeeâ€™s estimator, highlighting its dependence on the derivative of the log density of the sufficient statistic under the null hypothesis.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\frac{\\partial}{\\partial u}\\log p_{0}(k,x|u)|_{u=0}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"x/k\"\n}",
      "model_answer": "x/k",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1406",
    "folder": "",
    "question": "In graded matching for large observational studies, the network is made sparse by grading potential pairings into different grades, with a preference for higher grade pairings. The method aims to match with pairs of the best grade, incorporating progressively lower grade pairs only to the degree they are needed. This approach is implemented in an R package called [BLANK].",
    "gold_answer": "RBestMatch. This package is designed to facilitate graded matching by optimizing the use of higher grade pairings before considering lower grades, thereby making large-scale matching computationally feasible.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_31\\Issue_4\\Graded_Matching_for_Large_Observational_Studies__Graded_Matching_for_Large_Observational_Studies\\Graded_Matching_for_Large_Observational_Studies__Graded_Matching_for_Large_Observational_Studies.md",
      "Graded_Matching_for_Large_Observational_Studies__Graded_Matching_for_Large_Observational_Studies.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "RBestMatch",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"rcbalance\"\n}",
      "model_answer": "rcbalance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2556",
    "folder": "",
    "question": "The functional tangential angle pseudo-depth (FUNTA) is defined for a sample of real centred differentiable functions. The FUNTA pseudo-depth of a function $\tilde{x}(t)$ with respect to the sample is given by $\\mathrm{FUNTA}_{n}(\\tilde{x}) = 1 - (m\\pi)^{-1}\\sum_{i=1}^{n}\\sum_{k=1}^{m_{i}}\\gamma_{k}(\\tilde{x}(s_{i,k}),x_{i}(s_{i,k}))$. What does $\\gamma_{k}$ represent in this equation?",
    "gold_answer": "The geometric angle (in radiant measure) of the tangent to $\\tilde{x}(s_{i,k})$ with the tangent to $x_{i}(s_{i,k})$. It is the intersection angle between the function $\\tilde{x}$ and the sample function $x_{i}$ at their $k$-th intersection point $s_{i,k}$.",
    "source": [
      "An-angle-based-multivariate-functional-pseudo-dept.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2016\\ScienceDirect_articles_28Feb2025_08-54-00.030\\An-angle-based-multivariate-functional-pseudo-dept\\An-angle-based-multivariate-functional-pseudo-dept.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The geometric angle (in radiant measure) of the tangent to $\\tilde{x}(s_{i,k})$ with the tangent to $x_{i}(s_{i,k})$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the angle between the tangent lines of the function xÌƒ(t) and the sample function x_i(t) at point s_{i,k}\"\n}",
      "model_answer": "the angle between the tangent lines of the function xÌƒ(t) and the sample function x_i(t) at point s_{i,k}",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1063",
    "folder": "",
    "question": "In the simulation study, the true MSPE of the PEB estimator is calculated as TMSPE(Î³Ì‚iwPEB)=1Râˆ‘r=1R{Î³Ì‚iwPEB(r)âˆ’Î³i(r)}2. What does [BLANK] represent in this formula?",
    "gold_answer": "R. This is the number of independent simulation runs used to estimate the true mean squared prediction error, ensuring the reliability of the simulation results.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "R",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"r\"\n}",
      "model_answer": "r",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2865",
    "folder": "",
    "question": "A key assumption in the Bayesian approach for estimating the ROC surface under verification bias is that the probability of a subject being verified does not depend on the disease status given the observed measurements, known as the [BLANK] assumption.",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the method's validity, allowing for the analysis without explicitly modeling the missing data mechanism.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"MAR\"\n}",
      "model_answer": "MAR",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2048",
    "folder": "",
    "question": "For the multivariate t distribution, the prior for the location vector and the scale matrix is chosen to be minimally informative, specifically using the [BLANK] prior.",
    "gold_answer": "independence-Jeffreys. This prior is selected for its property of reflecting minimal prior information, making it suitable for objective Bayesian analysis.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "independence-Jeffreys",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Jeffreys\"\n}",
      "model_answer": "Jeffreys",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2336",
    "folder": "",
    "question": "In permutation-based linkages for hierarchical clustering, the similarity between two classes is computed by comparing observed similarities with those obtained from [BLANK] permutations of the data.",
    "gold_answer": "random. This method helps in assessing the significance of the observed similarities under the null hypothesis of independence.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "random",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"random\"\n}",
      "model_answer": "random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-348",
    "folder": "",
    "question": "In the model for analyzing paired comparison experiments, the difference in responses between two samples is given by Y_{isk} = Ï„_i - Ï„_s + (Ï†_1 - Ï†_2) + (Î±_{i1} - Î±_{s2}) + (Ïˆ_{i1k} - Ïˆ_{s2k}). Here, Ï†_1 - Ï†_2 can be represented by [BLANK], highlighting the order effect.",
    "gold_answer": "Ï†. This simplification is made to represent the order effect concisely in the model, emphasizing its role in the difference between responses.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_26_Issue_2\\The Analysis of an Unbalanced Paired Comparison Ex\\The Analysis of an Unbalanced Paired Comparison Ex.md",
      "The Analysis of an Unbalanced Paired Comparison Ex.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï†",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï\"\n}",
      "model_answer": "Ï",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3253",
    "folder": "",
    "question": "In the hierarchical Bayes approach to meta-analysis of microarray studies, the model uses an informative prior for the parameter of interest to aid the detection of differentially expressed genes. The parameter of interest is denoted by [BLANK].",
    "gold_answer": "Î³_g. This parameter represents the differential expression of gene g across all studies, with values close to zero indicating no differential expression and values far from zero indicating significant differential expression.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_16_Issue_4\\Meta-analysis of incomplete microarray studies\\Meta-analysis of incomplete microarray studies.md",
      "Meta-analysis of incomplete microarray studies.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î³_g",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¼\"\n}",
      "model_answer": "Î¼",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2074",
    "folder": "",
    "question": "In the context of linear random fields, the Beveridgeâ€“Nelson decomposition can be expressed as $\\phi(\\mathbf{L}) = \\mu_1 + A_2(\\mathbf{L}) - A_1(\\mathbf{L})$, where $\\mu_1$ represents the sum of the coefficients $\\varphi_{k,l}$. What is the condition required for $\\sum_{k,l\\ge0}|\\varphi_{k,l}^{*}|^{p}<\\infty$ to hold, where $\\varphi_{k,l}^{*} = \\sum_{i\\geq k+1,j\\geq l+1}\\varphi_{i,j}$?",
    "gold_answer": "The condition required is either $\\mathcal{L}_{p}$ for $1 \\leq p < \\infty$ or $\\mathcal{L}_{1,p}$ for $0 < p < 1$. This ensures the convergence of the series $\\sum_{k,l\\ge0}|\\varphi_{k,l}^{*}|^{p}$, highlighting the interplay between the moment conditions for innovations and the conditions on the coefficients $\\varphi_{k,l}$.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2010\\ScienceDirect_articles_01Mar2025_03-53-52.651\\On-Beveridge-Nelson-decomposition-and-limit-theore\\On-Beveridge-Nelson-decomposition-and-limit-theore.md",
      "On-Beveridge-Nelson-decomposition-and-limit-theore.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The condition required is either $\\mathcal{L}_{p}$ for $1 \\leq p < \\infty$ or $\\mathcal{L}_{1,p}$ for $0 < p < 1$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"p > 1\"\n}",
      "model_answer": "p > 1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3414",
    "folder": "",
    "question": "In the analysis of survival times for patients not permanently cured of cancer, the distribution of survival times is found to be skew and can be made approximately normal by applying a [BLANK] transformation.",
    "gold_answer": "logarithmic. This transformation is used because the skew distributions of survival times can be closely approximated by a lognormal distribution, making the data more amenable to statistical analysis.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "logarithmic",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"logarithmic\"\n}",
      "model_answer": "logarithmic",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-721",
    "folder": "",
    "question": "A worst-case estimator for econometric models containing unobservable components, based on minimax principles for optimal selection of parameters, is proposed. This estimator is robust against the averse effects of unobservables and involves solving a [BLANK] problem.",
    "gold_answer": "minimax continuous. The blank is filled to highlight the nature of the problem that needs to be solved to compute the worst-case estimators, emphasizing the challenge in their computation.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "minimax continuous",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"min-max\"\n}",
      "model_answer": "min-max",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-141",
    "folder": "",
    "question": "The class of bivariate exponential distributions in which we are interested, satisfy a strong stability relation. Exponential variables $(X,Y)$ satisfy the stability relation if and only if $W=\\operatorname*{min}{(a X,b Y)}$ is also exponentially distributed for all $a,b>0$ (Pickands, 1981). Therefore, the models we will consider have particular application in reliability and [BLANK] analysis.",
    "gold_answer": "survival. The blank is filled to indicate the field where the models discussed have particular applications, highlighting their relevance beyond theoretical statistics.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "survival",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"extreme value\"\n}",
      "model_answer": "extreme value",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1469",
    "folder": "",
    "question": "In the context of estimating the mean vector from mutually independent observations, the classic conjugate hierarchical model assumes that for each i, Î¸i âˆ¼ N(Î¼, Î»), where Î» is a hyper-parameter. The joint prior on Î¸â‚, ..., Î¸â‚š is given by (Î¸â‚, ..., Î¸â‚š)áµ€ âˆ¼ N(Î¼, Î£), where Î£ is defined as Î» times a matrix with 1 on the diagonal and r elsewhere. The condition r âˆˆ [BLANK] ensures that Î£ is positive definite when p is large.",
    "gold_answer": "[0,1). This condition ensures that the correlation r between any two Î¸i and Î¸j is non-negative and less than 1, guaranteeing the positive definiteness of the covariance matrix Î£ for any large p.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "[0,1)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"(-1/(p-1), 1)\"\n}",
      "model_answer": "(-1/(p-1), 1)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3201",
    "folder": "",
    "question": "In the context of judgment post-stratified (JPS) samples, the variance of the sign statistic for the pth quantile is given by V(âˆšn S(Î·_p)) = ÏƒÂ²_{n,Î·_p} = B_{n,H}ÎºÂ²_H(Î·_p) + C_{n,H}Î´Â²_H(Î·_p), where ÎºÂ²_H(Î·_p) = [BLANK]. What is the missing term in the equation for ÎºÂ²_H(Î·_p)?",
    "gold_answer": "ÎºÂ²_H(Î·_p) = (1/H) {âˆ‘_{k=1}^H (p - F_[k](Î·_p))Â²}. The term ÎºÂ²_H(Î·_p) represents the average squared deviation of the judgment class cumulative distribution functions from the quantile order p, highlighting the variability due to the ranking process.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2014\\ScienceDirect_articles_04Mar2025_11-04-16.848\\Statistical-inference-for-population-quantiles-and\\Statistical-inference-for-population-quantiles-and.md",
      "Statistical-inference-for-population-quantiles-and.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ÎºÂ²_H(Î·_p) = (1/H) {âˆ‘_{k=1}^H (p - F_[k](Î·_p))Â²}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"H(Î·_p)(1-H(Î·_p))\"\n}",
      "model_answer": "H(Î·_p)(1-H(Î·_p))",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1848",
    "folder": "",
    "question": "The paper proposes a method to test the hypothesis Hâ‚€': Ïƒ(Â·) âˆˆ M' using a process based on the difference of residuals distributions. This process, denoted as Å´(y) = n^(1/2)(FÌ‚_Îµâ°(y) - FÌ‚_Îµâ‚€(y)), is used to construct test statistics. The Kolmogorov-Smirnov type statistic is defined as T_KS = sup_{âˆ’âˆž < y â‰¤ T} |Å´(y)|, and the Cramer-von Mises type statistic is T_CM = (1/FÌ‚_Îµâ°(T)) âˆ«_{âˆ’âˆž}^T Å´Â²(y) dFÌ‚_Îµâ°(y). What critical assumption about the point T is omitted here?",
    "gold_answer": "The point T must be less than Ï„_HÎµâ° = Ï„_FÎµâ° âˆ§ Ï„_GÎµâ°, where Ï„_F is the infimum of {x: F(x) = 1}, ensuring that the estimators avoid the inconsistent parts of the distributions due to censoring.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The point T must be less than Ï„_HÎµâ° = Ï„_FÎµâ° âˆ§ Ï„_GÎµâ°, where Ï„_F is the infimum of {x: F(x) = 1}, ensuring that the estimators avoid the inconsistent parts of the distributions due to censoring",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"T must be finite\"\n}",
      "model_answer": "T must be finite",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1554",
    "folder": "",
    "question": "In the proportional odds ratio model, the reliability coefficient R is defined as [BLANK], where X and Y are random variables with tilt parameters Î±â‚ and Î±â‚‚, respectively.",
    "gold_answer": "R = P(X > Y). This definition highlights the probability that a random variable X from one distribution exceeds a random variable Y from another distribution, serving as a measure of reliability or the difference between two populations.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2009\\ScienceDirect_articles_04Mar2025_14-37-28.841\\Estimating-reliability-in-proportional-od_2009_Com\\Estimating-reliability-in-proportional-od_2009_Com.md",
      "Estimating-reliability-in-proportional-od_2009_Com.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "R = P(X > Y)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"cor(X,Y)/âˆš(Î±â‚Î±â‚‚)\"\n}",
      "model_answer": "cor(X,Y)/âˆš(Î±â‚Î±â‚‚)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1652",
    "folder": "",
    "question": "A key assumption in the Heckman selection model is that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes, known as the [BLANK] assumption.",
    "gold_answer": "Missing at random (MAR). This assumption simplifies the inference process by not requiring explicit modeling of the dropout mechanism.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1971",
    "folder": "",
    "question": "In the context of surrogate evaluation in the presence of interference, the definition of a predictive cluster level surrogate is based on the association between causal effects on the clinical outcome and causal effects on the surrogate outcome at the cluster level. This definition is rooted in the [BLANK] paradigm.",
    "gold_answer": "causal-association. The causal-association paradigm focuses on the relationship between treatment effects on the surrogate and clinical outcomes, which is central to evaluating surrogates in settings with interference.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_21_Issue_2\\Predictive cluster level surrogacy in the presence\\Predictive cluster level surrogacy in the presence.md",
      "Predictive cluster level surrogacy in the presence.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "causal-association",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"meta-analytic\"\n}",
      "model_answer": "meta-analytic",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3237",
    "folder": "",
    "question": "The paper discusses the application of the test to a doseâ€“response problem where the isotonic likelihood ratio test gave a $p$-value slightly above 0.05. What was the $p$-value obtained by the bootstrap $D_{\\infty}$ test, and what does this suggest about the test's sensitivity?",
    "gold_answer": "The bootstrap $D_{\\infty}$ test gave a $p$-value of 0.0021, suggesting that it is more sensitive to detecting doseâ€“response relationships, especially in cases with low event rates per dose group.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The bootstrap $D_{\\infty}$ test gave a $p$-value of 0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0.0001\"\n}",
      "model_answer": "0.0001",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1602",
    "folder": "",
    "question": "A key assumption in the closed population setting with no misclassification and independent captures is that the population is assumed to be [BLANK].",
    "gold_answer": "closed. This means there are no births, deaths, or migrations into or out of the population during the study period, ensuring that the population size remains constant.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "closed",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"closed\"\n}",
      "model_answer": "closed",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2615",
    "folder": "",
    "question": "In the model $y_{i j}=\\mu_{i}+\\beta_{j}+\\epsilon_{i j}$, the term $\\epsilon_{i j}$ is assumed to be a normal variate with zero mean and variance [BLANK]. What is the variance of $\\epsilon_{i j}$?",
    "gold_answer": "$\\sigma_{j}^{2}$. This specifies the variance of the error term for each column (or observer) in the two-way classification model, highlighting the heterogeneity of variances across different observers or methods.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_45_Issue_1-2\\ONE-WAY_VARIANCES_IN_A_TWO-WAY_CLASSIFICATION\\ONE-WAY_VARIANCES_IN_A_TWO-WAY_CLASSIFICATION.md",
      "ONE-WAY_VARIANCES_IN_A_TWO-WAY_CLASSIFICATION.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\sigma_{j}^{2}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ÏƒÂ²\"\n}",
      "model_answer": "ÏƒÂ²",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-13",
    "folder": "",
    "question": "In the context of block bootstrap methods for dependent data, the optimal block size for variance or bias estimation is of order [BLANK], where n is the length of the time series.",
    "gold_answer": "n^(1/3). This is derived from balancing the error-about-the-mean against bias to minimize mean squared error, with the optimal block size depending on the context of estimation.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_82_Issue_3\\On_blocking_rules_for_the_bootstrap_with_dependent_data\\On_blocking_rules_for_the_bootstrap_with_dependent_data.md",
      "On_blocking_rules_for_the_bootstrap_with_dependent_data.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "n^(1/3)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"n^(1/3)\"\n}",
      "model_answer": "n^(1/3)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1038",
    "folder": "",
    "question": "The variance-based sensitivity model constrains how different the true weights can be from the observable weights by bounding the distributional differences that arise from omitting a confounder, parameterized by an [BLANK] value.",
    "gold_answer": "RÂ². This approach focuses on the variance of the weights rather than worst-case errors, offering a more interpretable and stable sensitivity analysis.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "RÂ²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"eta\"\n}",
      "model_answer": "eta",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2276",
    "folder": "",
    "question": "In the context of bootstrap and Edgeworth approximations, the bootstrap approximation to the tail probability Fâ‚™(x) is denoted by [BLANK], where Ráµ¢ denotes the missingness indicators.",
    "gold_answer": "FÌ‚â‚™(x). This notation is used to represent the bootstrap approximation to the tail probability Fâ‚™(x), highlighting the bootstrap's role in estimating distribution functions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1990\\ScienceDirect_articles_02Mar2025_02-23-26.284\\On-the-relative-performance-of-bootstrap-and-Edgew\\On-the-relative-performance-of-bootstrap-and-Edgew.md",
      "On-the-relative-performance-of-bootstrap-and-Edgew.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "FÌ‚â‚™(x)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P*(Gâ‚™*(Ráµ¢) â‰¤ x)\"\n}",
      "model_answer": "P*(Gâ‚™*(Ráµ¢) â‰¤ x)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-830",
    "folder": "",
    "question": "The Naga skulls were collected from an area known as the Triangle, within which [BLANK] was practiced before 1927.",
    "gold_answer": "human sacrifice. This practice was the reason behind the expedition and collection of skulls and bones from the Naga Hills.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "human sacrifice",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"headhunting\"\n}",
      "model_answer": "headhunting",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1688",
    "folder": "",
    "question": "In the context of optimal discrimination designs for semiparametric models, the Kullbackâ€“Leibler divergence measures the discrepancy between two densities and is given by [BLANK]. What is the correct formula for the Kullbackâ€“Leibler divergence?",
    "gold_answer": "I_{1,2}(x,f_{1},f_{2},\\theta_{1},\\theta_{2})=\\int f_{1}(y;x,\\theta_{1})\\log\\frac{f_{1}(y;x,\\theta_{1})}{f_{2}(y;x,\\theta_{2})}\\mathrm{d}y. The formula is crucial for measuring the discrepancy between two competing models in the context of optimal discrimination designs.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_105_Issue_1\\Optimal_discrimination_designs_for_semiparametric_models\\Optimal_discrimination_designs_for_semiparametric_models.md",
      "Optimal_discrimination_designs_for_semiparametric_models.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "I_{1,2}(x,f_{1},f_{2},\\theta_{1},\\theta_{2})=\\int f_{1}(y;x,\\theta_{1})\\log\\frac{f_{1}(y;x,\\theta_{1})}{f_{2}(y;x,\\theta_{2})}\\mathrm{d}y",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"âˆ« f(x) log(f(x)/g(x))dx\"\n}",
      "model_answer": "âˆ« f(x) log(f(x)/g(x))dx",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-886",
    "folder": "",
    "question": "In high-dimensional quantile tensor regression using a general convex decomposable regularizer, the rates are stated in terms of the intrinsic dimension of the estimation problem, which is, roughly speaking, the dimension of the smallest subspace that contains the true coefficient. The intrinsic dimension is denoted by [BLANK].",
    "gold_answer": "s. This notation is used to represent the intrinsic dimension, which is crucial for understanding the complexity and structure of the estimation problem in high-dimensional quantile tensor regression.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "s",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"d\"\n}",
      "model_answer": "d",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1830",
    "folder": "",
    "question": "In the analysis of variance for orthogonal designs, the degrees of freedom dF for a plot factor F with nF levels are calculated recursively. The formula involves subtracting the sum of the degrees of freedom for all plot factors G that are coarser than F from nF. The initial step in this recursive calculation starts with the universal factor U, for which dU = [BLANK].",
    "gold_answer": "1. This is because the universal factor U has only one level, making its degrees of freedom equal to 1, serving as the base case for the recursive calculation.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3590",
    "folder": "",
    "question": "In the grading of apples for the experiment, three sizes were retained, with Grade 1 including those apples which rested on the 2Â¼-inch ring but passed through the [BLANK]-inch ring.",
    "gold_answer": "2Â½. This grading was part of the method to categorize apples by size, ensuring that only medium-sized apples were used in the experiment to reduce variability.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "2Â½",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"2Â½\"\n}",
      "model_answer": "2Â½",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-440",
    "folder": "",
    "question": "In the context of stochastic curtailment methods for early stopping in clinical trials, the method suggested by Lan et al. (1982) calculates the conditional power as the chance that the results at the end of the trial will be significant, given the current data. This can be expressed as [BLANK], where Ráµ¢ denotes the missingness indicators. What is the term used to describe this chance?",
    "gold_answer": "Conditional power. This term is used to describe the probability that the trial will achieve a statistically significant result by the end, based on the data observed up to the interim analysis.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_52_Issue_2\\Early Stopping by Using Stochastic Curtailment in\\Early Stopping by Using Stochastic Curtailment in.md",
      "Early Stopping by Using Stochastic Curtailment in.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Conditional power",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(reject Hâ‚€|data, Ráµ¢)\"\n}",
      "model_answer": "P(reject Hâ‚€|data, Ráµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1606",
    "folder": "",
    "question": "The class of multivariate survival functions being studied has the form $G(\\mathbf{x})=G_{0}(A(\\mathbf{x}))$ , where $G_{0}$ is a univariate survival function with support included in $[0,+\\infty)$ and $A:\\mathcal{R}_{+}^{n}\\to[0,\\infty)$ is a nondecreasing function such that $\\boldsymbol{A}(\\mathbf{0})=0$ and $A$ is homogeneous of order 1 (that is, $A(t\\mathbf{x})=t A(\\mathbf{x})$ for all $t>0$ and $\\mathbf{X}\\in{\\mathcal{R}}_{+}^{n}$ ). From a mixture of powers representation, it is known that this class includes $G$ for which $A$ is an exponent of a min-stable multivariate exponential distribution and $G_{0}$ is a [BLANK]. However, we find that the class contains much more than this.",
    "gold_answer": "Laplace transform. This is omitted to highlight that while the class includes cases where $G_{0}$ is a Laplace transform and $A$ is an exponent of a min-stable multivariate exponential distribution, the class is not limited to these cases, allowing for more general dependencies.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Laplace transform",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"univariate stable distribution\"\n}",
      "model_answer": "univariate stable distribution",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3561",
    "folder": "",
    "question": "In the context of extreme value theory, the condition that $L(x) = x^{\\alpha}\\mathcal{F}(x)$ should be slowly varying is a necessary and sufficient condition for (1.1) to hold with $G = \\Phi_{\\alpha}$. What is the term used to describe a strengthened form of this slow-variation condition that is necessary for large-deviation probabilities to hold?",
    "gold_answer": "Super-slow variation (SSV). This term is used to describe the condition that $L(x)$ must satisfy beyond regular slow variation to ensure the uniform convergence of large-deviation probabilities as described in the paper.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_40_Issue_2\\Super-Slowly Varying Functions in Extreme Value Th\\Super-Slowly Varying Functions in Extreme Value Th.md",
      "Super-Slowly Varying Functions in Extreme Value Th.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Super-slow variation (SSV)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"strong slow-variation\"\n}",
      "model_answer": "strong slow-variation",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1885",
    "folder": "",
    "question": "In the context of multinormal integrals, the function Ï†â‚™(y) is defined as (2Ï€)â»â¿/Â² exp(f(y)), where f(y) is given by [BLANK]. What is the expression for f(y)?",
    "gold_answer": "-Â½|y|Â². This expression represents the exponent in the multinormal density function, highlighting the quadratic form in the exponent.",
    "source": [
      "Asymptotic-approximations-for-multivariate-integra.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1989\\ScienceDirect_articles_02Mar2025_02-24-31.083\\Asymptotic-approximations-for-multivariate-integra\\Asymptotic-approximations-for-multivariate-integra.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "-Â½|y|Â²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"-y'y/2\"\n}",
      "model_answer": "-y'y/2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3260",
    "folder": "",
    "question": "In the context of testing for outliers when both $\\mu$ and $\\pmb{\\sigma}$ are unknown, the modified McKay criterion is given by $(x_{n}-{\\overline{{x}}})/\\pmb{\\delta}$, where $\\pmb{\\delta}$ is the [BLANK].",
    "gold_answer": "sample standard deviation. This is because when both population parameters are unknown, the sample standard deviation is used as an estimate for $\\sigma$.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "sample standard deviation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sample standard deviation\"\n}",
      "model_answer": "sample standard deviation",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-754",
    "folder": "",
    "question": "The paper concludes that semiparametric models are flexible enough to forecast out-of-sample better than any linear or nonlinear Taylor rule model, highlighting the importance of not imposing a known functional form for [BLANK].",
    "gold_answer": "f(.). This represents the unknown function in the nonparametric part of the semiparametric model, emphasizing the model's ability to reveal structure in data without fixed assumptions.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"monetary policy\"\n}",
      "model_answer": "monetary policy",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3112",
    "folder": "",
    "question": "In all three examples (Pseudo-Bayes Estimators, Aitchison and Aitken's Estimators, Nearest Neighbour Estimators) the bandwidth 9 has a high impact on the performance of the entire kernel estimator. Small bandwidths correspond to little smoothing, and under [BLANK] data are not smoothed at all; in the latter case the kernel estimators result in the frequency estimator.",
    "gold_answer": "Ï‘=0. This specifies the condition under which kernel estimators do not apply any smoothing to the data, effectively reverting to the frequency estimator.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï‘=0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"zero bandwidth\"\n}",
      "model_answer": "zero bandwidth",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3363",
    "folder": "",
    "question": "In the VAR-HME model, the conditional probability density function (pdf) of yâ‚œ is given by fâ‚œ(yâ‚œ|Fâ‚œâ‚‹â‚,Xâ‚œ;Î¸), where Î¸ is a parameter vector; Xâ‚œ is the Ïƒ-field generated by {xâ‚œ}â‚áµ€ representing external information; and, for each t, Fâ‚œâ‚‹â‚ is the Ïƒ-field generated by {yâ‚›}â‚áµ—â»Â¹ representing the previous history at time t-1. The conditional pdf fâ‚œ is assumed to depend on Xâ‚œ through [BLANK] only.",
    "gold_answer": "xâ‚œ. This is because the conditional pdf fâ‚œ typically depends on the current covariate vector xâ‚œ, not the entire history of covariates.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "xâ‚œ",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"xâ‚œ\"\n}",
      "model_answer": "xâ‚œ",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1505",
    "folder": "",
    "question": "In the two-way analysis of variance model without interaction, the intraclass correlation coefficient (ICC) is defined as the ratio of the variance between subjects to the total variance, which includes the variance between subjects, the variance between labs or raters, and the error variance. The formula for ICC is given by [BLANK]. What is the correct formula for ICC in this context?",
    "gold_answer": "ICC = Ïƒ_bÂ² / (Ïƒ_bÂ² + Ïƒ_lÂ² + Ïƒ_eÂ²). This formula represents the proportion of the total variance that is attributable to the variance between subjects, highlighting the agreement among measurements across different labs or raters.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2015\\ScienceDirect_articles_04Mar2025_10-59-44.155\\Sample-size-methods-for-constructing-confidence-in\\Sample-size-methods-for-constructing-confidence-in.md",
      "Sample-size-methods-for-constructing-confidence-in.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ICC = Ïƒ_bÂ² / (Ïƒ_bÂ² + Ïƒ_lÂ² + Ïƒ_eÂ²)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ÏƒÂ²â‚›/(ÏƒÂ²â‚› + ÏƒÂ²áµ£ + ÏƒÂ²â‚‘)\"\n}",
      "model_answer": "ÏƒÂ²â‚›/(ÏƒÂ²â‚› + ÏƒÂ²áµ£ + ÏƒÂ²â‚‘)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-73",
    "folder": "",
    "question": "In the context of nonformation, the concept where a submodel and the corresponding part of the data contain no available information with respect to the parameter of interest is termed as [BLANK].",
    "gold_answer": "nonformation. This term is introduced to describe the scenario where certain parts of the model or data do not contribute any information towards the parameter of interest, highlighting the importance of identifying informative versus non-informative components in statistical inference.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_63_Issue_3\\Nonformation\\Nonformation.md",
      "Nonformation.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "nonformation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nonidentifiability\"\n}",
      "model_answer": "nonidentifiability",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1447",
    "folder": "",
    "question": "In the context of testing hypotheses involving variance components, the statistic $F^{*}(\\mathbf{s})$ is used under the null hypothesis $H_{0}\\colon\\sum_{i=1}^{m}c_{i}\\sigma_{i}^{2}=\\sum_{i=m+1}^{l}c_{i}\\sigma_{i}^{2}$. The first moment of $F^{*}(\\mathbf{s})$ under $H_{0}$ can be approximated by $1 + 2V_{\\mathbf{u}}^{*} - 8V_{\\mathbf{s1}}^{*} + ...$. What does $V_{n}^{*}$ represent in this context?",
    "gold_answer": "$V_{n}^{*}$ represents the ratio of the sum of the $(c_{i}\\sigma_{i}^{2})^{r}/f_{i}^{r}$ terms for the denominator mean squares to the $r$-th power of the sum of the $c_{i}\\sigma_{i}^{2}$ terms for the denominator. It is part of the series expansion used to approximate the first moment of $F^{*}(\\mathbf{s})$ under the null hypothesis.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_58_Issue_2\\Miscellanea_On_alternative_approximate_F_tests_for_hypotheses_involving_variance_components\\Miscellanea_On_alternative_approximate_F_tests_for_hypotheses_involving_variance_components.md",
      "Miscellanea_On_alternative_approximate_F_tests_for_hypotheses_involving_variance_components.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$V_{n}^{*}$ represents the ratio of the sum of the $(c_{i}\\sigma_{i}^{2})^{r}/f_{i}^{r}$ terms for the denominator mean squares to the $r$-th power of the sum of the $c_{i}\\sigma_{i}^{2}$ terms for the denominator",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the coefficient of variation of the numerator\"\n}",
      "model_answer": "the coefficient of variation of the numerator",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1544",
    "folder": "",
    "question": "In the expansion of $C_{\\rho}^{*}(V+I)$ as a sum of zonal polynomials, the coefficients $\\boldsymbol{a}_{\\tau\\rho}$ are sometimes called [BLANK]. What is the term used to describe these coefficients?",
    "gold_answer": "generalized binomial coefficients. This term is used because these coefficients play a role analogous to binomial coefficients in the expansion of polynomials.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1985\\ScienceDirect_articles_02Mar2025_02-29-14.367\\On-the-expansion-of-C---V---I--as-a-sum-of-zon_198\\On-the-expansion-of-C---V---I--as-a-sum-of-zon_198.md",
      "On-the-expansion-of-C---V---I--as-a-sum-of-zon_198.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "generalized binomial coefficients",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"connection coefficients\"\n}",
      "model_answer": "connection coefficients",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1086",
    "folder": "",
    "question": "The likelihood ratio spatial scan statistic has been widely used in spatial disease surveillance and spatial cluster detection applications. In order to better understand cluster mechanisms, an equivalent model-based approach is proposed to the spatial scan statistic that unifies currently loosely coupled methods for including ecological covariates in the spatial scan test. In addition, the utility of the model-based approach with a [BLANK]-based scan statistic is demonstrated to account for overdispersion and heterogeneity in background rates.",
    "gold_answer": "Wald. The Wald-based scan statistic is introduced as a method to account for overdispersion and heterogeneity, showcasing the flexibility of the model-based approach beyond the likelihood ratio method.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2009\\ScienceDirect_articles_04Mar2025_14-35-09.749\\Spatial-scan-statistics-in-loglinear-_2009_Computa\\Spatial-scan-statistics-in-loglinear-_2009_Computa.md",
      "Spatial-scan-statistics-in-loglinear-_2009_Computa.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Wald",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"regression\"\n}",
      "model_answer": "regression",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1174",
    "folder": "",
    "question": "In the context of Bayesian variable selection with very large p, the proposed adaptive Markov chain Monte Carlo algorithms aim to improve performance by exploiting the observation that in large-p, small-n settings, the majority of the p variables will be approximately [BLANK] a posteriori.",
    "gold_answer": "uncorrelated. This observation allows the algorithms to adaptively build nonlocal proposals that result in moves with significantly larger squared jumping distances than standard methods.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_108_Issue_1\\In_search_of_lost_mixing_time_adaptive_Markov_chain_Monte_Carlo_schemes_for_Bayesian_variable_selection_with_very_large_p\\In_search_of_lost_mixing_time_adaptive_Markov_chain_Monte_Carlo_schemes_for_Bayesian_variable_selection_with_very_large_p.md",
      "In_search_of_lost_mixing_time_adaptive_Markov_chain_Monte_Carlo_schemes_for_Bayesian_variable_selection_with_very_large_p.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "uncorrelated",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"independent\"\n}",
      "model_answer": "independent",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2686",
    "folder": "",
    "question": "The consistency property of the principal component direction in high-dimensional settings is established under certain conditions. One such condition is that the eigenvalues of the covariance matrix Î£_d^(m) satisfy Î»â‚^(m) ~ d^Î±^(m), Î»â‚‚^(m) ~ d^Î¸^(m), and Î£_{i=2}^d Î»_i^(m) ~ d, where Î¸^(m) âˆˆ [0, Î±^(m)) and Î±^(m) âˆˆ (0, 1]. This condition is referred to as the [BLANK] condition.",
    "gold_answer": "spike. This condition specifies the divergence rates of the eigenvalues, which is crucial for establishing the consistency of PCA and SPCA estimates in high-dimensional settings.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "spike",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"spiked covariance\"\n}",
      "model_answer": "spiked covariance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-136",
    "folder": "",
    "question": "In the context of estimating a structural parameter in the presence of nuisance parameters, the Cramer-Rao bound does not necessarily give an attainable lower bound when the number of nuisance parameters increases in proportion to the sample size. The new lower bound proposed is expressed as the inverse of the sum of the partial information and a certain nonnegative term, which is derived by [BLANK] considerations.",
    "gold_answer": "differential-geometrical. This highlights the approach taken to derive the new lower bound, emphasizing the role of differential geometry in understanding the structure and efficiency of estimators in complex statistical models.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_71_Issue_3\\Estimation_of_a_structural_parameter_in_the_presence_of_a_large_number_of_nuisance_parameters\\Estimation_of_a_structural_parameter_in_the_presence_of_a_large_number_of_nuisance_parameters.md",
      "Estimation_of_a_structural_parameter_in_the_presence_of_a_large_number_of_nuisance_parameters.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "differential-geometrical",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"asymptotic\"\n}",
      "model_answer": "asymptotic",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2631",
    "folder": "",
    "question": "In the context of field trials for evaluating plant varieties, the use of composite samples for each variety is common for traits that are costly to measure. However, this approach precludes the use of an efficient statistical analysis. The proposed approach involves testing a proportion of varieties by using individual replicate samples, while the remaining varieties may be tested as composite samples or with reduced replication. This allows for the application of efficient mixed model analyses for both inexpensive and expensive traits. The missing element in this approach is [BLANK], which is crucial for accommodating spatial trend or design factors based on the original spatial coordinates of all plots.",
    "gold_answer": "the spatial analysis of data derived from a mixture of composite and individual plot samples. This is excluded to highlight the innovative aspect of the proposed approach, which allows for the accommodation of spatial trend and/or design factors based on the original spatial coordinates of all plots, including those used to form the composite samples.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_60_Issue_3\\The Design and Analysis of Variety Trials Using Mi\\The Design and Analysis of Variety Trials Using Mi.md",
      "The Design and Analysis of Variety Trials Using Mi.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the spatial analysis of data derived from a mixture of composite and individual plot samples",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"imputation\"\n}",
      "model_answer": "imputation",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-146",
    "folder": "",
    "question": "In the functional linear model (1), the time-varying long-run covariance function for the functional linear model is defined by Î£(t) = âˆ‘_{j=âˆ’âˆž}^{âˆž} cov{U(t, Fâ‚€), U(t, Fâ±¼)}, where U(t, Fáµ¢) = W(t, Fáµ¢)H(t, Fáµ¢). What key term is omitted in this definition that is crucial for understanding the nonstationarity of the process?",
    "gold_answer": "The key term omitted is 't âˆˆ [0,1]', which specifies the time interval over which the long-run covariance function is defined, highlighting the nonstationarity by allowing the covariance to vary over time.",
    "source": [
      "Difference-based_covariance_matrix_estimation_in_time_series_nonparametric_regression_with_application_to_specification_tests.md",
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_111_Issue_4\\Difference-based_covariance_matrix_estimation_in_time_series_nonparametric_regression_with_application_to_specification_tests\\Difference-based_covariance_matrix_estimation_in_time_series_nonparametric_regression_with_application_to_specification_tests.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The key term omitted is 't âˆˆ [0,1]', which specifies the time interval over which the long-run covariance function is defined, highlighting the nonstationarity by allowing the covariance to vary over time",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"t\"\n}",
      "model_answer": "t",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1683",
    "folder": "",
    "question": "In the context of adaptive group-sequential covariate-adjusted randomized clinical trials (RCTs), the parameter of scientific interest on the additive scale is denoted as [BLANK], where W is a vector of baseline covariates, A the treatment assignment, and Y the primary outcome of interest.",
    "gold_answer": "Î¨+ = E{E(Y|A=1,W)âˆ’E(Y|A=0,W)}. This represents the marginal effect of treatment a=1 relative to treatment a=0 on the additive scale, also known as the risk difference.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2014_Volume_41_Issue_1\\Scandinavian J Statistics - 2013 - Chambaz - Infer\\Scandinavian J Statistics - 2013 - Chambaz - Infer.md",
      "Scandinavian J Statistics - 2013 - Chambaz - Infer.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¨+ = E{E(Y|A=1,W)âˆ’E(Y|A=0,W)}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"E[Y|A=1,W] - E[Y|A=0,W]\"\n}",
      "model_answer": "E[Y|A=1,W] - E[Y|A=0,W]",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-383",
    "folder": "",
    "question": "The condition for the MS AMEM to be stationary and ergodic is given by Î£_{s_t=1}^n Ï€_{s_t} E[log{(Î±_{s_t} + Î³_{s_t} D_t) Îµ_t + Î²_{s_t}}] < 0. What does Ï€_{s_t} represent in this condition?",
    "gold_answer": "Ï€_{s_t} represents the ergodic probability of state s_t. This condition ensures that the model's parameters are set in such a way that the process does not explode over time, maintaining stability.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ï€_{s_t} represents the ergodic probability of state s_t",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"stationary probabilities\"\n}",
      "model_answer": "stationary probabilities",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2540",
    "folder": "",
    "question": "In the context of panel count data analysis, ignoring within-subject correlation may lead to [BLANK] in parameter estimation and inference.",
    "gold_answer": "serious problems. This includes biased parameter estimates and underestimated variances, which can result in misleading conclusions about the covariate effects.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "serious problems",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"inefficiency\"\n}",
      "model_answer": "inefficiency",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2108",
    "folder": "",
    "question": "The generalized logit (GL) transformation for an original time series {x_t} is given by y_t = Î³(x_t;Î½) = ln(x_t^Î½ / (1 - x_t^Î½)), where Î½ > 0 and x_t âˆˆ (0,1). The inverse transformation is x_t = Î³^(-1)(y_t;Î½) = [BLANK]. What is the correct expression for the inverse generalized logit transformation?",
    "gold_answer": "{1 + 1/exp(y_t)}^(-1/Î½). This expression correctly represents the inverse transformation, allowing the original variable x_t to be recovered from the transformed variable y_t.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_61_Issue_4\\Very-Short-Term Probabilistic Forecasting of Wind\\Very-Short-Term Probabilistic Forecasting of Wind.md",
      "Very-Short-Term Probabilistic Forecasting of Wind.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "{1 + 1/exp(y_t)}^(-1/Î½)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"(1 + exp(-y_t))^(-1/Î½)\"\n}",
      "model_answer": "(1 + exp(-y_t))^(-1/Î½)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1330",
    "folder": "",
    "question": "In the random dot product graph model, the edge probability between any two vertices is given by the dot product of their latent positions, formally expressed as [BLANK].",
    "gold_answer": "Îº(xi, xj) = xi^T xj. This formula is fundamental to the random dot product graph model, defining how the probability of an edge between two vertices is calculated based on their latent positions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_107_Issue_4\\Optimal_Bayesian_estimation_for_random_dot_product_graphs\\Optimal_Bayesian_estimation_for_random_dot_product_graphs.md",
      "Optimal_Bayesian_estimation_for_random_dot_product_graphs.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Îº(xi, xj) = xi^T xj",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(A_{ij} = 1) = x_i^T x_j\"\n}",
      "model_answer": "P(A_{ij} = 1) = x_i^T x_j",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1149",
    "folder": "",
    "question": "In the context of survival analysis models, the proportional hazard model is given by hY(y|x,m,u) = h0(y)exp(Î»1x + Î»2m + Î»3u). A key condition for the parameters Î»1 and Î»2 to be identifiable when U is unobserved is that the function Ïˆ1(X) in the model M = Ïˆ1(X) + Ïˆ2(U, ÎµM) is [BLANK].",
    "gold_answer": "not a linear function of X. This non-linearity condition is necessary to ensure that the parameters Î»1 and Î»2 can be distinguished from each other in the estimation process, allowing for the identification of direct and indirect effects.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "not a linear function of X",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nonlinear\"\n}",
      "model_answer": "nonlinear",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-602",
    "folder": "",
    "question": "In the proposed CMPMOB algorithm, to reduce computational complexity in split point estimation, tools from [BLANK] methodology are borrowed, proposing a new method that uses only the estimated score functions without fitting models for each split point.",
    "gold_answer": "change point estimation. This approach simplifies the exhaustive search traditionally used in the MOB algorithm, making it computationally more efficient.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "change point estimation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"M-estimation\"\n}",
      "model_answer": "M-estimation",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2070",
    "folder": "",
    "question": "In the Bayesian hierarchical model for estimating derivative curves, the sequence of quotient differences is constructed using both forward and backward differences to mitigate [BLANK] effects.",
    "gold_answer": "boundary. This approach helps in reducing the bias at the boundaries of the data range, making the derivative estimates more reliable across the entire domain.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "boundary",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"boundary\"\n}",
      "model_answer": "boundary",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2639",
    "folder": "",
    "question": "In the prequential framework, the performance of a Statistical Forecasting System is assessed by comparing the forecast distributions with the realised outcomes using the [BLANK] score.",
    "gold_answer": "logarithmic. The logarithmic score is used because it is an example of a proper scoring rule that motivates honest probability assessment.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_86_Issue_4\\On_efficient_probability_forecasting_systems\\On_efficient_probability_forecasting_systems.md",
      "On_efficient_probability_forecasting_systems.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "logarithmic",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"prequential\"\n}",
      "model_answer": "prequential",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1546",
    "folder": "",
    "question": "In the context of analyzing sickness rates using Makeham's hypothesis, the force of sickness at any age is expressed in the form [BLANK], where A and B are constants, and c is a base for the exponential function.",
    "gold_answer": "A + Bc^x. This formula represents the Makeham's hypothesis for the force of sickness, combining a constant term A with an exponential term Bc^x to model the rate of sickness at age x.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_3_Issue_1\\GRADUATION_OF_A_SICKNESS_TABLE_BY_MAKEHAM'S_HYPOTHESIS\\GRADUATION_OF_A_SICKNESS_TABLE_BY_MAKEHAM'S_HYPOTHESIS.md",
      "GRADUATION_OF_A_SICKNESS_TABLE_BY_MAKEHAM'S_HYPOTHESIS.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "A + Bc^x",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"A + Bc^x\"\n}",
      "model_answer": "A + Bc^x",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1448",
    "folder": "",
    "question": "In the model $Y_{i t}=X_{i t}\\beta+F_{t}A_{i}^{\\prime}+\\epsilon_{i t}$, the term $F_{t}A_{i}^{\\prime}$ represents the [BLANK] structure.",
    "gold_answer": "unobserved factor. This term captures the interaction between unobservable common time-varying factors and individual-specific factor loadings, highlighting the model's ability to account for unobserved heterogeneity.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2014\\ScienceDirect_articles_04Mar2025_11-04-27.030\\Parameter-cascading-for-panel-models-with-unknown-\\Parameter-cascading-for-panel-models-with-unknown-.md",
      "Parameter-cascading-for-panel-models-with-unknown-.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "unobserved factor",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"interactive fixed effects\"\n}",
      "model_answer": "interactive fixed effects",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2641",
    "folder": "",
    "question": "The condition that for every ${\\mathbf u}\\in[0,1]^{d}$, $C(\\mathbf{u})=0$ when at least one coordinate of $\\mathbf{u}$ is zero, is part of the definition of a [BLANK].",
    "gold_answer": "pseudo-copula. This condition ensures the pseudo-copula meets the basic requirements of a cumulative distribution function.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "pseudo-copula",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"copula\"\n}",
      "model_answer": "copula",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1868",
    "folder": "",
    "question": "In the context of testing the correct specification of general conditional location parametric functionals, the CramÃ©r-von Mises (CvM) test statistic is given by CvM_{n,w,Ïˆ} = âˆ«_Ï€ |R_{n,w}^1(x)|^2 Ïˆ(dx), where R_{n,w}^1(x) is the residual marked empirical process and Ïˆ is an integrating function. The term [BLANK] is crucial for the computation of the CvM test statistic as it represents the integrating function.",
    "gold_answer": "Ïˆ(dx). This term is essential as it defines the measure over which the squared norm of the residual marked empirical process is integrated, thereby influencing the test statistic's value and its sensitivity to deviations from the null hypothesis.",
    "source": [
      "Approximating-the-critical-values-of-Cram-r-von-Mi.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2010\\ScienceDirect_articles_04Mar2025_11-18-31.443\\Approximating-the-critical-values-of-Cram-r-von-Mi\\Approximating-the-critical-values-of-Cram-r-von-Mi.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ïˆ(dx)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ïˆ\"\n}",
      "model_answer": "Ïˆ",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3133",
    "folder": "",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a patternâ€“mixture perspective, where we distinguish subpopulations according to their missingness patterns. Suppose we rely on the â€˜neighboring case missing valueâ€™ approach (NCMV) so that missing values in a partially observed sequence borrow information only from the next identified pattern. If we consider the subpopulation distribution $f(Y | pattern)$, we multiply this by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern ($f(pattern)$). We omit it to underscore that each pattern has a distinct distribution of Y, and combining them in a patternâ€“mixture approach requires weighting by the relative frequency of each pattern.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the proportion of that missingness pattern ($f(pattern)$)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(pattern)\"\n}",
      "model_answer": "P(pattern)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-490",
    "folder": "",
    "question": "The estimator ð‘‡Ì‚ð‘›(ð‘) becomes efficient in the normal case when the tuning parameter ð‘ is set to [BLANK].",
    "gold_answer": "ð‘âˆ— = âˆ’ðœŒ0 / (1 + ðœŒ0^2). This optimal weight minimizes the variance of the estimator, making it efficient in estimating the correlation coefficient ðœŒ0 in the normal case.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ð‘âˆ— = âˆ’ðœŒ0 / (1 + ðœŒ0^2)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-919",
    "folder": "",
    "question": "The application of the cluster method based on redescending M-estimators to edge identification in noisy images involves estimating points that may belong to edges using the rotational density kernel estimator (RDKE). The choice of the window size $h_{N}$ for the RDKE method is critical and is often chosen relative to the size of the object to be detected, e.g., $10\\%$ of it. For a triangle with a diameter of 68 pixels, the window size would be $[BLANK]$.",
    "gold_answer": "6.8. This choice is based on the guideline to set the window size to approximately 10% of the object's size, ensuring that the RDKE method can effectively estimate points belonging to the edges without being too sensitive to noise.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "6",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"6.8\"\n}",
      "model_answer": "6.8",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1397",
    "folder": "",
    "question": "The limiting null distribution of the BHEP test statistic $T_{n,\\beta}$ under the hypothesis of multivariate normality is that of $\\sum_{j\\geq1}\\delta_{j}(\\beta)N_{j}^{2}$, where $N_{1},N_{2},...$ are i.i.d. standard normal random variables and $(\\delta_{j}(\\beta))_{j\\geqslant1}$ is a sequence of eigenvalues. These eigenvalues are associated with an integral operator defined by the covariance kernel $K(s,t)$. What is the expression for $K(s,t)$?",
    "gold_answer": "The covariance kernel $K(s,t)$ is given by $K(s,t)=\\exp\\bigg(-\\frac{\\|s-t\\|^{2}}{2}\\bigg)-\\bigg\\{1+s^{\\prime}t+\\frac{(s^{\\prime}t)^{2}}{2}\\bigg\\}\\exp\\bigg(-\\frac{\\|s\\|^{2}+\\|t\\|^{2}}{2}\\bigg)$. This kernel defines the covariance structure of the limiting Gaussian process.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The covariance kernel $K(s,t)$ is given by $K(s,t)=\\exp\\bigg(-\\frac{\\|s-t\\|^{2}}{2}\\bigg)-\\bigg\\{1+s^{\\prime}t+\\frac{(s^{\\prime}t)^{2}}{2}\\bigg\\}\\exp\\bigg(-\\frac{\\|s\\|^{2}+\\|t\\|^{2}}{2}\\bigg)$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"exp(-Î²Â²||s-t||Â²/2)(exp(-Î²Â²||s||Â²/2)+exp(-Î²Â²||t||Â²/2)-2exp(-(Î²Â²/4)(||s||Â²+||t||Â²)))\"\n}",
      "model_answer": "exp(-Î²Â²||s-t||Â²/2)(exp(-Î²Â²||s||Â²/2)+exp(-Î²Â²||t||Â²/2)-2exp(-(Î²Â²/4)(||s||Â²+||t||Â²)))",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2195",
    "folder": "",
    "question": "In the mover-stayer model, the transition probabilities for an m state Markov chain are given by Ï€áµ¢â±¼ = (1 - sáµ¢)pâ±¼ for i â‰  j and Ï€áµ¢áµ¢ = (1 - sáµ¢)páµ¢ + sáµ¢ for i = j. Here, {pâ‚–} is a probability distribution and sáµ¢ represents the probability of staying in state i. The constraints on sáµ¢ are that [BLANK] must be non-negative for all i.",
    "gold_answer": "1 - sáµ¢. This constraint ensures that the probability of moving from state i to any other state j (i â‰  j) is non-negative, maintaining the validity of the transition probabilities.",
    "source": [
      "A_comparison_of_iterative_methods_for_obtaining_maximum_likelihood_estimates_in_contingency_tables_with_a_missing_diagonal.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_64_Issue_2\\A_comparison_of_iterative_methods_for_obtaining_maximum_likelihood_estimates_in_contingency_tables_with_a_missing_diagonal\\A_comparison_of_iterative_methods_for_obtaining_maximum_likelihood_estimates_in_contingency_tables_with_a_missing_diagonal.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1 - sáµ¢",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sáµ¢\"\n}",
      "model_answer": "sáµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1064",
    "folder": "",
    "question": "In the context of microarray data analysis, the method that projects high-dimensional data onto a line and performs classification in this one-dimensional space, maximizing the distance between the means of the two classes while minimizing the variance within each class, is known as [BLANK].",
    "gold_answer": "Fisherâ€™s linear discriminant analysis (FLDA). This method is highlighted for its approach to classification by optimizing the separation between classes while minimizing within-class variance, making it suitable for microarray data analysis where distinguishing between classes based on gene expression is crucial.",
    "source": [
      "An-extensive-comparison-of-recent-classificatio_20.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2005\\ScienceDirect_articles_04Mar2025_14-57-27.999\\An-extensive-comparison-of-recent-classificatio_20\\An-extensive-comparison-of-recent-classificatio_20.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Fisherâ€™s linear discriminant analysis (FLDA)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Linear Discriminant Analysis\"\n}",
      "model_answer": "Linear Discriminant Analysis",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-471",
    "folder": "",
    "question": "The wavelet variance provides a scale-based decomposition of the variance of a time series, and a large var. $(W_{\\tau,t}^{\\mathrm{H}})$ for a particular $\\tau$ should provide the basis for defining a characteristic scale that is in the neighbourhood of $\\tau$. The goal of the paper is to expand this key idea to define a wavelet-based characteristic scale and to provide theory for a corresponding statistically tractable [BLANK].",
    "gold_answer": "estimator. The blank is filled with 'estimator' to highlight the paper's focus on developing a method to estimate the wavelet-based characteristic scale statistically.",
    "source": [
      "Assessing Characteristic Scales Using Wavelets.md",
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_64_Issue_2\\Assessing Characteristic Scales Using Wavelets\\Assessing Characteristic Scales Using Wavelets.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "estimator",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"estimator\"\n}",
      "model_answer": "estimator",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-711",
    "folder": "",
    "question": "The familywise error rate, FWER, is the probability of making [BLANK] false discovery, while the FDR is the expected proportion of false positives.",
    "gold_answer": "one. This highlights the stringent control of Type I errors provided by FWER, focusing on the probability of at least one false discovery.",
    "source": [
      "Covariate_adaptive_familywise_error_rate_control_for_genome-wide_association_studies.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_108_Issue_4\\Covariate_adaptive_familywise_error_rate_control_for_genome-wide_association_studies\\Covariate_adaptive_familywise_error_rate_control_for_genome-wide_association_studies.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "one",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"at least one\"\n}",
      "model_answer": "at least one",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-558",
    "folder": "",
    "question": "In the context of Bayesian density estimation using nonparametric hierarchical mixtures, the class of mixtures considered is very flexible in the detection of clusters in the data. This class is characterized by mixtures of parametric densities on the positive reals with a [BLANK] as mixing measure.",
    "gold_answer": "normalized generalized gamma process. This mixing measure is chosen for its flexibility in detecting clusters and its ability to model complex data structures effectively.",
    "source": [
      "Bayesian-density-estimation-and-model-selection-u_.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2010\\ScienceDirect_articles_04Mar2025_11-18-23.382\\Bayesian-density-estimation-and-model-selection-u_\\Bayesian-density-estimation-and-model-selection-u_.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "normalized generalized gamma process",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"random probability measure\"\n}",
      "model_answer": "random probability measure",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1632",
    "folder": "",
    "question": "In the spiked population model, all the population eigenvalues are equal to 1 except for a few fixed, larger eigenvalues that carry the relevant information. The behavior of the sample eigenvalues of the spiked population model in the high-dimensional case has been thoroughly studied in the past decade; see, e.g., [3,2,19]. In a remarkable result, Baik et al. [2] proved that the asymptotic behavior of the sample eigenvalues experiences a phase transition. If a population eigenvalue from the spike is not big enough, its value cannot be recovered from the samples: the estimated eigenvalue gets pulled towards the bulk, the noisy section of the matrix. On the other hand, if the spike population eigenvalue is bigger than a certain threshold, its value can be recovered from the limit of the estimates, which are, however, [BLANK].",
    "gold_answer": "biased",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "biased",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"biased\"\n}",
      "model_answer": "biased",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3392",
    "folder": "",
    "question": "The expected number of orders per unit time under formulations A and B is given by [BLANK], where Q is the average quantity demanded per unit time and R is the average size of an order.",
    "gold_answer": "Q/R. This formula represents the ratio of the average quantity demanded per unit time to the average size of an order, giving the expected number of orders needed to meet demand.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Q/R",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Q/R\"\n}",
      "model_answer": "Q/R",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2767",
    "folder": "",
    "question": "In the semiparametric transformation model $\\varLambda_{\\theta}(Y)=m(X)+\\varepsilon$, where $X$ is a $d$-dimensional covariate, $Y$ is a univariate dependent variable, and $\\varepsilon$ is an error term independent of $X$, the transformation $\\varLambda_{\\theta}(Y)$ is assumed to belong to a parametric family of strictly increasing functions. The parameter $\\theta$ is estimated using a [BLANK] estimator.",
    "gold_answer": "profile likelihood. The profile likelihood estimator is used for the parameter Î¸ in the semiparametric transformation model, highlighting its role in estimating the transformation parameter within a parametric family of strictly increasing functions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2017\\ScienceDirect_articles_28Feb2025_08-47-51.574\\Goodness-of-fit-tests-in-semiparametric-transforma\\Goodness-of-fit-tests-in-semiparametric-transforma.md",
      "Goodness-of-fit-tests-in-semiparametric-transforma.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "profile likelihood",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"profile likelihood\"\n}",
      "model_answer": "profile likelihood",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2788",
    "folder": "",
    "question": "The Laplace transform of a real scalar random variable X with density f(x) is given by L_f(s) = {sum_{j=1}^{m'}(1 + beta_j s)^{-alpha_j}} exp{-tr A - s tr B + tr(I + s C)^{-1}A}, where R(alpha_j) > 0, R(1 + beta_j s) > 0 for j = 1, ..., m', and C is a real symmetric matrix. The term [BLANK] is crucial for ensuring that L_f(s) is indeed a Laplace transform.",
    "gold_answer": "R(alpha_j) > 0, R(1 + beta_j s) > 0. These conditions are necessary to ensure the convergence of the Laplace transform, making it a valid representation of the density function's transform.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1992\\ScienceDirect_articles_02Mar2025_02-21-35.186\\On-linear-functions-of-certain-noncentral-versions\\On-linear-functions-of-certain-noncentral-versions.md",
      "On-linear-functions-of-certain-noncentral-versions.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "R(alpha_j) > 0, R(1 + beta_j s) > 0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"exp{-tr A - s tr B + tr(I + s C)^{-1}A}\"\n}",
      "model_answer": "exp{-tr A - s tr B + tr(I + s C)^{-1}A}",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3514",
    "folder": "",
    "question": "The joint composite estimating function approach to estimating spatiotemporal covariance structures is rooted in the construction of three sets of estimating functions from spatial, temporal, and [BLANK] cross-pairs, which results in overidentified estimating functions.",
    "gold_answer": "spatiotemporal. This highlights the method's unique approach by combining information from different types of pairs to improve estimation efficiency.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_74_Issue_5\\Joint Composite Estimating Functions in Spatiotemp\\Joint Composite Estimating Functions in Spatiotemp.md",
      "Joint Composite Estimating Functions in Spatiotemp.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "spatiotemporal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"spatiotemporal\"\n}",
      "model_answer": "spatiotemporal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-465",
    "folder": "",
    "question": "The gamma distribution with scale parameter Î¸ and shape parameter Ï, denoted by Î“(Ï,Î¸), is the distribution with probability density f(x;Ï,Î¸) = {Î¸^Ï Î“(Ï)}^-1 x^(Ï-1) exp(-x/Î¸) for x, Ï, Î¸ > 0. The detection of outliers is important for checking data for gross errors and in model-building, especially when the gamma distribution is suggested as a pragmatic fit to skewed data. In the context of testing for outliers in a gamma sample where both parameters are unknown, the test statistic proposed by Kimber (1979) for an outlier in an unspecified direction is Z = max D_i / Î£ D_i, where D_i = -log U_i - (n-1)log{(n-U_i)/(n-1)} and U_i = x_i / xÌ„. A large value of Z is evidence against the null hypothesis H_0. For large Ï, the distribution of Z depends little on Ï, and âˆš{(n-1)Z} approaches the [BLANK], which is the basis for the optimal two-sided test for a single outlier in the Normal (Ï=âˆž) case.",
    "gold_answer": "maximum absolute studentized residual (MASR). This is omitted to highlight the connection between the test statistic Z for gamma samples and its optimal counterpart in the Normal case, emphasizing the utility of Z across different distributions.",
    "source": [
      "Discordancy Testing in Gamma Samples with Both Par.md",
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_32_Issue_3\\Discordancy Testing in Gamma Samples with Both Par\\Discordancy Testing in Gamma Samples with Both Par.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "maximum absolute studentized residual (MASR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"studentized range\"\n}",
      "model_answer": "studentized range",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2356",
    "folder": "",
    "question": "In the penalized h-likelihood (HL) method for variable selection in general semiparametric frailty models, the penalty function that is unbounded at the origin and gives a very good performance in various high-dimensional problems is known as [BLANK].",
    "gold_answer": "HL penalty. This penalty is unbounded at the origin, distinguishing it from other penalties like LASSO and SCAD, and is particularly effective in high-dimensional problems due to its ability to provide oracle shrinkage estimators.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_23\\Issue_4\\Variable_Selection_in_General_Frailty_Models_Using_Penalized_H-Likelihood__Variable_Selection_in_General_Frailty_Models_Using_Penalized_H-Likelihood\\Variable_Selection_in_General_Frailty_Models_Using_Penalized_H-Likelihood__Variable_Selection_in_General_Frailty_Models_Using_Penalized_H-Likelihood.md",
      "Variable_Selection_in_General_Frailty_Models_Using_Penalized_H-Likelihood__Variable_Selection_in_General_Frailty_Models_Using_Penalized_H-Likelihood.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "HL penalty",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"SCAD\"\n}",
      "model_answer": "SCAD",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-993",
    "folder": "",
    "question": "The auxiliary mixture sampler for the stochastic volatility model approximates the bivariate conditional density of (Î¾â‚œ, Î·â‚œ)|dâ‚œ by a [BLANK]-components mixture of bivariate Gaussian densities.",
    "gold_answer": "K. This approximation allows for the efficient sampling of the latent variables by transforming the model into a linear Gaussian state space model conditioned on the mixture component indicator.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "K",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"10\"\n}",
      "model_answer": "10",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3035",
    "folder": "",
    "question": "The higher criticism test statistic is the supremum of a standardized empirical process under the null hypothesis and follows a [BLANK] distribution asymptotically, but its convergence is very slow and its $p$ -value cannot be reliably computed analytically based on asymptotic theory unless $d$ is very large.",
    "gold_answer": "Gumbel. This distribution is mentioned as the asymptotic distribution of the higher criticism test statistic, highlighting the challenge of relying on asymptotic theory for $p$-value computation when $d$ is not sufficiently large.",
    "source": [
      "Analytical_p-value_calculation_for_the_higher_criticism_test_in_finite-d_problems.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_101_Issue_4\\Analytical_p-value_calculation_for_the_higher_criticism_test_in_finite-d_problems\\Analytical_p-value_calculation_for_the_higher_criticism_test_in_finite-d_problems.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Gumbel",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Gumbel\"\n}",
      "model_answer": "Gumbel",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1882",
    "folder": "",
    "question": "In the context of nonparametric drift estimation from diffusions with correlated Brownian motions, the integrated mean squared risk of the proposed nonparametric estimator is bounded and an adaptive procedure is proposed. The dependency is modeled through correlations between the Brownian motions driving the diffusion processes, and the estimator does not use the knowledge of the [BLANK]. What is the missing term?",
    "gold_answer": "correlation matrix. The missing term highlights that the estimator is designed to work without prior knowledge of the correlation structure between the Brownian motions, making it adaptable to various dependency scenarios.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2023\\ScienceDirect_articles_28Feb2025_08-27-52.813\\Nonparametric-drift-estimation-from-diffusions-wit\\Nonparametric-drift-estimation-from-diffusions-wit.md",
      "Nonparametric-drift-estimation-from-diffusions-wit.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "correlation matrix",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"correlation\"\n}",
      "model_answer": "correlation",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2384",
    "folder": "",
    "question": "The Boxâ€“Cox class of power transformations for the response variable Y is defined as y^(Ï) = {(y^Ï - 1)/Ï for Ï â‰  0, log(y) for Ï = 0}. In the methodology described, Ï is limited to the values [BLANK] to ensure interpretability of the transformed predictors.",
    "gold_answer": "(-1, 0, 0.5, 1). These values allow the transformed predictors to be roughly interpreted as the reciprocal, the logarithm, the square root, and the untransformed response, respectively.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "(-1, 0, 0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"-2, -1, -0.5, 0, 0.5, 1, 2\"\n}",
      "model_answer": "-2, -1, -0.5, 0, 0.5, 1, 2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-7",
    "folder": "",
    "question": "The P.D.F. of the tth order statistic in a random sample of size k from a population with C.D.F. F(x) and P.D.F. f(x) at x satisfies the recurrence equation f_{i,k}(x) = [BLANK] - (k - i + 1)/(t - 1)f_{i-1,k}(x) for t=2,3,...,k.",
    "gold_answer": "k/(t - 1)f_{i-1,k-1}(x). This term is crucial for expressing the P.D.F. of the tth order statistic in terms of the P.D.F.s of order statistics from smaller samples.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_54_Issue_1-2\\Recurrence_relations_between_the_P.D.F.'S_of_order_statistics_of_dependent_variables,_and_some_applications\\Recurrence_relations_between_the_P.D.F.'S_of_order_statistics_of_dependent_variables,_and_some_applications.md",
      "Recurrence_relations_between_the_P.D.F.'S_of_order_statistics_of_dependent_variables,_and_some_applications.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "k/(t - 1)f_{i-1,k-1}(x)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"(k - i + 1)/(i)f_{i+1,k}(x)\"\n}",
      "model_answer": "(k - i + 1)/(i)f_{i+1,k}(x)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3007",
    "folder": "",
    "question": "The study concluded that the inheritance of psychical characters, such as ability, follows the same laws as physical characters, with a slope of the regression line around [BLANK].",
    "gold_answer": "0.47. This finding supports the hypothesis that mental and moral characters are inherited in the same manner and with similar intensity as physical traits.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0.5\"\n}",
      "model_answer": "0.5",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2569",
    "folder": "",
    "question": "In the proposed model, the total damage incurred up to time t, X(t), is modeled as the sum of damages from N(t) storms, where N(t) is a [BLANK] process for storm counts.",
    "gold_answer": "Poisson. This term is critical to define the stochastic process used for modeling the number of storm events over time.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Poisson",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Poisson\"\n}",
      "model_answer": "Poisson",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2730",
    "folder": "",
    "question": "In the context of stepped wedge cluster randomized experiments (SW-CREs), the model-assisted ANCOVA estimator that includes treatment-by-covariate interactions but without period-specific covariate effects is referred to as [BLANK].",
    "gold_answer": "ANCOVA III. This model is highlighted for its efficiency and robustness in estimating treatment effects, especially when the number of clusters is limited.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ANCOVA III",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ANCOVA2\"\n}",
      "model_answer": "ANCOVA2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1643",
    "folder": "",
    "question": "In the quantile regression model with power transformation, the basic assumption is that the transformation parameter and the regression coefficient depend on quantiles and may change from quantile to quantile. This model is referred to as [BLANK].",
    "gold_answer": "PQR (Power Transformed Quantile Regression). This is excluded to highlight the model's flexibility and complexity, which allows for different transformations and coefficients across quantiles.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "PQR (Power Transformed Quantile Regression)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"heterogeneous\"\n}",
      "model_answer": "heterogeneous",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-366",
    "folder": "",
    "question": "A proportional-integral-plus (PIP) controller includes an integrated error term to ensure the output tracks the target INR at steady state, despite modelling errors, by adding the term [BLANK] to the control equation.",
    "gold_answer": "kâ‚‚eâ‚œ. This term is crucial for the PIP controller's ability to adjust for cumulative errors over time, enhancing its robustness against model inaccuracies and disturbances.",
    "source": [],
    "category": "CORRECT_BUT_REASONING_MISMATCH",
    "question_context_used": "",
    "gold_answer_parsed": "kâ‚‚eâ‚œ",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"k_I \\\\sum_{j=1}^{i} e(j)\"\n}",
      "model_answer": "k_I \\sum_{j=1}^{i} e(j)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1187",
    "folder": "",
    "question": "The approximate score equations derived from the random subsampling framework are equivalent to logistic regression score equations. This equivalence allows for the use of standard, 'off-the-shelf' software in fitting these models, significantly simplifying the implementation process. The key to this equivalence is the inclusion of an offset related to the [BLANK] in the logistic regression model.",
    "gold_answer": "subsampling rate. This offset accounts for the differential sampling probabilities across time points, ensuring that the logistic regression accurately reflects the underlying recurrent event process.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "subsampling rate",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sampling fraction\"\n}",
      "model_answer": "sampling fraction",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-709",
    "folder": "",
    "question": "In the context of estimating a patterned covariance matrix Î£, the decomposition Î£ = âˆ‘_{i=1}^k Î¸_i M_i involves Î¸_i as the distinct unknown eigenvalues and M_i as a known complete orthogonal set of projection matrices. The problem of estimating Î£ under the loss function L_q(Î£Ì‚, Î£) = tr(Î£Ì‚ - Î£)^2 is dual to the problem of estimating the scale parameters of independent Ï‡^2 distributions under the loss L(Î¸Ì‚, Î¸) = âˆ‘_{i=1}^k p_i (Î¸Ì‚_i - Î¸_i)^2, where p_i = rank(M_i). What is the form of the maximum likelihood estimator (MLE) of Î¸_i^s in this context?",
    "gold_answer": "Q_i^s / p_i^s. The MLE of Î¸_i^s is derived from the likelihood function of the independent Ï‡^2 random variables Q_i, which are scaled by Î¸_i, highlighting the direct relationship between the estimation problems under the specified loss functions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1989\\ScienceDirect_articles_02Mar2025_02-24-23.081\\Improved-estimation-of-a-patterned-covarianc_1989_\\Improved-estimation-of-a-patterned-covarianc_1989_.md",
      "Improved-estimation-of-a-patterned-covarianc_1989_.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Q_i^s / p_i^s",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"y_i/p_i\"\n}",
      "model_answer": "y_i/p_i",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-77",
    "folder": "",
    "question": "In the context of testing linearity of regression, the simple formula suggested for Î£â‚šÂ² is Î£â‚šÂ² = (1/N) * ( (1/rÂ²) - (1/Î·Â²) ), under the assumption that [BLANK] is small.",
    "gold_answer": "Î¶/r",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¶/r",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1/Î·Â² - 1/rÂ²\"\n}",
      "model_answer": "1/Î·Â² - 1/rÂ²",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-675",
    "folder": "",
    "question": "In the context of optimal designs for $s^{n}$ factorial experiments with correlated observations within blocks, the varianceâ€“covariance matrix of the observational vector is given by $Var(\\mathbf{Y})=\\sigma^{2}D\\left(\\Sigma_{1},\\Sigma_{2},\\dots,\\Sigma_{b}\\right)$ where $\\boldsymbol{\\Sigma_{i}}=(1-\\rho)\\mathbf{I}_{k_{i}}+\\rho\\mathbf{J}_{k_{i}}$. What does $\\mathbf{J}_{k_{i}}$ represent in this equation?",
    "gold_answer": "$\\mathbf{J}_{k_{i}}$ represents a $k_{i} \\times k_{i}$ matrix of all ones. This is used to model the correlation structure within blocks, indicating that any two observations within the same block have a constant correlation $\\rho$.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2006\\ScienceDirect_articles_04Mar2025_14-47-36.948\\Optimal-sn-factorial-designs-when-observations_200\\Optimal-sn-factorial-designs-when-observations_200.md",
      "Optimal-sn-factorial-designs-when-observations_200.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\mathbf{J}_{k_{i}}$ represents a $k_{i} \\times k_{i}$ matrix of all ones",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"a matrix of all ones of order k_i\"\n}",
      "model_answer": "a matrix of all ones of order k_i",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1529",
    "folder": "",
    "question": "In the RKHS functional regression model, the expression âŸ¨X, Î²âŸ©_K must be interpreted as Ïˆ_X^{-1}(Î²), where Ïˆ_X is defined in terms of the process X. What does Ïˆ_X(Y)(t) represent?",
    "gold_answer": "Ïˆ_X(Y)(t) = E[Y{X(t) - m(t)}]. This represents the function that maps a random variable Y to its covariance with the centered process X(t) - m(t), highlighting the role of Ïˆ_X in connecting the RKHS with the space of random variables.",
    "source": [
      "An-RKHS-model-for-variable-selection-in-function_2.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2019\\ScienceDirect_articles_28Feb2025_08-42-33.752\\An-RKHS-model-for-variable-selection-in-function_2\\An-RKHS-model-for-variable-selection-in-function_2.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ïˆ_X(Y)(t) = E[Y{X(t) - m(t)}]",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"âŸ¨X(t,Â·), YâŸ©_K\"\n}",
      "model_answer": "âŸ¨X(t,Â·), YâŸ©_K",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2239",
    "folder": "",
    "question": "The recurrence relation for the content of regular hyperspherical simplices is given by V_{Î²,Î²}(Î¸) = 1/2^Î² + (Î²(Î²-1))/(4Ï€) âˆ«_{Ï€/2}^{Î¸} V_{Î²-2,Î²-2}(Ï†(Î¸')) dÎ¸', where Ï†(Î¸') = cos^{-1}(Î»/(1-2Î»)) and Î» = [BLANK].",
    "gold_answer": "-cos(Î¸'). This defines the transformation used in the recurrence relation for simplifying the integral.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "-cos(Î¸')",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sin^2(Î¸'/2)\"\n}",
      "model_answer": "sin^2(Î¸'/2)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3571",
    "folder": "",
    "question": "The estimator for the reciprocal-shape parameter of the Weibull distribution, as described, uses two suitably selected order statistics from a sample of N failure times and is given by the formula: \\(\\widehat{\\gamma}=(\\ln T_{(m)}-\\ln T_{(l)})B(N,l,m)\\), where \\(B(N,l,m)\\) is an unbiasing factor determined by \\(E(\\hat{\\gamma})=\\gamma\\). The normalized variance of the estimator is denoted by [BLANK]. What term is used to denote this normalized variance?",
    "gold_answer": "\\(g^{2}(N,l,m)\\). This term represents the variance of the estimator \\(\\widehat{\\gamma}\\) normalized by \\(\\gamma^{2}\\), highlighting its relative variability.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_37_Issue_1\\Estimation of Weibull Parameters from Two-Order St\\Estimation of Weibull Parameters from Two-Order St.md",
      "Estimation of Weibull Parameters from Two-Order St.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "\\(g^{2}(N,l,m)\\)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"V\"\n}",
      "model_answer": "V",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-967",
    "folder": "",
    "question": "The estimator FÌ‚_B(z), proposed as an alternative to NP MLE and self-consistent estimators, is obtained by assigning heavier weights to all 'observed failures' and is defined as [BLANK].",
    "gold_answer": "FÌ‚_B(z) = âˆ_{z_j < z, Î´_j = 1, A_j = 1} (1 - d_j / r_j)^{1/pÌ‚}. This estimator adjusts for the uncertainty in cause-of-death assessments by emphasizing the contributions of observed failures, where pÌ‚ is the estimated probability of observing the cause of death.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "FÌ‚_B(z) = âˆ_{z_j < z, Î´_j = 1, A_j = 1} (1 - d_j / r_j)^{1/pÌ‚}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"FÌ‚_B(z) = 1 - âˆ_{i:z_iâ‰¥z} (1 - 1/N_i)^{Î´_i}\"\n}",
      "model_answer": "FÌ‚_B(z) = 1 - âˆ_{i:z_iâ‰¥z} (1 - 1/N_i)^{Î´_i}",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2914",
    "folder": "",
    "question": "In the context of soft calibration for selection bias problems under mixed-effects models, the main idea is to calibrate the biased sample to the benchmark by adjusting the subject weights. However, hard calibration can produce enormous weights when an exact calibration is enforced on a large set of extraneous covariates. To address this, the article proposes a [BLANK] scheme, where the outcome and the selection indicator follow mixed-effect models.",
    "gold_answer": "soft calibration. This approach imposes an exact calibration on the fixed effects and an approximate calibration on the random effects, offering a more efficient estimation compared to hard calibration.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_110_Issue_4\\Soft_calibration_for_selection_bias_problems_under_mixed-effects_models\\Soft_calibration_for_selection_bias_problems_under_mixed-effects_models.md",
      "Soft_calibration_for_selection_bias_problems_under_mixed-effects_models.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "soft calibration",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"soft calibration\"\n}",
      "model_answer": "soft calibration",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1777",
    "folder": "",
    "question": "In the context of Bayesian nonparametric models for circular data, the projected PÃ³lya tree (PPT) model is centered around a parametric probability measure, typically a bivariate normal distribution. The projection of this bivariate distribution to the unit circle defines the PPT model, which is characterized by its depth M, precision parameter Î±, and a function Ï(m) that controls the speed of variance decay. The function Ï(m) is suggested to be Ï(m) = m^Î´, where Î´ > 1 ensures the process is absolutely continuous. What value of Î´ is suggested to maximize the dispersion of a finite tree and make the prior less informative?",
    "gold_answer": "Î´ = 1.1. This value is suggested to maximize the dispersion of a finite tree and make the prior less informative, as it is close to one but still ensures the process is absolutely continuous.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_30\\Issue_4\\Projected_PÃ³lya_Tree__Projected_P_lya_Tree\\Projected_PÃ³lya_Tree__Projected_P_lya_Tree.md",
      "Projected_PÃ³lya_Tree__Projected_P_lya_Tree.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î´ = 1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"2\"\n}",
      "model_answer": "2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-256",
    "folder": "",
    "question": "In bioequivalence studies, the FDA recommends a $2\\times2$ crossover design where typically 24 subjects are randomly divided into two groups. One group is given the brand-name drug first and then the new drug after a wash-out period, while the other group is treated in the reverse order. The blood samples are collected from each subject at various times to obtain a blood concentration curve against time of a certain ingredient. The three most typical characteristics of the blood concentration curve considered are the area under the concentration curve, [BLANK], the maximum concentration, $C_{\\mathrm{max}}$, and the time to reach the maximum concentration, $T_{\\mathrm{max}}$. Which characteristic is missing here?",
    "gold_answer": "AUC (Area Under the Curve). This is one of the key pharmacokinetic parameters used to assess the extent of drug absorption in bioequivalence studies.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_86_Issue_2\\Statistical_tests_for_multivariate_bioequivalence\\Statistical_tests_for_multivariate_bioequivalence.md",
      "Statistical_tests_for_multivariate_bioequivalence.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "AUC (Area Under the Curve)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"AUC\"\n}",
      "model_answer": "AUC",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3082",
    "folder": "",
    "question": "In the context of conditional versions of Spearmanâ€™s rho, the measure Ï(g) is defined as the normalized average distance between the copula C and the independence copula Î , weighted by a function g. The formula is given by Ï(g) = [âˆ«[0,1]d C(u)g(u)du - âˆ«[0,1]d Î (u)g(u)du] / [âˆ«[0,1]d M(u)g(u)du - âˆ«[0,1]d Î (u)g(u)du]. What key function is omitted in the numerator to emphasize the weighted difference between the copula C and the independence copula Î ?",
    "gold_answer": "C(u)g(u). This is omitted to highlight that the numerator represents the weighted difference between the copula C and the independence copula Î , emphasizing the role of the weighting function g in measuring dependence.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "C(u)g(u)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"g(u)\"\n}",
      "model_answer": "g(u)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1273",
    "folder": "",
    "question": "In the context of estimating parameters with values in a manifold, the CramÃ©r-Rao type lower bound for minimum loss unbiased estimators is derived, and the corresponding notion of [BLANK] is investigated.",
    "gold_answer": "efficiency. This term is omitted to highlight the focus on how well an estimator performs relative to the lower bound, which is a key aspect of the investigation.",
    "source": [
      "A-Cram-r-Rao-type-lower-bound-for-estimators-with_.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1991\\ScienceDirect_articles_02Mar2025_02-22-27.434\\A-Cram-r-Rao-type-lower-bound-for-estimators-with_\\A-Cram-r-Rao-type-lower-bound-for-estimators-with_.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "efficiency",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"efficiency\"\n}",
      "model_answer": "efficiency",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-258",
    "folder": "",
    "question": "In the proximal distance algorithm for sparse covariance estimation, the objective function is minimized subject to the constraint that the covariance matrix belongs to the sparsity set. The sparsity set is defined as all symmetric matrices with at most [BLANK] nonzero entries in their upper triangle.",
    "gold_answer": "2K. The sparsity set is defined to include all symmetric matrices with at most 2K nonzero entries in their upper triangle, where K is the number of nonzero entries specified for the upper triangle, and the diagonal entries are unconstrained.",
    "source": [
      "A_proximal_distance_algorithm_for_likelihood-based_sparse_covariance_estimation.md",
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_109_Issue_4\\A_proximal_distance_algorithm_for_likelihood-based_sparse_covariance_estimation\\A_proximal_distance_algorithm_for_likelihood-based_sparse_covariance_estimation.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "2K",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"k\"\n}",
      "model_answer": "k",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1157",
    "folder": "",
    "question": "In the context of multivariate branching-Markov processes (BMP), the limit distributions of the estimators are shown to be mixtures of normals rather than normal. This is due to the models discussed in this paper belonging to the [BLANK] family.",
    "gold_answer": "local asymptotic mixed normal (LAMN). This family is significant because it leads to non-standard limit results for estimators and tests, distinguishing BMP models from those with standard normal limit distributions.",
    "source": [
      "Asymptotic-optimal-inference-for-multivariate-bran.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2011\\ScienceDirect_articles_01Mar2025_03-44-48.419\\Asymptotic-optimal-inference-for-multivariate-bran\\Asymptotic-optimal-inference-for-multivariate-bran.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "local asymptotic mixed normal (LAMN)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"curved exponential\"\n}",
      "model_answer": "curved exponential",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-666",
    "folder": "",
    "question": "In the context of high-dimensional generalized linear models, ridge estimators regularize the squared Euclidean lengths of parameters and involve tuning parameters that need to be calibrated. The paper suggests modifying ridge estimators to avoid tuning parameters altogether, leading to an estimator referred to as [BLANK].",
    "gold_answer": "t-ridge. This modification integrates the calibration of the tuning parameter directly into the estimation process, eliminating the need for external calibration methods like cross-validation.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "t-ridge",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Stein-type estimator\"\n}",
      "model_answer": "Stein-type estimator",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2072",
    "folder": "",
    "question": "A key assumption in the model for missing response values is that the missingness mechanism is [BLANK], allowing the full data model to be specified independently of the observed data model.",
    "gold_answer": "ignorable. This assumption simplifies the analysis by enabling the use of the same inference techniques without explicitly modeling the missingness mechanism.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ignorable",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ignorable\"\n}",
      "model_answer": "ignorable",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1888",
    "folder": "",
    "question": "In the context of binomial sampling schemes, the information about the unknown proportion Î¸ can be measured using Shannon's concept of information, which is expressed as IÎ¸ = âˆ« p(Î¸)log p(Î¸)dÎ¸. This integral is unique apart from an arbitrary multiplying constant, which is incorporated in the arbitrariness of the [BLANK].",
    "gold_answer": "base of the logarithm. This highlights the flexibility in choosing the logarithmic base when calculating Shannon's information measure, without affecting the fundamental properties of the measure.",
    "source": [
      "BINOMIAL_SAMPLING_SCHEMES_AND_THE_CONCEPT_OF_INFORMATION.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_44_Issue_1-2\\BINOMIAL_SAMPLING_SCHEMES_AND_THE_CONCEPT_OF_INFORMATION\\BINOMIAL_SAMPLING_SCHEMES_AND_THE_CONCEPT_OF_INFORMATION.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "base of the logarithm",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"base of the logarithm\"\n}",
      "model_answer": "base of the logarithm",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-746",
    "folder": "",
    "question": "In the context of marked point processes, the nth order intensity/product density function Ï(n) can be expressed in terms of the nth order product density of the ground process Ïg(n) and a conditional density function fx1,...,xn(Â·) on the mark space. The expression is Ï(n)((x1,m1),...,(xn,mn)) = [BLANK] Ã— Ïg(n)(x1,...,xn). What is the missing term that describes the joint distribution of n marks given their associated ground process points?",
    "gold_answer": "fx1,...,xn(m1,...,mn). This term is crucial as it describes how the marks are jointly distributed given the locations of their associated points in the ground process, linking the spatial and mark components of the point process.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_33\\Issue_2\\Local_Inhomogeneous_Weighted_Summary_Statistics_for_Marked_Point_Processes__Local_Inhomogeneous_Weighted_Summary_Statistics_for_Marked_Point_Processes\\Local_Inhomogeneous_Weighted_Summary_Statistics_for_Marked_Point_Processes__Local_Inhomogeneous_Weighted_Summary_Statistics_for_Marked_Point_Processes.md",
      "Local_Inhomogeneous_Weighted_Summary_Statistics_for_Marked_Point_Processes__Local_Inhomogeneous_Weighted_Summary_Statistics_for_Marked_Point_Processes.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "fx1,",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"fx1,...,xn(m1,...,mn)\"\n}",
      "model_answer": "fx1,...,xn(m1,...,mn)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-126",
    "folder": "",
    "question": "In the context of generalized structured models, the equation $$\\Lambda(Y)=G\\{Z,\\beta,g(X)\\}+S\\{U,\\gamma,s(T)\\}\\epsilon,$$ with $E(\\epsilon\\mid Z,X,U,T)\\:=\\:0$, includes known functions $\\Lambda, G$, and $S$, unknown finite-dimensional parameters $\\beta,\\gamma$, and unknown nonparametric functions $g(\\cdot),s(\\cdot)$. The dependent variable $Y$ and observed covariates $(Z,X,U,T)$ are part of this model. What critical element is represented by [BLANK] in this equation?",
    "gold_answer": "$\\epsilon$, which represents the error term with conditional mean zero given the covariates. This element is crucial as it captures the random variation in the dependent variable $Y$ not explained by the model's systematic part.",
    "source": [
      "Backfitting_tests_in_generalized_structured_models.md",
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_109_Issue_1\\Backfitting_tests_in_generalized_structured_models\\Backfitting_tests_in_generalized_structured_models.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\epsilon$, which represents the error term with conditional mean zero given the covariates",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"epsilon\"\n}",
      "model_answer": "epsilon",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1966",
    "folder": "",
    "question": "In the context of wavelet-based functional linear mixed models, the discrete wavelet transform (DWT) is used to approximate the sample curve, x(t), using a finite basis expansion. The equation for this approximation is x(t) = Î£ from l=1 to L_S of c_Sl Ï†_Sl(t) + Î£ from s=1 to S Î£ from l=1 to L_s of d_sl Ïˆ_sl(t). What does the term [BLANK] represent in this equation?",
    "gold_answer": "d_sl Ïˆ_sl(t). This term represents the detail coefficients at scale s and location l, capturing finer details of the curve.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "d_sl Ïˆ_sl(t)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï†_Sl(t)\"\n}",
      "model_answer": "Ï†_Sl(t)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-528",
    "folder": "",
    "question": "A key constraint for a function $_g$ to be the density generator of an elliptical distribution is $s_{d}\\int_{0}^{\\infty}r^{d-1}g(r^{2})d r=s_{d}\\int_{0}^{\\infty}t^{d/2-1}g(t)d t/2=[BLANK]$.",
    "gold_answer": "1. This value is omitted to underscore the normalization condition that density generators must satisfy.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2770",
    "folder": "",
    "question": "The proposed semiparametric Wald statistic for testing Hâ‚€: AUC = AUCâ‚€ versus Hâ‚: AUC â‰  AUCâ‚€ under model (1.2) is given by á»¸â‚™ = âˆšn(ÃƒUC - AUCâ‚€)/ÏƒÌƒ, where ÏƒÌƒÂ² is the [BLANK] of ÏƒÂ²(Î±â‚€, Î²â‚€, G).",
    "gold_answer": "maximum semiparametric likelihood estimator. This estimator is used to approximate the asymptotic variance of the test statistic under the null hypothesis.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "maximum semiparametric likelihood estimator",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"consistent estimator\"\n}",
      "model_answer": "consistent estimator",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1249",
    "folder": "",
    "question": "In the context of group selection and shrinkage for semiparametric additive models, the group subset estimator with shrinkage can be expressed as minimizing the sum of the loss function and two penalty terms. The first penalty term controls group sparsity via group subset selection, and the second penalty term introduces shrinkage via group lasso. The missing term in the equation is [BLANK], where Î»0k and Î»1k are tuning parameters for the k-th group.",
    "gold_answer": "Î»0kðŸ™(â€–Î²kâ€–â‰ 0) + Î»1kâ€–Î²kâ€–. This term combines the penalties for group subset selection (Î»0kðŸ™(â€–Î²kâ€–â‰ 0)) and group lasso (Î»1kâ€–Î²kâ€–), allowing for both sparsity within groups and shrinkage of the coefficients.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_33\\Issue_4\\Group_Selection_and_Shrinkage_Structured_Sparsity_for_Semiparametric_Additive_Models__Group_Selection_and_Shrinkage__Structured_Sparsity_for_Semiparametric_Additive_Models\\Group_Selection_and_Shrinkage_Structured_Sparsity_for_Semiparametric_Additive_Models__Group_Selection_and_Shrinkage__Structured_Sparsity_for_Semiparametric_Additive_Models.md",
      "Group_Selection_and_Shrinkage_Structured_Sparsity_for_Semiparametric_Additive_Models__Group_Selection_and_Shrinkage__Structured_Sparsity_for_Semiparametric_Additive_Models.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î»0kðŸ™(â€–Î²kâ€–â‰ 0) + Î»1kâ€–Î²kâ€–",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»0k||Î²k||0 + Î»1k||Î²k||2\"\n}",
      "model_answer": "Î»0k||Î²k||0 + Î»1k||Î²k||2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2177",
    "folder": "",
    "question": "In the context of two-stage maximum likelihood estimation for copulas, the estimator is consistent for a well-defined least false parameter value, different from the analogous least false parameter associated with the full maximum likelihood procedure. This least false parameter value is denoted as [BLANK].",
    "gold_answer": "Î·â‚€,â‚‚ML. This notation is used to simplify the representation of the least false parameter value associated with two-stage maximum likelihood estimation, distinguishing it from the full maximum likelihood procedure's least false parameter.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î·â‚€,â‚‚ML",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¸â‚€â‚‚\"\n}",
      "model_answer": "Î¸â‚€â‚‚",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-306",
    "folder": "",
    "question": "In the Poisson field of discs model, the probability that a primary disc of radius râ‚€ will remain a circular clump of radius râ‚€ in the final pattern is given by P(râ‚€) = exp[-Î»Ï€{4râ‚€âˆ«â‚€^{râ‚€} r f(r) dr + âˆ«_{râ‚€}^âˆž (râ‚€ + r)Â² f(r) dr}]. The secondary density f* is then proportional to [BLANK].",
    "gold_answer": "P(râ‚€)f(râ‚€). This is because the secondary density f* accounts for the probability that a disc remains a circular clump and its original distribution f(râ‚€).",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_67_Issue_1\\Parameter_estimation_in_the_Poisson_field_of_discs\\Parameter_estimation_in_the_Poisson_field_of_discs.md",
      "Parameter_estimation_in_the_Poisson_field_of_discs.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "P(râ‚€)f(râ‚€)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"exp[-Î»Ï€{4râ‚€âˆ«â‚€^{râ‚€} r f(r) dr + âˆ«_{râ‚€}^âˆž (râ‚€ + r)Â² f(r) dr}]\"\n}",
      "model_answer": "exp[-Î»Ï€{4râ‚€âˆ«â‚€^{râ‚€} r f(r) dr + âˆ«_{râ‚€}^âˆž (râ‚€ + r)Â² f(r) dr}]",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1310",
    "folder": "",
    "question": "In the supercritical case of a BRW, if the process begins with a single particle at the origin and condition C(i,j) holds for all pairs i,j, then Nâ‚™(yâ‚™)/Ïâ¿ â†’ vÏ†áµ£(y)W as nâ†’âˆž, where W is the almost sure limit of [BLANK].",
    "gold_answer": "Nâ‚™uâ€²/Ïâ¿. This result is part of the limit theorems for supercritical BRWs, showing convergence to a limiting distribution scaled by the largest eigenvalue Ï.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Nâ‚™uâ€²/Ïâ¿",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Nâ‚™/Ïâ¿\"\n}",
      "model_answer": "Nâ‚™/Ïâ¿",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-368",
    "folder": "",
    "question": "The robust stability margin, denoted as R(K,Î”â‚œáµƒ), quantifies the system's stability under parameter uncertainty, where a value greater than [BLANK] indicates no parameter in the uncertainty set destabilizes the system.",
    "gold_answer": "1. This threshold signifies that the system remains stable across the entire range of parameter variations considered, a key indicator of controller robustness.",
    "source": [],
    "category": "CORRECT_BUT_REASONING_MISMATCH",
    "question_context_used": "",
    "gold_answer_parsed": "1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"1\"\n}",
      "model_answer": "1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3203",
    "folder": "",
    "question": "In the context of length-biased sampling, the density of the length-biased version $T_{\\mathrm{LB}}$ is given by $F_{\\mathrm{LB}}(t)=\\int_{0}^{t}x d F_{T}(x)\\mu_{T}^{-1}$ , $t\\geq0$ , where $\\mu_{T}$ is the mean of the distribution given by $\\textstyle\\int_{0}^{\\infty}x d F_{T}(x)$. The term [BLANK] is crucial for understanding the transformation from the original distribution to its length-biased counterpart.",
    "gold_answer": "$\\mu_{T}^{-1}$. This term scales the integral to ensure the length-biased distribution is properly normalized, reflecting the increased likelihood of observing longer intervals under length-biased sampling.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2022_Volume_49_Issue_2\\Scandinavian J Statistics - 2021 - Roy - Efficienc\\Scandinavian J Statistics - 2021 - Roy - Efficienc.md",
      "Scandinavian J Statistics - 2021 - Roy - Efficienc.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\mu_{T}^{-1}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¼_T\"\n}",
      "model_answer": "Î¼_T",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1283",
    "folder": "",
    "question": "The two-term Edgeworth expansion for the density function fn(x) includes a term that is a homogeneous polynomial in x of degree [BLANK].",
    "gold_answer": "3j",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "3j",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"3\"\n}",
      "model_answer": "3",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3036",
    "folder": "",
    "question": "In the context of generalized estimating equations (GEE), valid inference requires the mean for the response at time $t$ to be expressed properly as a function of the complete past, present, and future values of any time-varying covariate. This condition is especially important with environmental exposures, where it may be necessary to express the response as a function of multiple lagged values of the covariate series. The condition that ensures the mean, given all past, present, and future covariate values, is equal to the cross-sectional mean is known as [BLANK].",
    "gold_answer": "the full covariate conditional mean (FCCM) equality to the cross-sectional mean (CSM). This condition is crucial to avoid bias in parameter estimates for time-varying covariates when using nonindependence working correlation matrices in GEE.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_6_Issue_4\\Regression analysis of longitudinal binary data wi\\Regression analysis of longitudinal binary data wi.md",
      "Regression analysis of longitudinal binary data wi.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the full covariate conditional mean (FCCM) equality to the cross-sectional mean (CSM)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"exogeneity\"\n}",
      "model_answer": "exogeneity",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1798",
    "folder": "",
    "question": "In the context of matrix completion, the Adaptive-Impute algorithm iteratively applies thresholded SVD with data-dependent thresholding parameters. The algorithm's estimate enjoys the minimax error rate, and the thresholding scheme can be viewed as a solution to a [BLANK] optimization problem.",
    "gold_answer": "nonconvex. The thresholding scheme of Adaptive-Impute is attempting to solve a nonconvex optimization problem, which is challenging for theoretical guarantees but provides superior empirical performances.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_28\\Issue_2\\Intelligent_Initialization_and_Adaptive_Thresholding_for_Iterative_Matrix_Completion__Some_Statistical_and_Algorithmic_Theory_for_Adaptive-Impute\\Intelligent_Initialization_and_Adaptive_Thresholding_for_Iterative_Matrix_Completion__Some_Statistical_and_Algorithmic_Theory_for_Adaptive-Impute.md",
      "Intelligent_Initialization_and_Adaptive_Thresholding_for_Iterative_Matrix_Completion__Some_Statistical_and_Algorithmic_Theory_for_Adaptive-Impute.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "nonconvex",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"convex\"\n}",
      "model_answer": "convex",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-265",
    "folder": "",
    "question": "In the context of multi-phase case-control studies, the semiparametric maximum likelihood approach can be implemented by including additional intercept terms in the logistic model and then making some simple corrections to the score and information equations used in a Newtonâ€“Raphson or Fisher-scoring maximization of the prospective loglikelihood. The theoretical derivations apply to arbitrary binary regression models but results are presented for [BLANK] regression.",
    "gold_answer": "logistic. The focus on logistic regression is due to its widespread use in case-control studies and the ease with which the approach can be implemented and interpreted within this framework.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_97_Issue_2\\Efficient_estimation_in_multi-phase_case-control_studies\\Efficient_estimation_in_multi-phase_case-control_studies.md",
      "Efficient_estimation_in_multi-phase_case-control_studies.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "logistic",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"logistic\"\n}",
      "model_answer": "logistic",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-747",
    "folder": "",
    "question": "In the context of mean field variational Bayesian inference for nonparametric regression with measurement error, the model for the responses is given by yáµ¢ = f(xáµ¢) + Îµáµ¢, where Îµáµ¢ are i.i.d. N(0, [BLANK]). What is the variance of the error terms Îµáµ¢?",
    "gold_answer": "Ïƒáµ¢Â². This represents the variance of the error terms in the nonparametric regression model, indicating the spread of the residuals around the function f(xáµ¢).",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2013\\ScienceDirect_articles_04Mar2025_11-08-21.422\\Mean-field-variational-Bayesian-inference-for-non_\\Mean-field-variational-Bayesian-inference-for-non_.md",
      "Mean-field-variational-Bayesian-inference-for-non_.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ïƒáµ¢Â²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ÏƒÂ²\"\n}",
      "model_answer": "ÏƒÂ²",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-290",
    "folder": "",
    "question": "In the context of multivariate linear regression, the Akaike information criterion (AIC) and the Mallows' $C_{p}$ criterion are proposed as approximately unbiased estimators for their risks or underlying criterion functions. The paper proposes modified versions of AIC and $C_{p}$ to reduce bias in situations where the collection of candidate models includes both underspecified and overspecified models. The modified AIC is intended to provide better approximations to their risk functions, and better model selection, than the original AIC and $C_{p}$. The modified AIC is defined by $\\mathbf{MAIC}=n\\log|\\hat{\\Sigma}_{j}|+p n\\log2\\pi+B_{A}^{(1)}+\\hat{B}_{A}^{(2)}$, where $B_{A}^{(1)}$ is defined as $\\frac{n(n+k_{j})p}{n-k_{j}-p-1}$. What is the term $\\hat{B}_{A}^{(2)}$ in the modified AIC formula?",
    "gold_answer": "$\\hat{B}_{A}^{(2)}$ is defined from $B_{A}^{(2)}$ by substituting $\\hat{\\Lambda}$ for $\\pmb{\\Lambda}$ in the equation $B_{A}^{(2)}=2k_{j}\\mathrm{tr}(\\Lambda-I_{p})-\\{\\mathrm{tr}(\\Lambda-I_{p})\\}^{2}-\\mathrm{tr}\\left\\{(\\Lambda-I_{p})^{2}\\right\\}$. This term is crucial for adjusting the bias in the modified AIC, especially in underspecified cases, by accounting for the latent roots of $\\Lambda$ through the estimator $\\widehat{\\Lambda}=\\frac{n-k}{n-k_{\\omega}}\\widehat{\\Sigma}_{\\omega}\\widehat{\\Sigma}_{j}^{-1}$.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_84_Issue_3\\Modified_AIC_and_Cp_in_multivariate_linear_regression\\Modified_AIC_and_Cp_in_multivariate_linear_regression.md",
      "Modified_AIC_and_Cp_in_multivariate_linear_regression.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$\\hat{B}_{A}^{(2)}$ is defined from $B_{A}^{(2)}$ by substituting $\\hat{\\Lambda}$ for $\\pmb{\\Lambda}$ in the equation $B_{A}^{(2)}=2k_{j}\\mathrm{tr}(\\Lambda-I_{p})-\\{\\mathrm{tr}(\\Lambda-I_{p})\\}^{2}-\\mathrm{tr}\\left\\{(\\Lambda-I_{p})^{2}\\right\\}$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"2tr(Î£Ì‚â‚€â»Â¹Î£Ì‚â±¼)\"\n}",
      "model_answer": "2tr(Î£Ì‚â‚€â»Â¹Î£Ì‚â±¼)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3223",
    "folder": "",
    "question": "In the context of analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response Yáµ¢â±¼ can be written as logit[ P(Yáµ¢â±¼ â‰¤ r) ] = Î±áµ£ + xáµ¢â±¼áµ€Î² + [BLANK], where Î±áµ£ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "báµ¢ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "báµ¢ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"báµ¢\"\n}",
      "model_answer": "báµ¢",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-657",
    "folder": "",
    "question": "The [BLANK] allocation method distributes the sample size in proportion to the size of each stratum.",
    "gold_answer": "proportional",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "proportional",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"proportional\"\n}",
      "model_answer": "proportional",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3303",
    "folder": "",
    "question": "The statistic $M_{\\sun}$ is defined as $(F/t_{m s}-1)(F/t_{m s}+1)^{-1}$. It approaches $+1\\cdot0$ when $F\\gg t_{m s}$, equals zero when $F=t_{m s}$, and approaches $-1{\\cdot}0$ if $F\\ll t_{m\\pmb{\\theta}}$. For the special case $p=2$, regression algebra shows that a lower value is not possible, giving $\\pmb{M}$ a lower bound of [BLANK].",
    "gold_answer": "-0Â·33. This value is derived from regression algebra for the special case when there are two regressors, indicating the minimum possible value of the M statistic under these conditions.",
    "source": [
      "A Regression Assessment Statistic.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_24_Issue_1\\A Regression Assessment Statistic\\A Regression Assessment Statistic.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "-0Â·33",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"-1.0\"\n}",
      "model_answer": "-1.0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-347",
    "folder": "",
    "question": "In the context of meta-analysis, the simple heterogeneity variance estimator proposed is denoted by [BLANK], which is derived from the weighted residual sum of squares in the framework of a linear regression model without covariates.",
    "gold_answer": "SH (Simple Heterogeneity). This notation is used to distinguish the proposed estimator from other estimators in the literature, emphasizing its simplicity and the method of derivation.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_54_Issue_2\\Simple Heterogeneity Variance Estimation for Meta-\\Simple Heterogeneity Variance Estimation for Meta-.md",
      "Simple Heterogeneity Variance Estimation for Meta-.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "SH (Simple Heterogeneity)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"DL\"\n}",
      "model_answer": "DL",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2757",
    "folder": "",
    "question": "The iterative scheme (2.11) is an example of the [BLANK], which is known for its efficiency in solving optimization problems by breaking them into smaller, more manageable parts.",
    "gold_answer": "alternating direction method of multipliers (ADMM). This highlights the method's foundation in distributed optimization and statistical learning, leveraging parallel processing to enhance computational efficiency.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "alternating direction method of multipliers (ADMM)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"alternating direction method of multipliers\"\n}",
      "model_answer": "alternating direction method of multipliers",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1336",
    "folder": "",
    "question": "In the context of testing uniformity on a circle, the Rayleigh test rejects uniformity for large values of R, where R is defined as the square root of the sum of the squares of the sums of cosine and sine components of the angles. The formula for R is given by R = âˆš[(âˆ‘cosÎ¸áµ¢)Â² + (âˆ‘sinÎ¸áµ¢)Â²], where Î¸áµ¢ are the angles made by the radii through the observations on the circle and an arbitrary fixed reference radius. What critical mathematical operation is applied to the sums of cosine and sine components before taking the square root to compute R?",
    "gold_answer": "Squaring the sums of cosine and sine components. This operation is crucial as it ensures that both components contribute positively to the value of R, regardless of their individual signs, and it is part of the process that leads to the computation of the resultant vector length, which is central to the Rayleigh test.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_56_Issue_2\\On_Hodges's_bivariate_sign_test_and_a_test_for_uniformity_of_a_circular_distribution\\On_Hodges's_bivariate_sign_test_and_a_test_for_uniformity_of_a_circular_distribution.md",
      "On_Hodges's_bivariate_sign_test_and_a_test_for_uniformity_of_a_circular_distribution.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Squaring the sums of cosine and sine components",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"squaring\"\n}",
      "model_answer": "squaring",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1669",
    "folder": "",
    "question": "In the context of estimating multiple precision matrices with cluster fusion regularization, the CRF estimator is defined as minimizing a function that includes a term promoting similarities in precision matrices within the same cluster. This term is controlled by the tuning parameter [BLANK].",
    "gold_answer": "Î»â‚‚. The term is the cluster fusion penalty, which encourages precision matrices within the same cluster to be similar, controlled by the positive tuning parameter Î»â‚‚.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_30\\Issue_4\\Estimating_Multiple_Precision_Matrices_With_Cluster_Fusion_Regularization__Estimating_Multiple_Precision_Matrices_With_Cluster_Fusion_Regularization\\Estimating_Multiple_Precision_Matrices_With_Cluster_Fusion_Regularization__Estimating_Multiple_Precision_Matrices_With_Cluster_Fusion_Regularization.md",
      "Estimating_Multiple_Precision_Matrices_With_Cluster_Fusion_Regularization__Estimating_Multiple_Precision_Matrices_With_Cluster_Fusion_Regularization.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î»â‚‚",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î»\"\n}",
      "model_answer": "Î»",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2644",
    "folder": "",
    "question": "In the estimation of conditional pseudo-copulas, the nonparametric estimator $\\widehat C(\\mathbf{u}\\mid\\mathbf{X}_{n-1}^{n-p}=\\mathbf{y}^{*})$ is constructed using estimates of the joint conditional distribution and the [BLANK].",
    "gold_answer": "conditional marginal cdf's. This approach allows for flexible modeling of dependencies conditional on past observations.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "conditional marginal cdf's",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"marginal conditional distributions\"\n}",
      "model_answer": "marginal conditional distributions",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1121",
    "folder": "",
    "question": "In the context of partially nonstationary multivariate autoregressive models with conditional heteroscedasticity, the least squares estimator of the matrix F is given by [BLANK]. What is the correct formula for the least squares estimator?",
    "gold_answer": "The least squares estimator of F is given by (âˆ‘_{t=1}^n W_t X_{t-1}â€²)(âˆ‘_{t=1}^n X_{t-1} X_{t-1}â€²)^{-1}. This formula is derived by minimizing the sum of squared errors in the model, providing an initial estimate for further refinement through full-rank or reduced-rank maximum likelihood estimation.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_88_Issue_4\\Estimation_for_partially_nonstationary_multivariate_autoregressive_models_with_conditional_heteroscedasticity\\Estimation_for_partially_nonstationary_multivariate_autoregressive_models_with_conditional_heteroscedasticity.md",
      "Estimation_for_partially_nonstationary_multivariate_autoregressive_models_with_conditional_heteroscedasticity.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The least squares estimator of F is given by (âˆ‘_{t=1}^n W_t X_{t-1}â€²)(âˆ‘_{t=1}^n X_{t-1} X_{t-1}â€²)^{-1}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"FÌ‚ = (âˆ‘â‚œâ‚Œâ‚áµ€ Yâ‚œâ‚‹â‚Yâ‚œâ‚‹â‚áµ€)â»Â¹(âˆ‘â‚œâ‚Œâ‚áµ€ Yâ‚œâ‚‹â‚Yâ‚œáµ€)\"\n}",
      "model_answer": "FÌ‚ = (âˆ‘â‚œâ‚Œâ‚áµ€ Yâ‚œâ‚‹â‚Yâ‚œâ‚‹â‚áµ€)â»Â¹(âˆ‘â‚œâ‚Œâ‚áµ€ Yâ‚œâ‚‹â‚Yâ‚œáµ€)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2616",
    "folder": "",
    "question": "In the context of estimating $c$-level partial correlation graphs, the proposed method is adaptive to the 'large $p$, small $n$' scenario commonly seen in whole brain studies. The method incorporates the variation of the estimated partial correlations, which results in higher power compared to the existing methods. The key innovation of the proposed method over graphical Lasso and neighborhood selection is its ability to provide [BLANK] to each pair of partial correlations.",
    "gold_answer": "confidence intervals. This is omitted to highlight the method's capability to offer more detailed statistical inference, distinguishing it from other methods that lack this feature.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_21_Issue_4\\Estimating c-level partial correlation graphs with\\Estimating c-level partial correlation graphs with.md",
      "Estimating c-level partial correlation graphs with.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "confidence intervals",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"confidence intervals\"\n}",
      "model_answer": "confidence intervals",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2392",
    "folder": "",
    "question": "The product moments of existing and new noncentral bimatrix variate beta distributions with bounded domain are derived. From these, exact expressions for the distributions of statistics are obtained by using the [BLANK] transform.",
    "gold_answer": "Mellin. The Mellin transform is used to derive exact expressions for the distributions of statistics from the product moments of noncentral bimatrix variate beta distributions.",
    "source": [
      "Distribution-of-the-product-of-determinants-of-non.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2012\\ScienceDirect_articles_01Mar2025_03-42-53.714\\Distribution-of-the-product-of-determinants-of-non\\Distribution-of-the-product-of-determinants-of-non.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Mellin",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Mellin\"\n}",
      "model_answer": "Mellin",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1516",
    "folder": "",
    "question": "The improvement function introduced in the paper is based on the \"modified maximin fitness function\" which is known to identify well-spaced non-dominated outputs when used in [BLANK].",
    "gold_answer": "multiobjective evolutionary algorithms (MOEAs). This function helps in directing the search towards well-spaced designs close to the true Pareto front.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "multiobjective evolutionary algorithms (MOEAs)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"multi-objective optimization\"\n}",
      "model_answer": "multi-objective optimization",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2649",
    "folder": "",
    "question": "For covariance estimation, a perturbation resampling method is proposed. Perturbed versions of the estimators are obtained by solving S^*(Î³; Ï„) = 0, where S^*(Î³; Ï„) involves weights Î¸_i. What distribution are the Î¸_i generated from?",
    "gold_answer": "The Î¸_i are generated from a unit exponential distribution, which is used to create perturbed versions of the estimators for covariance estimation.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The Î¸_i are generated from a unit exponential distribution, which is used to create perturbed versions of the estimators for covariance estimation",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"standard exponential distribution\"\n}",
      "model_answer": "standard exponential distribution",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2098",
    "folder": "",
    "question": "The 2-term Edgeworth expansion, or the expansion up to order $1/n$ , of the distribution of the sample correlation coefficient in nonnormal observations is obtained. For the expansion, the formula of the [BLANK] of the function of sample variances and covariances of the associated observable variables is given.",
    "gold_answer": "fourth cumulant. This is critical because it provides the necessary information to approximate the distribution of the sample correlation coefficient under nonnormality.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "fourth cumulant",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"asymptotic variance\"\n}",
      "model_answer": "asymptotic variance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1976",
    "folder": "",
    "question": "In the context of signal extraction for nonstationary time series, the method that builds up optimal full model filters from reduced model filters through an iteration scheme is reminiscent of the [BLANK] program's approach.",
    "gold_answer": "X-11. The iterative approach discussed in the paper shares conceptual similarities with the nonparametric method used in the US Census Bureau's X-11 program for seasonal adjustment.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "X-11",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Kalman\"\n}",
      "model_answer": "Kalman",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2099",
    "folder": "",
    "question": "From a simulation, the partially weighted 2-term Edgeworth expansion is found to give smaller errors than those by the single-term or fully weighted 2-term Edgeworth expansions. This suggests that the optimal weight on the added term of order $n^{-1}$ is [BLANK].",
    "gold_answer": "between 0 and 1. This indicates that a partially weighted expansion, rather than fully weighted or unweighted, provides the best approximation under certain conditions.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "between 0 and 1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"between 0 and 1\"\n}",
      "model_answer": "between 0 and 1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1076",
    "folder": "",
    "question": "In the computation of minimal covering ellipsoids, the probability measure Î» can be regarded without confusion as a design weighting on ð’± or ð’°. The theory of optimal design tells us that, no matter what n is, at least [BLANK] of the Î»_i's are non-zero.",
    "gold_answer": "k+1. This is a fundamental property of the optimal design measure, ensuring that the ellipsoid is defined by at least k+1 points, which is necessary for its minimal covering property.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "k+1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"d+1\"\n}",
      "model_answer": "d+1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-216",
    "folder": "",
    "question": "In the context of testing the randomness of points on a line, the sum of squares of intervals along a line was first discussed by [BLANK].",
    "gold_answer": "Greenwood (1946). This reference is omitted to highlight the historical context and the foundational work in the field of randomness tests on a line.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_43_Issue_1-2\\TESTS_FOR_RANDOMNESS_OF_POINTS_ON_A_LINE\\TESTS_FOR_RANDOMNESS_OF_POINTS_ON_A_LINE.md",
      "TESTS_FOR_RANDOMNESS_OF_POINTS_ON_A_LINE.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Greenwood (1946)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Greenwood\"\n}",
      "model_answer": "Greenwood",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2962",
    "folder": "",
    "question": "In the context of envelope methods for reducing estimative variation in multivariate linear regression, the optimization is essentially over the set of all u-dimensional subspaces of â„áµ, which is a Grassmann manifold denoted as [BLANK].",
    "gold_answer": "ð’¢_{u,k}. This notation is used to represent the Grassmann manifold, which is the space of all u-dimensional subspaces in â„áµ, crucial for the optimization process in envelope estimation methods.",
    "source": [
      "Algorithms_for_Envelope_Estimation__Algorithms_for_Envelope_Estimation.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_25\\Issue_1\\Algorithms_for_Envelope_Estimation__Algorithms_for_Envelope_Estimation\\Algorithms_for_Envelope_Estimation__Algorithms_for_Envelope_Estimation.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "ð’¢_{u,k}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Gr(u,k)\"\n}",
      "model_answer": "Gr(u,k)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-619",
    "folder": "",
    "question": "The variance of the number of points in a region for a log Gaussian Cox process increases when the [BLANK] and hence the correlation increases.",
    "gold_answer": "Î²",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î²",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"range parameter\"\n}",
      "model_answer": "range parameter",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-681",
    "folder": "",
    "question": "A key property of dose-finding designs, which stipulates that a design should not escalate the dose after observing a toxic outcome, is called [BLANK].",
    "gold_answer": "Coherence. This principle ensures the safety of dose escalation in clinical trials.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Coherence",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"coherence\"\n}",
      "model_answer": "coherence",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1950",
    "folder": "",
    "question": "In the context of functional mixed effects models, the proposed approach avoids complex modeling and implementation by estimating the fixed effects under the assumption of [BLANK] and then using a nonparametric bootstrap of independent units to construct confidence intervals and conduct tests.",
    "gold_answer": "independence of functional residuals. This approach simplifies the inference process by not requiring the specification of the complex correlation structure of the data, leveraging the bootstrap method to account for all known sources of data dependence.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_19_Issue_2\\Simple fixed-effects inference for complex functio\\Simple fixed-effects inference for complex functio.md",
      "Simple fixed-effects inference for complex functio.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "independence of functional residuals",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"independence\"\n}",
      "model_answer": "independence",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2488",
    "folder": "",
    "question": "The conditional likelihood under the proportional risks model for NCC studies, which conditions on a failure of any type at each failure time, is denoted as [BLANK].",
    "gold_answer": "L2(Î²). This likelihood resembles the full cohort counterpart but with risk sets replaced by sampled risk sets, allowing for the pooling of controls from multiple NCC studies for more efficient estimates.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "L2(Î²)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"L2\"\n}",
      "model_answer": "L2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1091",
    "folder": "",
    "question": "In the simulation study, the performance of the proposed test is evaluated under the presence of outliers, with the degree of contamination represented by p, where p=0.5% indicates a [BLANK] degree of contamination.",
    "gold_answer": "low. This setting allows the assessment of the test's performance under minimal outlier influence, contrasting with higher contamination levels.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "low",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"low\"\n}",
      "model_answer": "low",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-664",
    "folder": "",
    "question": "In the context of estimating a copula when a covariate affects only marginal distributions, the conditional copula of Yâ‚ and Yâ‚‚ given X does not depend on the value of X. This independence is often referred to as the [BLANK] assumption.",
    "gold_answer": "simplifying assumption. This assumption is crucial for simplifying the estimation process by allowing the dependence structure between Yâ‚ and Yâ‚‚ to be modeled independently of the covariate X.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2015_Volume_42_Issue_4\\Scandinavian J Statistics - 2015 - Gijbels - Estim\\Scandinavian J Statistics - 2015 - Gijbels - Estim.md",
      "Scandinavian J Statistics - 2015 - Gijbels - Estim.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "simplifying assumption",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"simplifying\"\n}",
      "model_answer": "simplifying",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2249",
    "folder": "",
    "question": "In the context of robust regression, the DCML estimator is defined by maximizing the likelihood under the constraint that the distance between the initial robust estimator and the proposed estimator is less than a given threshold. This distance is based on the [BLANK] divergence.",
    "gold_answer": "Kullbackâ€“Leibler (KL). The KL divergence is chosen for this purpose because it yields easily manageable results and is a measure of the difference between two probability distributions.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2015\\ScienceDirect_articles_04Mar2025_10-59-54.640\\High-finite-sample-efficiency-and-robustness-base_\\High-finite-sample-efficiency-and-robustness-base_.md",
      "High-finite-sample-efficiency-and-robustness-base_.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Kullbackâ€“Leibler (KL)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Kullback-Leibler\"\n}",
      "model_answer": "Kullback-Leibler",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3029",
    "folder": "",
    "question": "In the proposed method, kernel density estimation is employed within [BLANK]-type procedures to use data from Monte Carlo generations and tabulated critical values jointly.",
    "gold_answer": "Bayesian",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Bayesian",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"bootstrap\"\n}",
      "model_answer": "bootstrap",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2354",
    "folder": "",
    "question": "For a tight Gaussian measure Î¼ in a Banach space X with zero mean, its characteristic functional can be expressed as Ï‡(x*) = exp{-1/2âŸ¨R x*, x*âŸ©}, where R is the [BLANK] operator.",
    "gold_answer": "covariance. This formula represents the Fourier transform of the Gaussian measure, with R capturing the measure's variance structure through its action on the dual space X*.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "covariance",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"covariance\"\n}",
      "model_answer": "covariance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-117",
    "folder": "",
    "question": "A key assumption for the pseudo-partial likelihood estimators is that the matrix APPLE(Ï€) is [BLANK], ensuring the identifiability of the parameter Î².",
    "gold_answer": "positive definite. This assumption guarantees that the parameter Î² can be uniquely identified from the profiled partial likelihood within a compact set.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "positive definite",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"positive definite\"\n}",
      "model_answer": "positive definite",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1639",
    "folder": "",
    "question": "In the context of estimating probability density functions, the Bayesian predictive method uses the estimate q(y|x) = âˆ«p(y|Î¸)p(Î¸|x)dÎ¸, where p(Î¸|x) is a Bayesian posterior density function based on a prior distribution p(Î¸) and the data x. The classical estimative method, in contrast, uses q(y|x) = p{y|Î¸=Î¸^(x)}, where Î¸^(x) is some efficient estimate of Î¸. A goodness-of-fit criterion based on an information measure introduced by Aitchison (1975) evaluates the deviation of an estimate r(y|x) from the true density p(y|Î¸) as âˆ«X pâ€²(x|Î¸)dx âˆ«Y p(y|Î¸)log{p(y|Î¸)/r(y|x)}dy. For the multivariate normal case, the predictive method based on vague prior knowledge is shown to be superior to the estimative method, leading to the estimate q(y|x) = St_d{Î½, m, (1+1/n)S}, where St_d denotes a d-dimensional Student's t distribution. The key element omitted here is the degrees of freedom parameter Î½, which is defined as Î½ = [BLANK].",
    "gold_answer": "Î½ = n - d + 1. This parameter is crucial because it adjusts the tails of the Student's t distribution to account for the uncertainty in estimating the covariance matrix from the data, especially in small samples.",
    "source": [
      "A_two-stage_model_for_growth_curves_which_leads_to_Rao's_covariance_adjusted_estimators.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_64_Issue_1\\A_two-stage_model_for_growth_curves_which_leads_to_Rao's_covariance_adjusted_estimators\\A_two-stage_model_for_growth_curves_which_leads_to_Rao's_covariance_adjusted_estimators.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î½ = n - d + 1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"n-1\"\n}",
      "model_answer": "n-1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3215",
    "folder": "",
    "question": "In the multiple-imputation strategy under a patternâ€“mixture perspective, the overall mixture distribution for the data is obtained by multiplying the subpopulation distribution f(Y | pattern) by [BLANK].",
    "gold_answer": "the proportion of that missingness pattern (f(pattern)). This weighting by the relative frequency of each pattern is essential for combining distributions in a patternâ€“mixture approach.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the proportion of that missingness pattern (f(pattern))",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(pattern)\"\n}",
      "model_answer": "P(pattern)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2331",
    "folder": "",
    "question": "In the Cox proportional hazards model, the baseline hazard function is denoted as [BLANK].",
    "gold_answer": "h0(t). This function represents the hazard when all covariates are zero, serving as a reference for comparing the hazard rates across different groups or levels of covariates.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "h0(t)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"hâ‚€(t)\"\n}",
      "model_answer": "hâ‚€(t)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2585",
    "folder": "",
    "question": "In the context of canonical correlation analysis (CCA), the purpose is to describe the linear interrelations between p- and q-variate random vectors by finding new coordinate systems for both vectors. The covariance matrix between the two random vectors in these new systems is (R,0), where R is a diagonal matrix with descending positive diagonal elements. The new variables and their correlations are called [BLANK] and canonical correlations, respectively.",
    "gold_answer": "canonical variates. This term is used to describe the new variables obtained after transforming the original variables into a new coordinate system where the interrelations are described by canonical correlations.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "canonical variates",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"canonical variables\"\n}",
      "model_answer": "canonical variables",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3549",
    "folder": "",
    "question": "The MAVE method is proposed within the context of semiparametric models and is called the (conditional) minimum average variance estimation (MAVE) method. One of its advantages is that it can achieve a faster rate of consistency for the estimator of the parameters even without [BLANK] the nonparametric link function estimator.",
    "gold_answer": "undersmoothing. This is highlighted to emphasize that, unlike most existing methods which require undersmoothing to achieve a faster consistency rate for parameter estimators, the MAVE method achieves this faster rate without the need to undersmooth the nonparametric link function estimator.",
    "source": [
      "An Adaptive Estimation of Dimension Reduction Spac.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_64_Issue_3\\An Adaptive Estimation of Dimension Reduction Spac\\An Adaptive Estimation of Dimension Reduction Spac.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "undersmoothing",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"undersmoothing\"\n}",
      "model_answer": "undersmoothing",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1266",
    "folder": "",
    "question": "In the non-homogeneous two-state Markov chain model described, the transition probabilities at week t are represented by a matrix where p(t) = P[Y_{t+1} = 0 | Y_t = 0] and q(t) = P[Y_{t+1} = 0 | Y_t = 1]. These probabilities are made to depend on k explanatory variables through the multiple logistic function, where Î±_t = exp[Î¸_{00} + Î¸_{01}x_1(t) + ... + Î¸_{0k}x_k(t)] and Î²_t = exp[Î¸_{10} + Î¸_{11}x_1(t) + ... + [BLANK]]. What is the missing part of the equation for Î²_t?",
    "gold_answer": "Î¸_{1k}x_k(t). This part is crucial for defining how the transition probability from state 1 to state 0 depends on the k-th explanatory variable at week t.",
    "source": [
      "A Logit Model for Infectious Diseases.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_24_Issue_1\\A Logit Model for Infectious Diseases\\A Logit Model for Infectious Diseases.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¸_{1k}x_k(t)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¸_{1k}x_k(t)\"\n}",
      "model_answer": "Î¸_{1k}x_k(t)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1919",
    "folder": "",
    "question": "The performance of the Gaussian process AFT model is evaluated using metrics such as the C-index, integrated Brier score, and integrated AUC. The C-index measures the [BLANK] of the predicted survival times or risk scores.",
    "gold_answer": "concordance. This metric evaluates how well the model predicts the relative ordering of survival times, which is a key aspect of survival analysis.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "concordance",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"concordance\"\n}",
      "model_answer": "concordance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2826",
    "folder": "",
    "question": "In the context of continuous-time information sources, the notion of continuity introduced by Pinsker is equivalent to [BLANK] for stationary processes with a separable metric space as their state space.",
    "gold_answer": "continuity in probability. This equivalence highlights the relationship between two fundamental concepts in the study of stochastic processes and their applications in information theory.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1977\\ScienceDirect_articles_02Mar2025_09-13-45.437\\Equivalence-of-two-notions-of-continuity-for-stati\\Equivalence-of-two-notions-of-continuity-for-stati.md",
      "Equivalence-of-two-notions-of-continuity-for-stati.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "continuity in probability",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ergodicity\"\n}",
      "model_answer": "ergodicity",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1931",
    "folder": "",
    "question": "In the mixed-effect two-stage polytomous model score test (MTOP), the score statistic for the fixed effect Î¸_f under the global null hypothesis is given by [BLANK].",
    "gold_answer": "Q_Î¸_f = (Y - P_f)^T G_M Z_f I_f^{-1} Z_f^T G_M^T (Y - P_f) ~ Ï‡_{l_f}^2. This statistic tests the association between the SNP and disease subtypes, accounting for fixed effects and missing data through the EM algorithm.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Q_Î¸_f = (Y - P_f)^T G_M Z_f I_f^{-1} Z_f^T G_M^T (Y - P_f) ~ Ï‡_{l_f}^2",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"S_f = U_f^T I_{ff}^{-1} U_f\"\n}",
      "model_answer": "S_f = U_f^T I_{ff}^{-1} U_f",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2420",
    "folder": "",
    "question": "In the context of directional multiple hypotheses testing, the loss function considered is of the form L(Î¸, d^X) = Î£ L_i(Î¸_i, d_i^X), where d_i^X âˆˆ {âˆ’1, 0, 1}. Here, d_i^X = âˆ’1 means that [BLANK] is selected.",
    "gold_answer": "H_-^i. This indicates the selection of the hypothesis that Î¸_i is less than 0, representing a directional alternative.",
    "source": [
      "A-Bayesian-decision-theoretic-approach-to-directio.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2013\\ScienceDirect_articles_01Mar2025_03-34-11.870\\A-Bayesian-decision-theoretic-approach-to-directio\\A-Bayesian-decision-theoretic-approach-to-directio.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "H_-^i",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î¸_i < 0\"\n}",
      "model_answer": "Î¸_i < 0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-282",
    "folder": "",
    "question": "In the bivariate regression model with arbitrary error structure, two simple but inefficient approaches to analysis are (i) to work with the differences between the two components of each response and (ii) to derive working independence estimators as if the two component responses were independent. The former strategy does well if the explanatory variables are balanced over pairs and the correlation between the two components of the response is high; the latter strategy does well when the response correlation is low or the covariates are highly unbalanced. Combining the two estimators can give a procedure with high efficiency in all situations, especially when an adjusted marginal score is calculated that is uncorrelated with the within-pair score. The covariance matrix between the score functions for the two analyses and the variance matrix of the paired score function are each scalar multiples of the matrix [BLANK].",
    "gold_answer": "W = âˆ‘(xáµ¢â‚ - xáµ¢â‚‚)(xáµ¢â‚ - xáµ¢â‚‚)áµ€. This matrix is crucial as it represents the configuration of the explanatory variables across pairs, affecting the efficiency of the combined estimator.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_87_Issue_2\\Regression_in_a_bivariate_copula_model\\Regression_in_a_bivariate_copula_model.md",
      "Regression_in_a_bivariate_copula_model.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "W = âˆ‘(xáµ¢â‚ - xáµ¢â‚‚)(xáµ¢â‚ - xáµ¢â‚‚)áµ€",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"V\"\n}",
      "model_answer": "V",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3563",
    "folder": "",
    "question": "In the context of testing for genetic effects in semiparametric models with interaction, the score test statistic for a fixed value of Î³ is given by Tâ‚™,pro(Î³) = nâ»Â¹/Â² Î£áµ¢â‚Œâ‚â¿ Î¨áµ¢(Î³) + oâ‚š(1). What term is represented by Î¨áµ¢(Î³) in this equation?",
    "gold_answer": "Î¨áµ¢(Î³) represents the individual contribution of the ith observation to the score statistic, adjusted for the interaction parameter Î³. It is derived from the model's likelihood and includes terms for the main effects, the interaction effects, and the non-parametric components, ensuring the test statistic's validity under the null hypothesis.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_71_Issue_1\\Testing in Semiparametric Models with Interaction,\\Testing in Semiparametric Models with Interaction,.md",
      "Testing in Semiparametric Models with Interaction,.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¨áµ¢(Î³) represents the individual contribution of the ith observation to the score statistic, adjusted for the interaction parameter Î³",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the efficient score function\"\n}",
      "model_answer": "the efficient score function",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-260",
    "folder": "",
    "question": "In the context of testing hypotheses about the mean of a normal population with unknown variance, the sequential test procedure that modifies Baker's approach and is analogous to Stein's procedure is referred to as test [BLANK].",
    "gold_answer": "T. This refers to the sequential test procedure discussed in the paper, which is a modification of Baker's approach and serves as an analog to Stein's two-stage test procedure.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_49_Issue_3-4\\Some_sequential_analogs_of_Stein's_two-stage_test\\Some_sequential_analogs_of_Stein's_two-stage_test.md",
      "Some_sequential_analogs_of_Stein's_two-stage_test.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "T",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"S\"\n}",
      "model_answer": "S",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-84",
    "folder": "",
    "question": "When analyzing correlated ordinal responses, a common approach involves modeling the association between outcomes through shared random effects. The covariance matrix of these random effects, often denoted as [BLANK], captures the degree of association between the outcomes.",
    "gold_answer": "Î£ (the covariance matrix of random effects). This is omitted to highlight the importance of the covariance matrix in modeling the association between outcomes through shared random effects.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î£ (the covariance matrix of random effects)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"G\"\n}",
      "model_answer": "G",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-634",
    "folder": "",
    "question": "In the AFT-SDAR algorithm, the step size Ï„ must satisfy the condition 0 < Ï„ < [BLANK] to ensure the algorithm's convergence. What is the missing term in this inequality?",
    "gold_answer": "1/(âˆšT U). This condition ensures that the step size is sufficiently small to guarantee the convergence of the AFT-SDAR algorithm by balancing the trade-off between the algorithm's speed and stability.",
    "source": [
      "-0-Regularized-high-dimensional-accelerated_2022_C.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2022\\ScienceDirect_articles_03Mar2025_08-48-55.542\\-0-Regularized-high-dimensional-accelerated_2022_C\\-0-Regularized-high-dimensional-accelerated_2022_C.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "1/(âˆšT U)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"2/L\"\n}",
      "model_answer": "2/L",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-858",
    "folder": "",
    "question": "For modeling skewed error distributions in spatial models, one approach is to introduce a term Î»dáµ¢, where dáµ¢ follows a [BLANK] distribution truncated below at zero.",
    "gold_answer": "normal",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "normal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"normal\"\n}",
      "model_answer": "normal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2924",
    "folder": "",
    "question": "In the context of threshold diffusion processes, the maximum likelihood estimator for the drift parameters (bâ‚Š, bâ‚‹) can be expressed as Î²â‚œâº = (Râ‚œâº / Qâ‚œâº) and Î²â‚œâ» = (Râ‚œâ» / Qâ‚œâ»), where Râ‚œâº and Râ‚œâ» are defined based on the process's behavior above and below the threshold, and Qâ‚œâº and Qâ‚œâ» are the occupation times. The term [BLANK] is crucial for calculating Râ‚œâº and Râ‚œâ» from the process's observations.",
    "gold_answer": "the symmetric local time Lâ‚œ(Î¾) at the threshold. This term is essential because it accounts for the time the process spends at the threshold, influencing the calculation of Râ‚œâº and Râ‚œâ» by adjusting for crossings between the positive and negative sides of the threshold.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2020_Volume_47_Issue_3\\Scandinavian J Statistics - 2019 - Lejay - Maximum\\Scandinavian J Statistics - 2019 - Lejay - Maximum.md",
      "Scandinavian J Statistics - 2019 - Lejay - Maximum.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the symmetric local time Lâ‚œ(Î¾) at the threshold",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"local time\"\n}",
      "model_answer": "local time",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2758",
    "folder": "",
    "question": "In the context of solving fused penalty estimation problems, the term [BLANK] refers to the method of introducing auxiliary variables to decouple the linear constraints, facilitating parallel computation.",
    "gold_answer": "block splitting. This technique is crucial for reformulating the problem in a way that allows for separable optimization tasks, significantly improving scalability and computational speed.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "block splitting",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"ADMM\"\n}",
      "model_answer": "ADMM",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-870",
    "folder": "",
    "question": "The first four conditional moments of the integrated variance implied by the GARCH diffusion process are derived analytically. Based on these moments and on a power series method an analytical approximation formula to price European options under the GARCH diffusion model is obtained. Monte Carlo simulations show that this approximation formula up to order [BLANK] is accurate for a large set of reasonable parameters and highlight potential instabilities of the fourth term.",
    "gold_answer": "three. The missing element is 'three' because the text specifies that the approximation formula up to order three is accurate, highlighting potential instabilities of the fourth term.",
    "source": [
      "An-option-pricing-formula-for-the-GARCH-d_2005_Com.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2005\\ScienceDirect_articles_04Mar2025_14-57-17.520\\An-option-pricing-formula-for-the-GARCH-d_2005_Com\\An-option-pricing-formula-for-the-GARCH-d_2005_Com.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "three",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"3\"\n}",
      "model_answer": "3",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2809",
    "folder": "",
    "question": "A diffusion is said to be [BLANK] if there exists a sigma-finite (but not finite) invariant measure $m$ which is unique up to a constant multiple.",
    "gold_answer": "null recurrent. Null recurrence implies that while the process will return to any state with probability one, the expected time for such returns is infinite.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "null recurrent",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"recurrent\"\n}",
      "model_answer": "recurrent",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3013",
    "folder": "",
    "question": "The MSCAL distribution is fitted using a Monte Carlo expectation-maximization (MCEM) algorithm that uses a Monte Carlo method to estimate the [BLANK] matrix of eigenvectors.",
    "gold_answer": "orthogonal. The MCEM algorithm's use of a Monte Carlo method for estimating the orthogonal matrix of eigenvectors is crucial for the model's ability to handle complex data structures.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "orthogonal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"conditional\"\n}",
      "model_answer": "conditional",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1254",
    "folder": "",
    "question": "In the context of ordinal data analysis, the method of mean square contingency and corrections for the grouping of both variates assumes that the marginal totals for both variates follow approximately [BLANK] distributions.",
    "gold_answer": "normal",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "normal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"normal\"\n}",
      "model_answer": "normal",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3012",
    "folder": "",
    "question": "In the context of the MSCAL distribution, the parameters that model the proportion of good points and degree of contamination are the same across every dimension of the data, which is restrictive because it implies that all dimensions have the same amount of [BLANK].",
    "gold_answer": "leptokurtosis. This restriction is addressed by the MSCAL distribution by allowing these parameters to vary across dimensions, providing more flexibility in modeling tail behavior.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "leptokurtosis",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"contamination\"\n}",
      "model_answer": "contamination",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3519",
    "folder": "",
    "question": "In the development of local Bayes factors, a uniform prior density over an appropriate volume in R^(pâ‚ - pâ‚€) is used to ensure non-decreasing probability is assigned to a local neighbourhood of Î¸ = 0. This approach can be seen as a special case of a [BLANK] prior.",
    "gold_answer": "Jeffreys invariant. The use of a uniform prior in this context aligns with Jeffreys' principle of invariance, emphasizing the role of prior specification in Bayesian model comparison.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Jeffreys invariant",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Lindley\"\n}",
      "model_answer": "Lindley",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1609",
    "folder": "",
    "question": "When analyzing correlated ordinal responses, a proportional odds mixed model may be used for each outcome, and then random effects can be correlated across outcomes to capture their association. A simplified version for a single ordinal response $Y_{ij}$ can be written as $\\text{logit}[ P(Y_{ij} \\leq r) ] = \\alpha_r + x_{ij}^T\\beta + [BLANK]$, where $\\alpha_r$ are category-specific intercepts. What key latent variable is omitted here?",
    "gold_answer": "$b_i$ (the random intercept). This is excluded to emphasize that individual-specific heterogeneity is captured by a random effect, and without it, we cannot account for the correlation structure within each subjectâ€™s repeated measurements.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$b_i$ (the random intercept)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"b_i\"\n}",
      "model_answer": "b_i",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1743",
    "folder": "",
    "question": "In the analysis of variance under spatial correlation, if $R \\neq I$, then the usual $F$ ratio will not have an $F$ distribution. Exceptions are when $R$ is formed from the appropriate randomization induced correlations or the corresponding random effects model. For a particular $R$, the distribution of $F$ could be obtained numerically, or approximated by independent $\\chi^2$ distributions with the same first two moments, a method introduced by [BLANK].",
    "gold_answer": "Box (1954) and Andersen, Jensen & Schou (1981). This approximation method is crucial for practical analysis when the error structure deviates from independence.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Box (1954) and Andersen, Jensen & Schou (1981)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Satterthwaite\"\n}",
      "model_answer": "Satterthwaite",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3322",
    "folder": "",
    "question": "A multiple-imputation strategy for incomplete ordinal data can be performed under a patternâ€“mixture perspective, where we distinguish subpopulations according to their missingness patterns. If we rely on the â€˜neighboring case missing valueâ€™ approach (NCMV) so that missing values in a partially observed sequence borrow information only from the next identified pattern, we multiply the subpopulation distribution f(Y | pattern) by [BLANK] to obtain the overall mixture distribution for the data.",
    "gold_answer": "the proportion of that missingness pattern (f(pattern)). This step is essential for combining distinct distributions of Y in a patternâ€“mixture approach by weighting by the relative frequency of each pattern.",
    "source": [],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the proportion of that missingness pattern (f(pattern))",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"P(pattern)\"\n}",
      "model_answer": "P(pattern)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-748",
    "folder": "",
    "question": "The method introduced for reducing bias of a wide variety of density estimators involves 'sharpening' the data by making them slightly more [BLANK] than before, and then computing the estimator in the usual way, but from the sharpened data rather than the original data.",
    "gold_answer": "clustered. This is excluded to highlight the key action in the data-sharpening method, which is adjusting the data distribution to reduce bias in density estimation.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_86_Issue_4\\Miscellanea._Data_sharpening_as_a_prelude_to_density_estimation\\Miscellanea._Data_sharpening_as_a_prelude_to_density_estimation.md",
      "Miscellanea._Data_sharpening_as_a_prelude_to_density_estimation.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "clustered",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"peaked\"\n}",
      "model_answer": "peaked",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3108",
    "folder": "",
    "question": "In the context of multivariate normal mixtures, the EM algorithm generates a sequence of estimates {Î¨(m)}m where Î¨(0) denotes the initial guess and Î¨(m) âˆˆ Î¨ for m âˆˆ â„•, ensuring that the sequence of the log-likelihood values {â„’(Î¨(m))}m is [BLANK].",
    "gold_answer": "not decreasing. This ensures that each iteration of the EM algorithm does not decrease the likelihood, aiming for convergence to a local maximum.",
    "source": [
      "Degeneracy-of-the-EM-algorithm-for-the-MLE-of-mult.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2011\\ScienceDirect_articles_04Mar2025_11-14-22.194\\Degeneracy-of-the-EM-algorithm-for-the-MLE-of-mult\\Degeneracy-of-the-EM-algorithm-for-the-MLE-of-mult.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "not decreasing",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"monotonically increasing\"\n}",
      "model_answer": "monotonically increasing",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2340",
    "folder": "",
    "question": "In the context of nonlinear regression models with heteroscedasticity, the general form of the model is given by Y_i = f(x_i, Î²) + Îµ_i, where Îµ_i ~ N(0, Ïƒ_i^2). To model the variance Ïƒ_i^2, the equation Ïƒ_i^2 = Ïƒ^2 m(z_i, Î») = Ïƒ^2 m_i is used. The test for heterogeneity of variance is equivalent to testing the hypotheses H_0: Î» = Î»_0 vs. H_1: Î» â‰  Î»_0. The log-likelihood function for Î¸ = (Î»^T, Î²^T, Ïƒ^2)^T is given by l(Î¸) = C - (n/2)logÏƒ^2 - (1/2)Î£_{i=1}^n log m_i - (1/(2Ïƒ^2))Î£_{i=1}^n m_i^{-1}(Y_i - f(x_i, Î²))^2. The Fisher information matrix under H_0 is I_Y(Î¸) = [ (1/2)M^T M^{-2} M 0 (1/(2Ïƒ^2))M^T M^{-1} 1_n; 0 (1/Ïƒ^2)F^T M^{-1} F 0; (1/(2Ïƒ^2))1_n^T M^{-1} M 0 n/(2Ïƒ^4) ], where M = diag(m_1, ..., m_n), MÌ‡ = (âˆ‚m(z_i, Î»)/âˆ‚Î»_j)_{nÃ—q}, 1_n = (1, ..., 1)^T, and FÌ‡ = (âˆ‚f(x_i, Î²)/âˆ‚Î²_j)_{nÃ—p}. The score test statistic for hypothesis (2) is based on the score function âˆ‚l(Î¸)/âˆ‚Î»|_{Î¸Ì‚_0} = { MÌ‡^T u / (2Ïƒ^2) }|_{Î¸Ì‚_0}, where u = (Îµ_1^2, ..., Îµ_n^2)^T, Î¸Ì‚_0 = (Î»_0^T, Î³Ì‚_0^T)^T, Î³Ì‚_0 is the MLE of Î³ under H_0, and MÌ‡ = (I_n - 1_n 1_n^T /n) MÌ‡. The score statistic is computed as SC_1 = { (âˆ‚l(Î¸)/âˆ‚Î»)^T I^{Î»Î»} (âˆ‚l(Î¸)/âˆ‚Î») }|_{Î¸Ì‚_0} = { u^T MÌ‡ (MÌ‡^T MÌ‡)^{-1} MÌ‡^T u / (2Ïƒ^4) }|_{Î¸Ì‚_0}, where I^{Î»Î»} = 2 { MÌ‡^T (I_n - 1_n 1_n^T /n) MÌ‡ }^{-1} = 2 (MÌ‡^T MÌ‡)^{-1}, which is the upper left corner of I_Y^{-1}(Î¸) under H_0. The asymptotic distribution of SC_1 under H_0 is a central Ï‡^2 distribution with q degrees of freedom. The approximate power of the score test under local alternatives is given by ALP_1(Î») = 1 - F_Ï‡^2(Ï‡_Î±^2(q) | q, Î´), where F_Ï‡^2(x | q, Î´) is the noncentral Ï‡^2 distribution function with q degrees of freedom and noncentrality parameter Î´ = Î¼^T Î£^{-1} Î¼, with Î¼ = (Ïƒ^2 / (2Ïƒ_0^2)) MÌ‡_0^T M 1_n + (1 / (2Ïƒ_0^2)) MÌ‡_0^T G 1_n and Î£ = (Ïƒ^4 / (2Ïƒ_0^4)) MÌ‡_0^T M^2 MÌ‡_0 + (Ïƒ^2 / Ïƒ_0^4) MÌ‡_0^T M G MÌ‡_0. Here, Ï‡_Î±^2(q) is the critical value of the central Ï‡^2 distribution with q degrees of freedom at level Î±, MÌ‡_0 is the value of MÌ‡ at Î»_0, and MÌ‡ = (I_n - 1_n 1_n^T /n) MÌ‡. The noncentrality parameter Î´ is crucial for calculating the approximate power under local alternatives. What is the expression for the noncentrality parameter Î´ in terms of Î¼ and Î£?",
    "gold_answer": "Î´ = Î¼^T Î£^{-1} Î¼. The noncentrality parameter Î´ is calculated as the quadratic form of Î¼ multiplied by the inverse of Î£, where Î¼ represents the expected value of the score function under the alternative hypothesis, and Î£ represents the variance of the score function. This parameter is essential for determining the approximate power of the score test under local alternatives, as it quantifies the deviation from the null hypothesis in terms of the score function's distribution.",
    "source": [
      "Approximate-power-of-score-test-for-variance-heter.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2006\\ScienceDirect_articles_04Mar2025_14-47-30.505\\Approximate-power-of-score-test-for-variance-heter\\Approximate-power-of-score-test-for-variance-heter.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î´ = Î¼^T Î£^{-1} Î¼",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î´ = Î¼^T Î£^{-1} Î¼\"\n}",
      "model_answer": "Î´ = Î¼^T Î£^{-1} Î¼",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2558",
    "folder": "",
    "question": "In the context of nonlinear regression with censored responses, the parameter Î¸â‚€ can be estimated through a standard least squares procedure if [BLANK] were available. What is the missing element?",
    "gold_answer": "Y*. The missing element is Y*, which represents the synthetic data transformations that have the same conditional expectation as Y, allowing for the estimation of Î¸â‚€ in the presence of censoring.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Scandinavian_Journal_of_Statistics\\Year_2008_Volume_35_Issue_2\\Scandinavian J Statistics - 2008 - DELECROIX - Non\\Scandinavian J Statistics - 2008 - DELECROIX - Non.md",
      "Scandinavian J Statistics - 2008 - DELECROIX - Non.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Y*",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"uncensored responses\"\n}",
      "model_answer": "uncensored responses",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-798",
    "folder": "",
    "question": "In the sensitivity analysis for publication bias in meta-analyses, the publication process is modeled such that 'statistically significant' results are more likely to be published than negative or 'non-significant' results by an unknown ratio, denoted as [BLANK].",
    "gold_answer": "Î·. This ratio represents the relative likelihood of publishing statistically significant results compared to non-significant ones, serving as a key parameter in assessing the impact of publication bias.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î·",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï‰\"\n}",
      "model_answer": "Ï‰",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-975",
    "folder": "",
    "question": "In the Hartley-Khamis procedure, the grouped frequencies' estimates are determined by the conditions involving the moments of the distribution and the missingness indicators. The equation representing this is given by f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK], where Ráµ¢ denotes the missingness indicators. What is the omitted term that represents the missingness mechanism?",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). This term is crucial as it represents the conditional distribution of the missingness indicators given the outcomes, highlighting the dependency of missingness on the observed and unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2332",
    "folder": "",
    "question": "In the context of analyzing the first occurrence of elements in a fair coin-tossing process, for each element A in Î©â‚™, the stopping time T_A is defined as the infimum of m such that A equals (Y_{m-n+1}, ..., Y_m). If no such m exists, T_A is defined as [BLANK]. What is the value assigned to T_A when the sequence A does not occur in the process?",
    "gold_answer": "âˆž (infinity). This is because T_A is defined as the first time the sequence A appears in the process, and if A never appears, by definition, T_A is set to infinity to indicate that the event does not occur.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1979\\ScienceDirect_articles_02Mar2025_09-12-46.606\\On-fair-coin-tossing-games_1979_Journal-of-Multiva\\On-fair-coin-tossing-games_1979_Journal-of-Multiva.md",
      "On-fair-coin-tossing-games_1979_Journal-of-Multiva.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "âˆž (infinity)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"âˆž\"\n}",
      "model_answer": "âˆž",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1956",
    "folder": "",
    "question": "In the two-stage model for estimating the long-term health effects of air pollution, the first stage involves a spatio-temporal fusion model linking modeled and measured pollution data, while the second stage links these predictions to the disease data. The methodology is motivated by a study investigating the effects of multiple pollutants on respiratory hospitalizations in England between 2007 and 2011, using pollution and disease data relating to local and unitary authorities on a [BLANK] time scale.",
    "gold_answer": "monthly. The study utilizes a monthly time scale to match the granularity of the pollution and disease data, allowing for less aggregation away from the individual level and capturing both chronic and acute pollution exposure effects.",
    "source": [
      "A rigorous statistical framework for spatio-tempor.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biostatistics\\Volume_18_Issue_2\\A rigorous statistical framework for spatio-tempor\\A rigorous statistical framework for spatio-tempor.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "monthly",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"monthly\"\n}",
      "model_answer": "monthly",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-76",
    "folder": "",
    "question": "For a normal distribution, the relationship between the correlation ratio Î· and the correlation coefficient r is given by [BLANK] = r.",
    "gold_answer": "Î·",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î·",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î·\"\n}",
      "model_answer": "Î·",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-667",
    "folder": "",
    "question": "The t-ridge estimator for generalized linear models is defined by minimizing an objective function that includes the data-fitting function divided by the L2 norm of the score function, plus the L2 norm of the parameter vector. Specifically, the objective function is given by D(Î¸|Z)/||s(Î¸)||â‚‚ + ||Î¸||â‚‚, where s(Î¸) is the score function defined as [BLANK].",
    "gold_answer": "s(Î¸) = -âˆ‚D(Î¸|Z)/âˆ‚Î¸. The score function represents the gradient of the data-fitting function with respect to the parameter vector, crucial for the optimization process in the t-ridge estimator.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "s(Î¸) = -âˆ‚D(Î¸|Z)/âˆ‚Î¸",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the gradient of D(Î¸|Z) with respect to Î¸\"\n}",
      "model_answer": "the gradient of D(Î¸|Z) with respect to Î¸",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1616",
    "folder": "",
    "question": "In the context of estimating multivariate binary density using orthonormal functions, the shrinkage estimator proposed by Liang and Krishnaiah can be expressed as [BLANK], where Î»áµ£ are the shrinkage coefficients and Ï•áµ£(x) are the orthonormal functions.",
    "gold_answer": "âˆ‘áµ£âˆˆR Î»áµ£ Ã¢áµ£ Ï•áµ£(x). This formula represents the shrinkage estimator that adjusts the coefficients Ã¢áµ£ towards zero to reduce variance in the estimation process.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\1989\\ScienceDirect_articles_02Mar2025_02-24-17.877\\Estimation-of-multivariate-binary-density-using-_1\\Estimation-of-multivariate-binary-density-using-_1.md",
      "Estimation-of-multivariate-binary-density-using-_1.md"
    ],
    "category": "PARTIALLY_CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "âˆ‘áµ£âˆˆR Î»áµ£ Ã¢áµ£ Ï•áµ£(x)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"âˆ‘Î»áµ£Ï•áµ£(x)\"\n}",
      "model_answer": "âˆ‘Î»áµ£Ï•áµ£(x)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3583",
    "folder": "",
    "question": "In the context of Approximate Bayesian Computation (ABC), the ABC posterior is defined in terms of a function S(Â·) which maps the data onto a d-dimensional summary statistic, a density kernel K(x), and a bandwidth h > 0. The ABC posterior can be expressed as Ï€ABC(Î¸|sobs) âˆ Ï€(Î¸) Ã— [BLANK]. What is the term that completes this equation to define the ABC posterior?",
    "gold_answer": "p(Î¸|sobs). This term represents the approximation to the likelihood as defined by the integral of the product of the true likelihood Ï€(y|Î¸) and the kernel function K[{S(y) - sobs}/h] over all possible data y, thus linking the parameter Î¸ to the observed summary statistic sobs through the kernel density estimation.",
    "source": [
      "Constructing Summary Statistics for Approximate Ba.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_74_Issue_3\\Constructing Summary Statistics for Approximate Ba\\Constructing Summary Statistics for Approximate Ba.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "p(Î¸|sobs)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"âˆ« K((s - sobs)/h) f(s|Î¸) ds\"\n}",
      "model_answer": "âˆ« K((s - sobs)/h) f(s|Î¸) ds",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2076",
    "folder": "",
    "question": "In the context of the GTL distribution, the condition for the kth moment mk of a GTL(Î±, Î´)-distributed random variable Îµ to exist is that Î±âˆ’Î´ > âˆ’1/k and [BLANK].",
    "gold_answer": "Î±+Î´ > âˆ’1/k",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î±+Î´ > âˆ’1/k",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Î±+Î´ > 1/k\"\n}",
      "model_answer": "Î±+Î´ > 1/k",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2226",
    "folder": "",
    "question": "In the semiparametric approach where the missing-data mechanism is nonparametric, the model becomes identifiable if the outcome model is correctly specified and [BLANK].",
    "gold_answer": "the missing-data mechanism is unspecified. This leverages the flexibility of the nonparametric component to achieve identifiability without strict parametric assumptions.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the missing-data mechanism is unspecified",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the missing-data mechanism is independent of the outcome\"\n}",
      "model_answer": "the missing-data mechanism is independent of the outcome",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3365",
    "folder": "",
    "question": "Estimation of the VAR-HME model parameters is achieved via the [BLANK] algorithm, which is an iterative method for finding maximum likelihood estimates.",
    "gold_answer": "EM (expectationâ€“maximization). The EM algorithm is used due to its effectiveness in handling missing data and latent variables in statistical models.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "EM (expectationâ€“maximization)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"EM\"\n}",
      "model_answer": "EM",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3170",
    "folder": "",
    "question": "In the context of nonparametric regression for model checking, a pseudo likelihood ratio test is developed to provide a global assessment of fit. The test statistic is derived from a likelihood ratio argument but its distribution is not approximately chi-squared. Instead, simulation is used to examine the null hypothesis behavior of the test statistic. For Finney's data, the observed significance level is [BLANK] with a simulation size N=500.",
    "gold_answer": "0.4%. This value is reported to illustrate how the significance level is calculated from the position of the observed test statistic in the ordered test statistics derived from simulated data, emphasizing the practical application of the pseudo likelihood ratio test in assessing model fit.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_76_Issue_1\\On_the_use_of_nonparametric_regression_for_model_checking\\On_the_use_of_nonparametric_regression_for_model_checking.md",
      "On_the_use_of_nonparametric_regression_for_model_checking.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0.048\"\n}",
      "model_answer": "0.048",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3597",
    "folder": "",
    "question": "In the context of non-Gaussian Ornsteinâ€“Uhlenbeck stochastic volatility processes, the volatility process is modeled as a stationary, latent OU process, driven by a non-Gaussian LÃ©vy process. This specification forces the volatility to move up entirely by jumps and then to tail off exponentially. The jump times and corresponding sizes are controlled by the increment distribution of the driving [BLANK] process.",
    "gold_answer": "LÃ©vy. The LÃ©vy process is crucial for modeling the jumps in volatility, with its increment distribution determining the timing and size of these jumps, which then tail off exponentially.",
    "source": [
      "Bayesian Inference for Non-Gaussian Ornsteinâ€“Uhlen.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JRSSB\\Volume_66_Issue_2\\Bayesian Inference for Non-Gaussian Ornsteinâ€“Uhlen\\Bayesian Inference for Non-Gaussian Ornsteinâ€“Uhlen.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "LÃ©vy",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"LÃ©vy\"\n}",
      "model_answer": "LÃ©vy",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2320",
    "folder": "",
    "question": "In the context of heteroscedastic regression models, the log-likelihood function, L(Î²,Î±), is given by L(Î²,Î±)=-âˆ‘áµ¢logÏƒáµ¢(Î±)+âˆ‘áµ¢logf{(yáµ¢-Î¼áµ¢(Î²))/Ïƒáµ¢(Î±)}. What critical condition causes the likelihood to diverge to infinity when Ïƒâ±¼â†’0 and Ïƒáµ¢â†’sáµ¢ (0<sáµ¢<âˆž, iâ‰ j)?",
    "gold_answer": "Î¼â±¼(bâ‚€)=yâ±¼. This condition is critical because it signifies that at a certain value of Î², the location function equals the observed value for the j-th observation, leading to the likelihood diverging to infinity as Ïƒâ±¼ approaches zero.",
    "source": [
      "A_note_on_nonregular_likelihood_functions_in_heteroscedastic_regression_models.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_81_Issue_3\\A_note_on_nonregular_likelihood_functions_in_heteroscedastic_regression_models\\A_note_on_nonregular_likelihood_functions_in_heteroscedastic_regression_models.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Î¼â±¼(bâ‚€)=yâ±¼",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"yâ±¼=Î¼â±¼(Î²)\"\n}",
      "model_answer": "yâ±¼=Î¼â±¼(Î²)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-46",
    "folder": "",
    "question": "The assumption that the probability of dropout does not depend on unobserved outcomes, conditional on observed data, is known as [BLANK].",
    "gold_answer": "Missing at random (MAR). This assumption is crucial for the validity of likelihood-based or multiple-imputation methods without explicitly modeling the dropout process.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1140",
    "folder": "",
    "question": "The dependence function A(w) in bivariate extreme value distributions is convex and satisfies the inequalities [BLANK] for 0 â‰¤ w â‰¤ 1.",
    "gold_answer": "max(w,1-w) â‰¤ A(w) â‰¤ 1. This is crucial as it defines the range within which the dependence function must lie, ensuring it adheres to the properties of bivariate extreme value distributions.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "max(w,1-w) â‰¤ A(w) â‰¤ 1",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"max(w,1-w) â‰¤ A(w) â‰¤ 1\"\n}",
      "model_answer": "max(w,1-w) â‰¤ A(w) â‰¤ 1",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-70",
    "folder": "",
    "question": "The joint probability density function of the ordered observations remaining after censoring in a normal population is given by f(x_{r_{1}+1},...,x_{n-r_{2}};Î¼,Ïƒ)= [BLANK]. What is the correct expression for this density function?",
    "gold_answer": "The correct expression is (n!/(r_{1}!r_{2}!))*(1/(sqrt(2Ï€)Ïƒ))^m * exp[-âˆ‘_{i=r_{1}+1}^{n-r_{2}}(x_{i}-Î¼)^2/(2Ïƒ^2)] * [F((x_{r_{1}+1}-Î¼)/Ïƒ)]^{r_{1}} * [1-F((x_{n-r_{2}}-Î¼)/Ïƒ)]^{r_{2}}. This formula accounts for the censoring from both ends of the sample, where F is the cumulative distribution function of the standard normal distribution.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_53_Issue_1-2\\Iterative_maximum-likelihood_estimation_of_the_parametersof_normal_population_from_singly_and_doubly_censored_samples\\Iterative_maximum-likelihood_estimation_of_the_parametersof_normal_population_from_singly_and_doubly_censored_samples.md",
      "Iterative_maximum-likelihood_estimation_of_the_parametersof_normal_population_from_singly_and_doubly_censored_samples.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "The correct expression is (n!/(r_{1}!r_{2}!))*(1/(sqrt(2Ï€)Ïƒ))^m * exp[-âˆ‘_{i=r_{1}+1}^{n-r_{2}}(x_{i}-Î¼)^2/(2Ïƒ^2)] * [F((x_{r_{1}+1}-Î¼)/Ïƒ)]^{r_{1}} * [1-F((x_{n-r_{2}}-Î¼)/Ïƒ)]^{r_{2}}",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"C(n!/(râ‚!râ‚‚!))âˆ(i=râ‚+1 to n-râ‚‚)[f(xáµ¢)][F(xáµ¢)]^(i-1)[1-F(xáµ¢)]^(n-i)\"\n}",
      "model_answer": "C(n!/(râ‚!râ‚‚!))âˆ(i=râ‚+1 to n-râ‚‚)[f(xáµ¢)][F(xáµ¢)]^(i-1)[1-F(xáµ¢)]^(n-i)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1178",
    "folder": "",
    "question": "The estimator of location, $J_{n}$, is defined as $J_{n}=\\frac{6}{n}\\sum_{i=1}^{n}\\frac{i}{n+1}\\bigg(1-\\frac{i}{n+1}\\bigg)Y_{i}$, where $Y_{1}<...<Y_{n}$ are the order statistics for a sample $X_{1},...,X_{n}$ of size $n$. This estimator is an asymptotically best linear unbiased estimator of the location parameter of the [BLANK] distribution.",
    "gold_answer": "logistic. The logistic distribution is specified as the context in which $J_{n}$ is an asymptotically best linear unbiased estimator, highlighting its relevance in statistical estimation for this particular distribution.",
    "source": [
      "An_estimator_of_location_for_dependent_data.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_69_Issue_2\\An_estimator_of_location_for_dependent_data\\An_estimator_of_location_for_dependent_data.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "logistic",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"logistic\"\n}",
      "model_answer": "logistic",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-313",
    "folder": "",
    "question": "In the likelihood ratio test for comparing two variances from a bivariate normal population, the test statistic is given by Î» = {1 - [(Î´â‚Â² - Î´â‚‚Â²)Â² / ((Î´â‚Â² + Î´â‚‚Â²)Â² - 4râ‚â‚‚Â²Î´â‚Â²Î´â‚‚Â²)]}^(n/2). The hypothesis that Ïƒâ‚ = Ïƒâ‚‚ becomes less likely as Î» approaches [BLANK].",
    "gold_answer": "0. This is because as Î» moves towards 0, it indicates a greater discrepancy between the sample variances Î´â‚Â² and Î´â‚‚Â², making the hypothesis that Ïƒâ‚ = Ïƒâ‚‚ less plausible.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_31_Issue_1-2\\TEST_FOR_THE_SIGNIFICANCE_OF_THE_DIFFERENCE_BETWEEN_THE_TWO_VARIANCES_IN_A_SAMPLE_FROM_A_NORMAL_BIVARIATE_POPULATION\\TEST_FOR_THE_SIGNIFICANCE_OF_THE_DIFFERENCE_BETWEEN_THE_TWO_VARIANCES_IN_A_SAMPLE_FROM_A_NORMAL_BIVARIATE_POPULATION.md",
      "TEST_FOR_THE_SIGNIFICANCE_OF_THE_DIFFERENCE_BETWEEN_THE_TWO_VARIANCES_IN_A_SAMPLE_FROM_A_NORMAL_BIVARIATE_POPULATION.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "0",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"0\"\n}",
      "model_answer": "0",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1415",
    "folder": "",
    "question": "The efficiency of a design ignoring correlations compared to a design accounting for correlations is calculated using the formula Ï•_Eff = {Ï•(Î¾_Ï=0,Î¸â°)/Ï•(Î¾_Ï>0,Î¸â°)}^(1/p), where p is the number of parameters. This efficiency measure is used to assess the [BLANK] of the design ignoring correlations.",
    "gold_answer": "relative performance. This measure quantifies how much less efficient a design ignoring correlations is compared to one that accounts for them, with values closer to 1 indicating better performance.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "relative performance",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"relative performance\"\n}",
      "model_answer": "relative performance",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2263",
    "folder": "",
    "question": "In the selection modeling framework for analyzing ordinal outcomes and their missingness, the likelihood is factorized into the product of the outcome model and the missingness mechanism, expressed as f(Y_i, R_i) = f(Y_i) Ã— [BLANK], where R_i denotes the missingness indicators.",
    "gold_answer": "f(R_i | Y_i). This term is omitted to emphasize that, in selection models, the distribution of missingness may depend on both observed and unobserved outcomes, distinguishing these models from pattern-mixture approaches.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(R_i | Y_i)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(R_i|Y_i)\"\n}",
      "model_answer": "f(R_i|Y_i)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2421",
    "folder": "",
    "question": "Gaussian elimination was originally introduced by Gauss as a way of determining the precision of least squares estimates and only later described as a computational algorithm. The key function Gauss introduced for this purpose is proportional to e^(-h^2Î©), where Î© is the [BLANK].",
    "gold_answer": "residual sum of squares. This is because Î© represents the sum of the squares of the differences between the observed and predicted values, which is central to the method of least squares.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_4\\Issue_1\\Gauss,_Statistics,_and_Gaussian_Elimination__Gauss__Statistics__and_Gaussian_Elimination\\Gauss,_Statistics,_and_Gaussian_Elimination__Gauss__Statistics__and_Gaussian_Elimination.md",
      "Gauss,_Statistics,_and_Gaussian_Elimination__Gauss__Statistics__and_Gaussian_Elimination.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "residual sum of squares",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"sum of squares of the residuals\"\n}",
      "model_answer": "sum of squares of the residuals",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1588",
    "folder": "",
    "question": "The Breslow estimator Î›â‚™(x) for the baseline cumulative hazard function in the Cox model is given by âˆ‘_{i|Xáµ¢ â‰¤ x} dáµ¢ / âˆ‘_{j=1}^n {Tâ±¼ â‰¥ Xáµ¢} e^(Î²Ì‚â‚™'Zâ±¼), where dáµ¢ is the number of events at Xáµ¢ and Î²Ì‚â‚™ is the maximum partial likelihood estimator of the regression coefficients. The term {Tâ±¼ â‰¥ Xáµ¢} is an indicator function that equals 1 if [BLANK].",
    "gold_answer": "Tâ±¼ â‰¥ Xáµ¢. This indicator function ensures that only individuals at risk at time Xáµ¢ contribute to the denominator of the Breslow estimator.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Tâ±¼ â‰¥ Xáµ¢",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"subject j is still at risk at time Xi\"\n}",
      "model_answer": "subject j is still at risk at time Xi",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-464",
    "folder": "",
    "question": "Fisher's linear discriminant function (LDF) provides a linear combination of observations with the property that the mean difference in y for the two populations divided by the (common) standard deviation of y within populations is a maximum. This property does not depend on X being [BLANK].",
    "gold_answer": "multivariate normal. This highlights that Fisher's LDF can be useful for a wide variety of distributions of the observations, not just those that are multivariate normal.",
    "source": [
      "Discrimination and Allocation with Discrete Data.md",
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_16_Issue_3\\Discrimination and Allocation with Discrete Data\\Discrimination and Allocation with Discrete Data.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "multivariate normal",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"normally distributed\"\n}",
      "model_answer": "normally distributed",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-102",
    "folder": "",
    "question": "The measure of dependence between two statistical variables proposed by J. F. Steffensen, which is designed to remain applicable even when the number of distinct values the variables can assume becomes infinite, is denoted by [BLANK].",
    "gold_answer": "Ïˆ (psi). This measure is highlighted to show its applicability in both finite and infinite scenarios, emphasizing its versatility in statistical dependence measurement.",
    "source": [
      "(i)_On_certain_Measures_of_Dependenoe_between_Statistical_Variables.md",
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_26_Issue_1-2\\(i)_On_certain_Measures_of_Dependenoe_between_Statistical_Variables\\(i)_On_certain_Measures_of_Dependenoe_between_Statistical_Variables.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Ïˆ (psi)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Ï\"\n}",
      "model_answer": "Ï",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3511",
    "folder": "",
    "question": "In a setting where patients may drop out before completing all scheduled visits, we often assume that, conditional on observed data, the probability of dropout does not depend on unobserved outcomes. This assumption is known as [BLANK] and is crucial for likelihood-based or multiple-imputation methods to yield valid inferences without explicitly modeling the dropout process.",
    "gold_answer": "Missing at random (MAR). We remove it from the question because it represents the core assumption that simplifies inference: once we condition on the observed responses, the missingness no longer depends on the unobserved data.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Missing at random (MAR)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"missing at random\"\n}",
      "model_answer": "missing at random",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-504",
    "folder": "",
    "question": "In the orthogonal decomposition $Y=m(X)+\\varepsilon$, the function $m$ is the regression function of $Y$ on $X$ and is usually unknown. It is often assumed that $m$ belongs to a given parametric family $\\mathcal{M}$ of functions, so that $m$ is completely specified up to a [BLANK]. Which term completes this statement?",
    "gold_answer": "finite-dimensional parameter. This term is crucial because it specifies that the regression function $m$ can be fully described by a finite number of parameters within the parametric family $\\mathcal{M}$.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_95_Issue_2\\Model_diagnosis_for_parametric_regression_in_high-dimensional_spaces\\Model_diagnosis_for_parametric_regression_in_high-dimensional_spaces.md",
      "Model_diagnosis_for_parametric_regression_in_high-dimensional_spaces.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "finite-dimensional parameter",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"parameter\"\n}",
      "model_answer": "parameter",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3165",
    "folder": "",
    "question": "In the context of group divisible designs, the condition that distinguishes a regular subtype from singular and semiregular is given by [BLANK].",
    "gold_answer": "r > Î»â‚ and rk > Î»â‚‚. This condition is crucial for identifying regular group divisible designs, which are the most numerous among the partially balanced designs.",
    "source": [
      "A_cyclic_method_of_constructing_regular_group_divisible_incomplete_block_designs.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_63_Issue_3\\A_cyclic_method_of_constructing_regular_group_divisible_incomplete_block_designs\\A_cyclic_method_of_constructing_regular_group_divisible_incomplete_block_designs.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "r > Î»â‚ and rk > Î»â‚‚",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"n1 = n2\"\n}",
      "model_answer": "n1 = n2",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2549",
    "folder": "",
    "question": "In the context of ordinal data analysis, the [BLANK] model is often used to account for the ordered nature of the response categories.",
    "gold_answer": "proportional odds. This model is chosen because it specifically handles the ordinal nature of the data by assuming that the relationship between each pair of outcome groups is the same.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "proportional odds",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"proportional odds\"\n}",
      "model_answer": "proportional odds",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1507",
    "folder": "",
    "question": "In the context of high dimensional meanâ€“variance optimization through factor analysis, the proposed estimator for the high dimensional covariance matrix is applied to solve the meanâ€“variance portfolio optimization problem. The consistency of the proposed estimator is established by imposing a factor model structure with a relatively weak assumption on the relationship between the dimension and the sample size. The proposed estimator is shown to outperform the plugin, linear shrinkage, and bootstrap-corrected approaches. Which approach is NOT mentioned as being outperformed by the proposed estimator?",
    "gold_answer": "Nearest Neighbor approach. The text mentions the plugin, linear shrinkage, and bootstrap-corrected approaches as being outperformed by the proposed estimator, but does not mention the Nearest Neighbor approach.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2015\\ScienceDirect_articles_01Mar2025_03-28-21.604\\High-dimensional-mean-variance-optimization-thro_2\\High-dimensional-mean-variance-optimization-thro_2.md",
      "High-dimensional-mean-variance-optimization-thro_2.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "Nearest Neighbor approach",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nonlinear shrinkage\"\n}",
      "model_answer": "nonlinear shrinkage",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1713",
    "folder": "",
    "question": "In the partially varying coefficient model (PVCM), the likelihood can be factorized into a product of the outcome model and the missingness mechanism. In selection modeling, this is expressed as f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK], where Ráµ¢ denotes the missingness indicators. Which term is deliberately omitted in this equation?",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). This term is omitted to highlight that, in a selection framework, the distribution of the missingness (Ráµ¢) may depend on the observed and unobserved outcomes (Yáµ¢), distinguishing selection models from patternâ€“mixture approaches.",
    "source": [
      "A-reproducing-kernel-Hilbert-space-approach-to-hig.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2020\\ScienceDirect_articles_03Mar2025_08-53-11.628\\A-reproducing-kernel-Hilbert-space-approach-to-hig\\A-reproducing-kernel-Hilbert-space-approach-to-hig.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3066",
    "folder": "",
    "question": "In the context of testing for normality, the paper highlights a cautionary note regarding the assumption about the mean. It suggests that even if one believes the true mean is known, one should still assume the mean is [BLANK] in making the test to avoid a significant loss in power.",
    "gold_answer": "unknown. This is because assuming the mean to be unknown when it is actually known can lead to a significant loss in the power of the test, as demonstrated by the comparative results in the paper.",
    "source": [
      "Comparisons_of_tests_for_normality_with_a_cautionary_note.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_61_Issue_1\\Comparisons_of_tests_for_normality_with_a_cautionary_note\\Comparisons_of_tests_for_normality_with_a_cautionary_note.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "unknown",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"unknown\"\n}",
      "model_answer": "unknown",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-144",
    "folder": "",
    "question": "In the context of hierarchical testing of variable importance, the null hypothesis for a cluster C of variables can be formulated as Hâ‚€,C: Î²â‚– = 0 for all k âˆˆ C, versus Hâ‚,C: Î²â‚– â‰  0 for at least one k âˆˆ C. The adjustment for multiplicity in the p-values is achieved by multiplying the p-value of each cluster C by the inverse of the fraction of variables it contains, expressed as [BLANK]. What is the correct term or formula used for this adjustment?",
    "gold_answer": "m/|C|. This adjustment is resolution-dependent, applying a weaker penalty for coarser resolutions and increasing for finer resolutions, ensuring that the root node's p-value is unadjusted while individual variables receive a Bonferroni-type adjustment.",
    "source": [
      "E:\\shuju\\MD_result\\statistics_journal\\biomet\\Volume_95_Issue_2\\Hierarchical_testing_of_variable_importance\\Hierarchical_testing_of_variable_importance.md",
      "Hierarchical_testing_of_variable_importance.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "m/|C|",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"p|V|/|C|\"\n}",
      "model_answer": "p|V|/|C|",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3045",
    "folder": "",
    "question": "In the context of Bayesian latent class models with structural zeros, the basic idea is to treat the observed data as a truncated sample from an augmented dataset. This approach allows us to exploit the conditional independence assumptions for computational expediency. The model can be expressed as f(Yáµ¢, Ráµ¢) = f(Yáµ¢) Ã— [BLANK], where Ráµ¢ denotes the missingness indicators. What missingness-related term is deliberately omitted in this equation?",
    "gold_answer": "f(Ráµ¢ | Yáµ¢). This term is omitted to highlight that, in a selection framework, the distribution of the missingness (Ráµ¢) may depend on the observed and unobserved outcomes (Yáµ¢), distinguishing selection models from patternâ€“mixture approaches.",
    "source": [
      "Bayesian_Estimation_of_Discrete_Multivariate_Latent_Structure_Models_With_Structural_Zeros__Bayesian_Estimation_of_Discrete_Multivariate_Latent_Structure_Models_With_Structural_Zeros.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\JCGS\\Volume_23\\Issue_4\\Bayesian_Estimation_of_Discrete_Multivariate_Latent_Structure_Models_With_Structural_Zeros__Bayesian_Estimation_of_Discrete_Multivariate_Latent_Structure_Models_With_Structural_Zeros\\Bayesian_Estimation_of_Discrete_Multivariate_Latent_Structure_Models_With_Structural_Zeros__Bayesian_Estimation_of_Discrete_Multivariate_Latent_Structure_Models_With_Structural_Zeros.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f(Ráµ¢ | Yáµ¢)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f(Ráµ¢|Yáµ¢)\"\n}",
      "model_answer": "f(Ráµ¢|Yáµ¢)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-343",
    "folder": "",
    "question": "In the context of marked point processes, the joint conditional intensity function can be factorized into the product of the conditional intensity of the ground process and the conditional probability density or mass function of the mark at time t. This is expressed as Î»*(t,m) = Î»g*(t) Ã— [BLANK]. What term completes this equation?",
    "gold_answer": "f*(mâˆ£t). This term represents the conditional probability density or mass function of the mark m at time t, highlighting how the mark's distribution depends on time.",
    "source": [
      "E:\\shuju\\MD_result\\statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_72_Issue_5\\Proposer of the vote of thanks to Narayanan, Kosmi\\Proposer of the vote of thanks to Narayanan, Kosmi.md",
      "Proposer of the vote of thanks to Narayanan, Kosmi.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "f*(mâˆ£t)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"f*(m|t)\"\n}",
      "model_answer": "f*(m|t)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1156",
    "folder": "",
    "question": "In the context of finite population sampling, the conditional bias attached to unit i of the Horvitz-Thompson estimator is defined as [BLANK], where Ï€i is the first-order inclusion probability of unit i.",
    "gold_answer": "B1iHT = EP(Î¸Ì‚HT | Ii = 1) - Î¸ = âˆ‘jâˆˆU (Ï€ij / (Ï€iÏ€j) - 1) yj. This definition highlights the conditional bias as a measure of the influence of unit i on the estimation error, accounting for the sampling design through the inclusion probabilities.",
    "source": [
      "A_unified_approach_to_robust_estimation_in_finite_population_sampling.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_100_Issue_3\\A_unified_approach_to_robust_estimation_in_finite_population_sampling\\A_unified_approach_to_robust_estimation_in_finite_population_sampling.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "B1iHT = EP(Î¸Ì‚HT | Ii = 1) - Î¸ = âˆ‘jâˆˆU (Ï€ij / (Ï€iÏ€j) - 1) yj",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"(1-Ï€i)/Ï€i\"\n}",
      "model_answer": "(1-Ï€i)/Ï€i",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1012",
    "folder": "",
    "question": "In the context of epidemic dynamics, the normalized Markov jump process is defined as $\\mathcal{Z}_{N}(t) = \\frac{\\mathcal{Z}(t)}{N} \\in E^{N} = \\{k/N, k \\in E\\}$. The associated jump functions are, for $\\boldsymbol{x} \\in E^{N}$, $\\alpha_{\\ell}^{N}(x) = \\frac{1}{N}\\alpha_{\\ell}([N x])$. The process $(\\mathcal{Z}(t))$ is density-dependent, meaning for all $\\ell$, $\\forall \\boldsymbol{x} \\in [0,1]^{d}$, $\\frac{1}{N}\\alpha_{\\ell}([N \\boldsymbol{x}]) \\underset{N \\to +\\infty}\\rightarrow \\beta_{\\ell}(\\boldsymbol{x})$, and $\\forall \\ell$, $\\beta_{\\ell} \\in C^{2}([0,1]^{d}, \\mathbb{R})$. The drift function $b(\\cdot)$ and the diffusion matrix $\\Sigma(\\cdot)$ are defined as $b(x) = \\sum_{\\ell \\in E^{-}}\\ell\\beta_{\\ell}(x); \\quad \\Sigma(x) = \\sum_{\\ell \\in E^{-}}\\beta_{\\ell}(x)\\ell\\ell^{t}$. For the SIR model, the jumps are $(S,I) \\rightarrow (S-1,I+1)$ with rate $\\lambda S I / N$ and $(S,I) \\rightarrow (S,I-1)$ with rate $\\gamma I$. The drift function for the SIR model is [BLANK].",
    "gold_answer": "$b(\\eta, s, i) = \\left(\\begin{array}{c}{-\\lambda s i}\\\\{\\lambda s i - \\gamma i}\\end{array}\\right)$. This is the drift function for the SIR model, representing the expected change in the number of susceptible and infectious individuals over time.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Computational Statistics & Data Analysis\\2021\\ScienceDirect_articles_03Mar2025_08-50-05.737\\Inference-for-partially-observed-epidemic-dynamic_\\Inference-for-partially-observed-epidemic-dynamic_.md",
      "Inference-for-partially-observed-epidemic-dynamic_.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "$b(\\eta, s, i) = \\left(\\begin{array}{c}{-\\lambda s i}\\\\{\\lambda s i - \\gamma i}\\end{array}\\right)$",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"b(x) = (-Î»xâ‚xâ‚‚, Î»xâ‚xâ‚‚-Î³xâ‚‚)\"\n}",
      "model_answer": "b(x) = (-Î»xâ‚xâ‚‚, Î»xâ‚xâ‚‚-Î³xâ‚‚)",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1211",
    "folder": "",
    "question": "The condition that any two vertices in the clan of a vertex v* are adjacent in the DAG unless both are in pa(v*) is equivalent to stating that v* is [BLANK] from the DAG.",
    "gold_answer": "removable. This condition ensures that the vertex v* can be removed without affecting the model's collapsibility, provided the adjacency condition is met.",
    "source": [],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "removable",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"collapsible\"\n}",
      "model_answer": "collapsible",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-3033",
    "folder": "",
    "question": "In the context of testing the error distribution in regression models, the proposed jackknife empirical likelihood method is advantageous because it has a [BLANK] limit, making critical values readily available without the need for bootstrap methods.",
    "gold_answer": "chi-square. This highlights the method's ease of use and computational simplicity compared to traditional approaches that require more complex procedures to determine critical values.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2012\\ScienceDirect_articles_01Mar2025_03-42-36.661\\Jackknife-empirical-likelihood-tests-for-error-dis\\Jackknife-empirical-likelihood-tests-for-error-dis.md",
      "Jackknife-empirical-likelihood-tests-for-error-dis.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "chi-square",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"chi-square\"\n}",
      "model_answer": "chi-square",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1698",
    "folder": "",
    "question": "The musk data application involves predicting the binding strength between molecules (bags) with different conformations (instances) and target receptors. The covariates or explanatory variables in this context are the distances measured from the origin to the surface of each conformation of the molecule along many rays, and the response is the [BLANK] between the molecule and the target receptor.",
    "gold_answer": "binding affinity. This continuous response variable measures the strength of the interaction between the molecule and its target receptor, which is the focus of the prediction task in the musk data application.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "binding affinity",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"binding strength\"\n}",
      "model_answer": "binding strength",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-740",
    "folder": "",
    "question": "In the context of local manifold approximation classification, the general algorithm assigns a feature to the class having the closest support, which is referred to as [BLANK].",
    "gold_answer": "local manifold approximation classification. This term is used to describe the algorithm's approach of approximating the support of the data within each class locally around the feature to be classified.",
    "source": [
      "Classification_via_local_manifold_approximation.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\biomet\\Volume_107_Issue_4\\Classification_via_local_manifold_approximation\\Classification_via_local_manifold_approximation.md"
    ],
    "category": "INCORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "local manifold approximation classification",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"nearest neighbor\"\n}",
      "model_answer": "nearest neighbor",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-773",
    "folder": "",
    "question": "The multivariate Laplace distribution is defined by a density function that includes a normalizing constant a(Î£) and a vector function t(y-Î¼) = (Â±âˆš|yâ‚-Î¼â‚|, ..., Â±âˆš|yâ‚š-Î¼â‚š|)^T, where the sign of each component is determined by [BLANK].",
    "gold_answer": "the sign of yâ±¼ - Î¼â±¼. This specifies how the absolute differences are signed, ensuring the correct construction of the residual vector for the Laplace distribution.",
    "source": [],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "the sign of yâ±¼ - Î¼â±¼",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"the sign of the corresponding component of y-Î¼\"\n}",
      "model_answer": "the sign of the corresponding component of y-Î¼",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-2847",
    "folder": "",
    "question": "In the context of longitudinal canonical correlation analysis (LCCA), the model for each observation is given by Xáµ¢â±¼ = Î¼áµ¢â±¼Ë£ + Záµ¢,â‚€Ë£ + táµ¢â±¼Záµ¢,â‚Ë£ + Îµáµ¢â±¼Ë£, where Záµ¢,â‚€Ë£ and Záµ¢,â‚Ë£ represent the [BLANK] and random slopes, respectively.",
    "gold_answer": "random intercepts. This highlights the model's use of random effects to account for individual variability in both the baseline levels and the rates of change over time.",
    "source": [
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of the Royal Statistical Society, Series C (Applied Statistics)\\Volume_72_Issue_3\\Longitudinal canonical correlation analysis\\Longitudinal canonical correlation analysis.md",
      "Longitudinal canonical correlation analysis.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "random intercepts",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"random intercepts\"\n}",
      "model_answer": "random intercepts",
      "error": null
    }
  },
  {
    "qid": "fill-in-the-blank-ds-1823",
    "folder": "",
    "question": "The Hilbertâ€“Schmidt Independence Criterion (HSIC) is a nonparametric dependence measure that uses the distance between the kernel embeddings of probability measures in a [BLANK].",
    "gold_answer": "reproducing kernel Hilbert space (RKHS). This space is crucial for measuring dependency not only between univariate or multivariate random variables but also between random variables in more complex structures like high-dimensional or functional data.",
    "source": [
      "A-fast-and-accurate-kernel-based-independence-test.md",
      "E:\\shuju\\MD_result\\md_statistic_paper\\Journal of Multivariate Analysis\\2024\\ScienceDirect_articles_28Feb2025_08-26-22.000\\A-fast-and-accurate-kernel-based-independence-test\\A-fast-and-accurate-kernel-based-independence-test.md"
    ],
    "category": "CORRECT",
    "question_context_used": "",
    "gold_answer_parsed": "reproducing kernel Hilbert space (RKHS)",
    "model_evaluation_result": {
      "model_raw_response": "{\n  \"answer\": \"Reproducing Kernel Hilbert Space\"\n}",
      "model_answer": "Reproducing Kernel Hilbert Space",
      "error": null
    }
  }
]